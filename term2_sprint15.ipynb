{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "term2_sprint15.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyORdcJzDrj7tuNt96I0Yv9V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/T-Sawao/diveintocode-ml3/blob/main/term2_sprint15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6OIBurNYGQg"
      },
      "source": [
        "# 1.このSprintについて\n",
        "\n",
        "**Sprintの目的**  \n",
        "機械学習分野の論文から有益な情報を引き出せるようにする\n",
        "これまで扱ってきた領域の論文から新たな知識を得る\n",
        "\n",
        "どのように学ぶか\n",
        "ある論文に対しての問題に答えていくことで、読むポイントを学んでいきます。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGCa5AwOYOq4"
      },
      "source": [
        ".論文読解\n",
        "\n",
        "以下の論文を読み問題に答えてください。CNNを使った物体検出（Object Detection）の代表的な研究です。\n",
        "\n",
        "\n",
        "[8]Ren, S., He, K., Girshick, R., Sun, J.: Faster r-cnn: Towards real-time object detection with region proposal networks. In: Advances in neural information processing systems. (2015) 91–99  \n",
        "https://arxiv.org/pdf/1506.01497.pdf\n",
        "\n",
        "\n",
        "## 問題\n",
        "それぞれについてJupyter Notebookにマークダウン形式で記述してください。\n",
        "\n",
        "**条件**  \n",
        "- 答える際は論文のどの部分からそれが分かるかを書く。\n",
        "- 必要に応じて先行研究（引用されている論文）も探しにいく。最低2つは他の論文を利用して回答すること。\n",
        "- 論文の紹介記事を見ても良い。ただし、答えは論文内に根拠を探すこと。\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yaVDKrBYo4E"
      },
      "source": [
        "### (1) 物体検出の分野にはどういった手法が存在したか。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVDUxsQfZUma"
      },
      "source": [
        "１PP-Abstract内を参照\n",
        "\n",
        "SPPnet、FastR -CNN\n",
        "\n",
        "Abstract—State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet [1] and Fast R-CNN [2] have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNaJzyJOaj93"
      },
      "source": [
        "要約-最先端のオブジェクト検出ネットワークは、オブジェクトの場所を仮定するために地域提案アルゴリズムに依存しています。 SPPnet [1]やFastR-CNN [2]のような進歩により、これらの検出ネットワークの実行時間が短縮され、領域提案の計算がボトルネックになっています。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLzzsXJTYo10"
      },
      "source": [
        "### (2) Fasterとあるが、どういった仕組みで高速化したのか。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NF5osBBUcz4n"
      },
      "source": [
        "Our object detection system, called Faster R-CNN, is composed of two modules. The first module is a deep fully convolutional network that proposes regions, and the second module is the Fast R-CNN detector [2] that uses the proposed regions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtUfeNIgdteq"
      },
      "source": [
        "RPN(マルチスペクトル領域提案ネットワーク)とFastR-CNN\n",
        "\n",
        "step1  \n",
        "① RPNでトレーニングした提案を使用してFast R-CNNをトレーニングします。\n",
        "\n",
        "② FastR-CNNによって調整されたネットワークを使用して初期化します。 RPN、およびこのプロセスが繰り返されます。\n",
        "\n",
        "このソリューションでは、RPNネットワークとFast R-CNNネットワークがトレーニング中に1つのネットワークにマージされます（図2を参照）。提案ボックスの座標はネットワーク応答でもあるため、おおよそのボックス座標です。\n",
        "\n",
        "step2  \n",
        "step1 RPNによって生成された提案を使用して、Fast R-CNNによって個別の検出ネットワークをトレーニングします。  \n",
        "※この時点で、2つのネットワークは畳み込み層を共有しません。\n",
        "\n",
        "step3  \n",
        "検出器ネットワークを使用します。 RPNトレーニングを初期化しますが、共有畳み込みを修正しますレイヤーを作成し、RPNに固有のレイヤーのみを微調整します。  \n",
        "\n",
        "これで、2つのネットワークは畳み込み層を共有します。最後に、共有畳み込み層を固定したまま、FastR-CNNの一意の層を微調整します。そのため、両方のネットワークは同じ畳み込み層を共有し、統合ネットワークを形成します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oxv2nN2vYozU"
      },
      "source": [
        "### (3) One-Stageの手法とTwo-Stageの手法はどう違うのか。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGJ1dJ64jJaw"
      },
      "source": [
        "OverFeat  \n",
        "https://arxiv.org/abs/1312.6229v4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABP4J-WQAtPR"
      },
      "source": [
        "Our multiscale and multi-view approach was critical to obtaining good performance, as can be seen\n",
        "in Fig. 9: Using only a single centered crop, our regressor network achieves an error rate of 40%. By\n",
        "combining regressor predictions from all spatial locations at two scales, we achieve a vastly better\n",
        "error rate of 31.5%. Adding a third and fourth scale further improves performance to 30.0% error.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF1T8aF7BT_-"
      },
      "source": [
        "ご覧のとおり、優れたパフォーマンスを得るには、マルチスケールおよびマルチビューのアプローチが重要でした。\n",
        "図9：単一の中心のクロップのみを使用して、リグレッサーネットワークは40％のエラー率を達成します。 沿って\n",
        "2つのスケールですべての空間位置からのリグレッサー予測を組み合わせることで、はるかに優れた\n",
        "エラー率は31.5％です。 3番目と4番目のスケールを追加すると、パフォーマンスがさらに向上し、エラーが30.0％になります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vT0RD96qYow4"
      },
      "source": [
        "### (4) RPNとは何か。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqi40dw8jUt5"
      },
      "source": [
        "3P-3.1Region Proposal Networksを参照  \n",
        "A Region Proposal Network (RPN) takes an image (of any size) as input and outputs a set of rectangular object proposals, each with an objectness score\n",
        "\n",
        "参考資料  \n",
        "https://medium.com/egen/region-proposal-network-rpn-backbone-of-faster-r-cnn-4a744a38d7f9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlrQKGYzYoul"
      },
      "source": [
        "###  (5) RoIプーリングとは何か。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ymDtUN5ew_-"
      },
      "source": [
        "参照資料  \n",
        "https://qiita.com/yu4u/items/5cbe9db166a5d72f9eb8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-kZHfHbYosU"
      },
      "source": [
        "### (6) Anchorのサイズはどうするのが適切か。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IaE_-XUknCv"
      },
      "source": [
        "複数のスケールとアスペクト比のアンカーボックスを参照して、境界ボックスを分類および回帰する。 単一の縮尺の画像とフィーチャマップのみに依存し、単一のサイズのフィルター（フィーチャマップ上のスライドウィンドウ）を使用します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLIV0cWyjfes"
      },
      "source": [
        "Our method classifies and regresses bounding boxes with reference to anchor boxes of multiple scales and aspect ratios. It only relies on images and feature maps of a single scale, and uses filters (sliding windows on the feature map) of a single size. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zf0PdodRYoqd"
      },
      "source": [
        "### (7) 何というデータセットを使い、先行研究に比べどういった指標値が得られているか。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8vbTgVJey_r"
      },
      "source": [
        "MS COCOデータセットを使用（（P11参照)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lO_f8syey9e"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okBrJjmKYoo1"
      },
      "source": [
        "### (8) （アドバンス課題）Faster R-CNNよりも新しい物体検出の論文では、Faster R-CNNがどう引用されているか。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DttnfaHHn_NW"
      },
      "source": [
        "### 自動要約機\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSUypOEyNtT6"
      },
      "source": [
        "https://text-summary.userlocal.jp/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdtBOYdhN4eM"
      },
      "source": [
        "で見せます対処するためのこのスキームの効果を実験する複数のスケールとサイズ（表8）。 \n",
        "分類損失 Lcls は、2つのクラスにわたるログ損失です。 \n",
        "検出ネットワークには採用高速 R - CNN [2]。 \n",
        "私たちは技術を開発する必要があります間で畳み込み層を共有することができます2つの別々のネットワークを学習するのではなく、2つのネットワーク-動作します。 \n",
        "ネットワークをトレーニングするための3つの方法について説明します機能を共有：（ i ）交互のトレーニング。 \n",
        "共有層後方伝搬信号 RPN 損失と高速 R - CNN 損失の両方から結合されます。 \n",
        "ソルバーはに含まれていますリリースされたPython コード。 \n",
        "FastR - CNN による検出ネットワークステップ1 RPN によって生成されます。 \n",
        "検出ネット-作業もImageNet によって初期化されます-事前トレーニング済みモデル。 \n",
        "そのような予測は不可能ではありません—それでも真ん中だけの場合、オブジェクトの範囲を大まかに推測しますオブジェクトのが表示されます。\n",
        "          "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhzPbPu2OHZC"
      },
      "source": [
        "IMAKITA Document Squeezer  \n",
        "https://report.hot-cafe.net/imakita-document-squeezer-7125\n",
        "\n",
        "\n",
        "検出ネットワークには採用高速 R - CNN [2]。\n",
        " 私たちは技術を開発する必要があります間で畳み込み層を共有することができます2つの別々のネットワークを学習するのではなく、2つのネットワーク-動作します。\n",
        " ネットワークをトレーニングするための3つの方法について説明します機能を共有：（ i ）交互のトレーニング。\n",
        " 共有層後方伝搬信号 RPN 損失と高速 R - CNN 損失の両方から結合されます。\n",
        " FastR - CNN による検出ネットワークステップ1 RPN によって生成されます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OE2fXG1FQ7SF"
      },
      "source": [
        "###  資料\n",
        "\n",
        "### 分野の系譜などわかりやすそう\n",
        "\n",
        "https://blog.negativemind.com/2019/04/27/general-object-detection-and-instance-segmentation-mask-r-cnn/\n",
        "\n",
        "### FastR-CNN特化\n",
        "https://www.slideshare.net/takashiabe338/fast-rcnnfaster-rcnn\n",
        "\n",
        "### 医療特化の論文翻訳機  \n",
        "https://www.marketing.hpcr.jp/hpcrreading?utm_source=ydn&utm_medium=display&utm_campaign=ydnRtg_hreader_300x300_191217nkd1&yclid=YJAD.1607587547.hMQXhyCdcq0aSWzV4_F_33m0oPEqqgqh0yOG2BVvHvG09AQXd6fZtsShShFrGxESZcNlY_LOGYoNSuya6WCn1rhwzylcng1Tu6G6ix.Hqww.myQ-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dn9h9q5Nn23u"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmpEY-u2sHn6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}