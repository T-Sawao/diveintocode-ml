{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sprint9 深層学習スクラッチ ニューラルネットワーク",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1x0ncqXZSnJu8BQJMsfWocIYdJT1Pwt4x",
      "authorship_tag": "ABX9TyNAayTR9AcxI6w/3MVrQLMY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/T-Sawao/diveintocode-ml/blob/master/term1_sprint9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XC87SJCf3c3"
      },
      "source": [
        "# 2.MNISTデータセット\n",
        "\n",
        "ニューラルネットワークスクラッチの検証にはMNISTデータセットを使用します。各種ライブラリやサイトからダウンロードできますが、ここでは深層学習フレームワークのKerasを用います。以下のコードを実行すればデータセットをダウンロードし、展開まで行えます。\n",
        "\n",
        "\n",
        "《データセットをダウンロードするコード》"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8dATX-XjFmt"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as setattr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TK_cHv3hf16i"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANj91yBrhVlu"
      },
      "source": [
        "**《MNISTとは？》**\n",
        "\n",
        "\n",
        "画像分類のための定番データセットで、手書き数字認識を行います。このデータセットには訓練用6万枚、テスト用1万枚の28×28ピクセルの白黒画像、およびそれらが0〜9のどの数字であるかというラベルが含まれています。\n",
        "\n",
        "\n",
        "**《画像データとは？》**\n",
        "\n",
        "\n",
        "デジタル画像は点の集合で、これをピクセルと呼びます。一般的に白黒画像であればピクセルには0〜255の値が含まれます。一方、カラー画像であればR（赤）、G（緑）、B（青）それぞれに対応する0〜255の値が含まれます。機械学習をする上では、この0〜255の値一つひとつが特徴量として扱われます。0〜255は符号なしの8ビット整数で表せる範囲になるため、NumPyであれば「uint8」型の変数として保持できます。\n",
        "\n",
        "\n",
        "**データセットの確認**\n",
        "どういったデータなのかを見てみます。\n",
        "\n",
        "\n",
        "**《サンプルコード》**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SN-ETfZMg-oW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb8f86b5-9bc1-43e9-d309-cf74737a6268"
      },
      "source": [
        "print(X_train.shape) # (60000, 28, 28)\n",
        "print(X_test.shape) # (10000, 28, 28)\n",
        "print(X_train[0].dtype) # uint8\n",
        "print(X_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n",
            "uint8\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
            "  175  26 166 255 247 127   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
            "  225 172 253 242 195  64   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
            "   93  82  82  56  39   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
            "   25   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
            "  150  27   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
            "  253 187   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
            "  253 249  64   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
            "  253 207   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
            "  250 182   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
            "   78   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YJO0avohaQc"
      },
      "source": [
        "各データは28×28ピクセルの白黒画像です。\n",
        "\n",
        "\n",
        "**平滑化**  \n",
        "(1, 28, 28)の各画像を、(1, 784)に変換します。これまで学んできた機械学習手法や、今回扱う全結合層のみのニューラルネットワークではこの形で扱います。全てのピクセルが一列になっていることを、 平滑化（flatten） してあるという風に表現します。\n",
        "\n",
        "\n",
        "**《サンプルコード》**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3fBa8J0hbqR"
      },
      "source": [
        "X_train = X_train.reshape(-1, 784)\n",
        "X_test = X_test.reshape(-1, 784)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZucq4mcuV7L"
      },
      "source": [
        "**《補足》**\n",
        "\n",
        "\n",
        "ここまで機械学習を学んでくる中で、特徴量の数を「次元」と呼んできました。その視点ではMNISTは784次元のデータです。一方で、NumPyのshapeが(784,)の状態を1次元配列とも呼びます。画像としての縦横の情報を持つ（28, 28)の状態であれば、2次元配列です。この視点では2次元のデータです。さらに、もしもカラー画像であれば(28, 28, 3)ということになり、3次元配列です。先ほどの視点では3次元のデータになります。しかし、白黒でもカラーでも平面画像であり、立体データではないという視点で、2次元のデータです。画像データを扱う際にはこのように「次元」という言葉が複数の意味合いで使われることに注意してください。\n",
        "\n",
        "\n",
        "## 画像データの可視化\n",
        "画像データを可視化します。plt.imshowに渡します。\n",
        "\n",
        "\n",
        "**《サンプルコード》**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMPyAGiluVu9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "9ea5bdb5-4fe8-4250-9d45-08d7e15bf8d9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "index = 0\n",
        "image = X_train[index].reshape(28,28)\n",
        "# X_train[index]: (784,)\n",
        "# image: (28, 28)\n",
        "plt.imshow(image, 'gray')\n",
        "plt.title('label : {}'.format(y_train[index]))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arGUeurkix_m"
      },
      "source": [
        "numpy.reshape — NumPy v1.17 Manual  \n",
        "https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html\n",
        "\n",
        "matplotlib.pyplot.imshow — Matplotlib 3.1.1 documentation  \n",
        "https://matplotlib.org/api/_as_gen/matplotlib.pyplot.imshow.html\n",
        "\n",
        "\n",
        "**《発展的話題》**\n",
        "\n",
        "\n",
        "画像データは符号なし8ビット整数のuint8型で保持されることが一般的ですが、plt.imshowはより自由な配列を画像として表示することが可能です。例えば、以下のようにマイナスの値を持ったfloat64型の浮動小数点であってもエラーにはならないし、先ほどと全く同じ風に表示されます。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BnZscP4FTSu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "be20a472-4994-44c7-f79e-f92c402e698a"
      },
      "source": [
        "index = 0\n",
        "image = X_train[index].reshape(28,28)\n",
        "image = image.astype(np.float) # float型に変換\n",
        "image -= 105.35 # 意図的に負の小数値を作り出してみる\n",
        "plt.imshow(image, 'gray')\n",
        "plt.title('label : {}'.format(y_train[index]))\n",
        "plt.show()\n",
        "print(image) # 値を確認"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[[-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -102.35  -87.35  -87.35  -87.35   20.65   30.65\n",
            "    69.65  -79.35   60.65  149.65  141.65   21.65 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -75.35\n",
            "   -69.35  -11.35   48.65   64.65  147.65  147.65  147.65  147.65  147.65\n",
            "   119.65   66.65  147.65  136.65   89.65  -41.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -56.35  132.65\n",
            "   147.65  147.65  147.65  147.65  147.65  147.65  147.65  147.65  145.65\n",
            "   -12.35  -23.35  -23.35  -49.35  -66.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35  113.65\n",
            "   147.65  147.65  147.65  147.65  147.65   92.65   76.65  141.65  135.65\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -25.35\n",
            "    50.65    1.65  147.65  147.65   99.65  -94.35 -105.35  -62.35   48.65\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "   -91.35 -104.35   48.65  147.65  -15.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35   33.65  147.65   84.65 -103.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35  -94.35   84.65  147.65  -35.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35  -70.35  135.65  119.65   54.65    2.65 -104.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35  -24.35  134.65  147.65  147.65   13.65\n",
            "   -80.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35  -60.35   80.65  147.65  147.65\n",
            "    44.65  -78.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -89.35  -12.35  146.65\n",
            "   147.65   81.65 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  143.65\n",
            "   147.65  143.65  -41.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35  -59.35   24.65   77.65  147.65\n",
            "   147.65  101.65 -103.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35  -66.35   42.65  123.65  147.65  147.65  147.65\n",
            "   144.65   76.65 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35  -81.35    8.65  115.65  147.65  147.65  147.65  147.65   95.65\n",
            "   -27.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -82.35\n",
            "   -39.35  107.65  147.65  147.65  147.65  147.65   92.65  -24.35 -103.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35   65.65  113.65\n",
            "   147.65  147.65  147.65  147.65   89.65  -25.35  -96.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35  -50.35   66.65  120.65  147.65  147.65\n",
            "   147.65  147.65  138.65   27.65  -94.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35   30.65  147.65  147.65  147.65  106.65\n",
            "    29.65   26.65  -89.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhxXBf50kAsC"
      },
      "source": [
        "これは、自動的に値を0〜255の整数に変換して処理するように作られているからです。uint8型であっても最小値が0、最大値が255でない場合には色合いがおかしくなります。それを防ぐためには次のように引数を入れてください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73RcT2XGkHvv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "f1b4d33d-3806-442d-8052-8d0f7cae991a"
      },
      "source": [
        "plt.imshow(image, 'gray', vmin = 0, vmax = 255)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fda168ee588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDf3h29dnbGS"
      },
      "source": [
        "画像関係のライブラリではこの自動的なスケーリングが思わぬ結果を生むことがあるので、新しいメソッドを使うときには確認しておきましょう。\n",
        "\n",
        "\n",
        "## 前処理\n",
        "画像は0から255のuint8型で表されますが、機械学習をする上では0から1のfloat型で扱うことになります。以下のコードで変換可能です。\n",
        "\n",
        "\n",
        "**《サンプルコード》**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYslQq_roh8C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "460b24ff-eea4-4eb5-912c-e57886cc67db"
      },
      "source": [
        "X_train = X_train.astype(np.float)\n",
        "X_test = X_test.astype(np.float)\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(X_train.max()) # 1.0\n",
        "print(X_train.min()) # 0.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGv552fVCOo2"
      },
      "source": [
        "また、正解ラベルは0から9の整数ですが、ニューラルネットワークで多クラス分類を行う際には one-hot表現 に変換します。scikit-learnのOneHotEncoderを使用したコードが以下です。このone-hot表現による値はそのラベルである確率を示していることになるため、float型で扱います。\n",
        "\n",
        "\n",
        "《サンプルコード》"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqdCYUbjCOTA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dc98a8d-9805-4558-938f-579e955b5139"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
        "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
        "print(y_train.shape) # (60000,)\n",
        "print(y_train_one_hot.shape) # (60000, 10)\n",
        "print(y_train_one_hot.dtype) # float64"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000,)\n",
            "(60000, 10)\n",
            "float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icdFEvl31yLQ"
      },
      "source": [
        "sklearn.preprocessing.OneHotEncoder — scikit-learn 0.21.3 documentation  \n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n",
        "\n",
        "さらに、訓練データ6万枚の内2割を検証データとして分割してください。訓練データが48000枚、検証データが12000枚となります。\n",
        "\n",
        "\n",
        "《サンプルコード》"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4Lzj9o5lHgI",
        "outputId": "3da77d25-0c59-4c85-e73c-4541235d60db"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
        "print(X_train.shape) # (48000, 784)\n",
        "print(X_val.shape) # (12000, 784)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48000, 784)\n",
            "(12000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnL0UXs3lI1j"
      },
      "source": [
        "# 3.ニューラルネットワークスクラッチ\n",
        "\n",
        "ニューラルネットワークのクラスをスクラッチで作成していきます。NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。\n",
        "\n",
        "\n",
        "今回は多クラス分類を行う3層のニューラルネットワークを作成します。層の数などは固定した上でニューラルネットワークの基本を学びます。次のSprintで層を自由に変えられる設計にしていきます。\n",
        "\n",
        "\n",
        "以下に雛形を用意してあります。このScratchSimpleNeuralNetrowkClassifierクラスにコードを書き加えていってください。\n",
        "\n",
        "\n",
        "**《雛形》**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAOAa1zSlJQG"
      },
      "source": [
        "class ScratchSimpleNeuralNetrowkClassifier():\n",
        "    \"\"\"\n",
        "    シンプルな三層ニューラルネットワーク分類器\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    \"\"\"\n",
        "    def __init__(self, verbose = True):\n",
        "        self.verbose = verbose\n",
        "        pass\n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        \"\"\"\n",
        "        ニューラルネットワーク分類器を学習する。\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : 次の形のndarray, shape (n_samples, n_features)\n",
        "            訓練データの特徴量\n",
        "        y : 次の形のndarray, shape (n_samples, )\n",
        "            訓練データの正解値\n",
        "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
        "            検証データの特徴量\n",
        "        y_val : 次の形のndarray, shape (n_samples, )\n",
        "            検証データの正解値\n",
        "        \"\"\"\n",
        "        if self.verbose:\n",
        "            #verboseをTrueにした際は学習過程などを出力する\n",
        "            print()\n",
        "        pass\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        ニューラルネットワーク分類器を使い推定する。\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : 次の形のndarray, shape (n_samples, n_features)\n",
        "            サンプル\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "            次の形のndarray, shape (n_samples, 1)\n",
        "            推定結果\n",
        "        \"\"\"\n",
        "        pass\n",
        "        return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDHfNYsHlJhJ"
      },
      "source": [
        "## ミニバッチ処理\n",
        "これまでの機械学習スクラッチでは、全てのサンプルを一度に計算していました。しかし、ニューラルネットワークではデータを分割して入力する 確率的勾配降下法 が一般的です。分割した際のひとかたまりを ミニバッチ 、そのサンプル数を バッチサイズ と呼びます。\n",
        "\n",
        "\n",
        "今回はバッチサイズを20とします。今回使う訓練データは48000枚ですから、48000÷20で2400回の更新を繰り返すことになります。ニューラルネットワークではこれを2400回 イテレーション（iteration） すると呼びます。訓練データを一度全て見ると1回の エポック（epoch） が終わったことになります。このエポックを複数回繰り返し、学習が完了します。\n",
        "\n",
        "\n",
        "これを実現するための簡素なイテレータを用意しました。for文で呼び出すと、ミニバッチを取得できます。\n",
        "\n",
        "\n",
        "《コード》"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqckuvYKlKiE"
      },
      "source": [
        "class GetMiniBatch:\n",
        "    \"\"\"\n",
        "    ミニバッチを取得するイテレータ\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : 次の形のndarray, shape (n_samples, n_features)\n",
        "      訓練データ\n",
        "    y : 次の形のndarray, shape (n_samples, 1)\n",
        "      正解値\n",
        "    batch_size : int\n",
        "      バッチサイズ\n",
        "    seed : int\n",
        "      NumPyの乱数のシード\n",
        "    \"\"\"\n",
        "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self._X = X[shuffle_index]\n",
        "        self._y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self._X[p0:p1], self._y[p0:p1]        \n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self._X[p0:p1], self._y[p0:p1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTMSAqsTFRTh"
      },
      "source": [
        "このクラスをインスタンス化し、for文を使うことでミニバッチが取り出せます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aU-gjZuvmk5Q",
        "outputId": "6effdd1c-3fb6-4766-87b8-6436fa7dbfda"
      },
      "source": [
        "get_mini_batch = GetMiniBatch(X_train, y_train, batch_size=20)\n",
        "print(len(get_mini_batch)) # 2400\n",
        "print(get_mini_batch[5]) # 5番目のミニバッチが取得できる\n",
        "for mini_X_train, mini_y_train in get_mini_batch:\n",
        "    # このfor文内でミニバッチが使える\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2400\n",
            "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       ...,\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.]]), array([9, 0, 6, 1, 6, 1, 3, 1, 0, 3, 2, 7, 0, 9, 7, 6, 9, 9, 1, 0],\n",
            "      dtype=uint8))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y686rxuqmolU"
      },
      "source": [
        "__getitem__や__next__は__init__と同じ特殊メソッドの一種です。\n",
        "\n",
        "\n",
        "**学習**  \n",
        "ニューラルネットワークの学習はフォワードプロパゲーションとバックプロパゲションの繰り返しになります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6zShQCkmorj"
      },
      "source": [
        "## 【問題1】重みの初期値を決めるコードの作成\n",
        "ニューラルネットワークの各層の重みの初期値を決めるコードを作成してください。\n",
        "\n",
        "\n",
        "重みの初期値は様々な方法が提案されていますが、今回はガウス分布による単純な初期化を行います。バイアスに関しても同様です。\n",
        "\n",
        "\n",
        "以下のコードを参考にしてください。標準偏差の値sigmaはハイパーパラメータです。発展的な重みの初期化方法については次のSprintで扱います。\n",
        "\n",
        "\n",
        "《サンプルコード》\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nofElv2zmoxY"
      },
      "source": [
        "n_features = 784\n",
        "n_nodes1 = 400\n",
        "sigma = 0.01 # ガウス分布の標準偏差\n",
        "W1 = sigma * np.random.randn(n_features, n_nodes1)\n",
        "# W1: (784, 400)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5YEdHLBmo27"
      },
      "source": [
        "numpy.random.randn — NumPy v1.15 Manual  \n",
        "https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.randn.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0nTE3fqmo5N"
      },
      "source": [
        "## 【問題2】フォワードプロパゲーションの実装\n",
        "三層のニューラルネットワークの フォワードプロパゲーション を作成してください。以下の説明ではノード数は1層目は400、2層目は200としますが、変更しても構いません。\n",
        "\n",
        "\n",
        "各層の数式を以下に示します。今回はそれぞれの記号が表す配列が、実装上どのようなndarrayのshapeになるかを併記してあります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EuK6I11moz5"
      },
      "source": [
        "batch_size = 20 # バッチサイズ\n",
        "n_features = 784 # 特徴量の数\n",
        "n_nodes1 = 400 # 1層目のノード数\n",
        "n_nodes2 = 200 # 2層目のノード数\n",
        "n_output = 10 # 出力のクラス数（3層目のノード数）"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XcD-2sKmouI"
      },
      "source": [
        "「1層目」\n",
        "\n",
        "$$A_1 = X \\cdot W_1 + B_1$$\n",
        "\n",
        "X\n",
        "  : 特徴量ベクトル (batch_size, n_features)\n",
        "\n",
        "\n",
        "W\n",
        "1\n",
        " : 1層目の重み (n_features, n_nodes1)\n",
        "\n",
        "\n",
        "B\n",
        "1\n",
        " : 1層目のバイアス (n_nodes1,)\n",
        "\n",
        "\n",
        "A\n",
        "1\n",
        " : 出力 (batch_size, n_nodes1)\n",
        "\n",
        "\n",
        "「1層目の活性化関数」\n",
        "\n",
        "$$Z_1 = f(A_1)$$\n",
        "f\n",
        "(\n",
        ")\n",
        "  : 活性化関数\n",
        "\n",
        "\n",
        "Z\n",
        "1\n",
        " 出力 (batch_size, n_nodes1)\n",
        "\n",
        "\n",
        "「2層目」\n",
        "\n",
        "$$A_2 = Z_1 \\cdot W_2 + B_2$$\n",
        "\n",
        "W\n",
        "2\n",
        "  : 2層目の重み (n_nodes1, n_nodes2)\n",
        "\n",
        "\n",
        "B\n",
        "2\n",
        " : 2層目のバイアス (n_nodes2,)\n",
        "\n",
        "\n",
        "A\n",
        "2\n",
        " : 出力 (batch_size, n_nodes2)\n",
        "\n",
        "\n",
        "「2層目の活性化関数」\n",
        "\n",
        "$$Z_2 = f(A_2)$$\n",
        "\n",
        "f\n",
        "(\n",
        ")\n",
        " : 活性化関数\n",
        "\n",
        "\n",
        "Z\n",
        "2\n",
        " 出力 (batch_size, n_nodes2)\n",
        "\n",
        "\n",
        "「3層目（出力層）」\n",
        "\n",
        "$$A_3 = Z_2 \\cdot W_3 + B_3$$\n",
        "\n",
        "W\n",
        "3\n",
        "  : 3層目の重み (n_nodes2, n_output)\n",
        "\n",
        "\n",
        "B\n",
        "3\n",
        " : 3層目のバイアス (n_output,)\n",
        "\n",
        "\n",
        "A\n",
        "3\n",
        " : 出力 (batch_size, n_output)\n",
        "\n",
        "\n",
        "「3層目の活性化関数」\n",
        "\n",
        "$$Z_3 = softmax(A_3)$$\n",
        "s\n",
        "o\n",
        "f\n",
        "t\n",
        "m\n",
        "a\n",
        "x\n",
        "(\n",
        ")\n",
        " : ソフトマックス関数\n",
        "\n",
        "\n",
        "Z\n",
        "3\n",
        " 出力 (batch_size, n_output)\n",
        "\n",
        "\n",
        "Z\n",
        "3\n",
        " は各ラベル（0〜9）に対する確率の配列である。\n",
        "\n",
        "\n",
        "\n",
        "**活性化関数（フォワードプロバゲーション）**  \n",
        "\n",
        "活性化関数を作成し、フォワードプロパゲーションの中で使用します。切り替えられるように実装することを推奨しますが、片方でも構いません。\n",
        "\n",
        "\n",
        "「シグモイド関数」\n",
        "\n",
        "$$f(Z) = sigmoid(A) = \\frac{1}{1+exp(-A)}$$\n",
        "\n",
        "指数関数 \n",
        "e\n",
        "x\n",
        "p\n",
        "(\n",
        "−\n",
        "A\n",
        ")\n",
        " の計算はnp.expを使用してください。\n",
        "\n",
        "\n",
        "numpy.exp — NumPy v1.15 Manual  \n",
        "https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.exp.html\n",
        "\n",
        "\n",
        "「ハイパボリックタンジェント関数」\n",
        "\n",
        "\n",
        "次の数式で表されますが、np.tanhひとつで実現できます。\n",
        "\n",
        "$$f(Z) = tanh(A) = \\frac{exp(A) - exp(-A)}{exp(A) + exp(-A)}$$\n",
        "\n",
        "numpy.tanh — NumPy v1.15 Manual  \n",
        "https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.tanh.html\n",
        "\n",
        "\n",
        "＊現在ではこれらの代わりにReLUと呼ばれる活性化関数が一般的です。次のSprintで扱います。\n",
        "\n",
        "\n",
        "**ソフトマックス関数**  \n",
        "ソフトマックス関数を作成し、フォワードプロパゲーションの中で使用します。これも活性化関数の一種ですが、多クラス分類の出力層で使われる特性上、区別して扱われることが多いです。\n",
        "\n",
        "\n",
        "次の数式です。\n",
        "$$Z_{3\\_k} = \\frac{exp(A_{3\\_k})}{\\sum_{i=1}^{n_c}exp(A_{3\\_i})}$$\n",
        "\n",
        "Z\n",
        "3\n",
        "k\n",
        " : \n",
        "k\n",
        " 番目のクラスの確率ベクトル (batch_size,)\n",
        "\n",
        "\n",
        "A\n",
        "3\n",
        "k\n",
        " : \n",
        "k\n",
        " 番目のクラスにあたる前の層からのベクトル (batch_size,)\n",
        "\n",
        "\n",
        "n\n",
        "c\n",
        " : クラスの数、n_output。今回のMNISTでは10。\n",
        "\n",
        "\n",
        "分母は全てのクラスに相当する値を指数関数に通した上で足し合わせたものです。その中で、分子に \n",
        "k\n",
        " 番目のクラスを持ってくることで、 \n",
        "k\n",
        " 番目のクラスである確率が求まります。\n",
        "\n",
        "\n",
        "これを10クラス分計算し、合わせたものが \n",
        "Z\n",
        "3\n",
        " です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBT8EmxumooX"
      },
      "source": [
        "## 【問題3】交差エントロピー誤差の実装\n",
        "目的関数（損失関数）を作成します。\n",
        "\n",
        "\n",
        "多クラス分類の目的関数である交差エントロピー誤差 $L$ は次の数式です。\n",
        "\n",
        "\n",
        "$$L = - \\frac{1}{n_b}\\sum_{j}^{n_b}\\sum_{k}^{n_c}y_{jk} log(z_{3\\_jk})$$\n",
        "$y_{ij}$ : $j$ 番目のサンプルの $k$ 番目のクラスの正解ラベル（one-hot表現で0か1のスカラー）\n",
        "\n",
        "\n",
        "$z_{3_ij}$ : $j$ 番目のサンプルの $k$ 番目のクラスの確率（スカラー）\n",
        "\n",
        "\n",
        "$n_{b}$ : バッチサイズ、batch_size\n",
        "\n",
        "\n",
        "$n_{c}$ : クラスの数、n_output（今回のMNISTでは10）\n",
        "\n",
        "\n",
        "サンプル1つあたりの誤差が求まります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkdVoHnJmofV"
      },
      "source": [
        "## 【問題4】バックプロパゲーションの実装\n",
        "三層のニューラルネットワークのバックプロパゲーションを作成してください。確率的勾配降下法を行う部分です。\n",
        "\n",
        "\n",
        "数式を以下に示します。\n",
        "\n",
        "\n",
        "まず、i層目の重みとバイアスの更新式です。 \n",
        "W\n",
        "i\n",
        " と \n",
        "B\n",
        "i\n",
        " に対し、更新後の \n",
        "W\n",
        "′\n",
        "i\n",
        " と \n",
        "B\n",
        "′\n",
        "i\n",
        " は次の数式で求められます。\n",
        "\n",
        "$$W_i^{\\prime} = W_i - \\alpha \\frac{\\partial L}{\\partial W_i}$$\n",
        "$$B_i^{\\prime} = B_i - \\alpha \\frac{\\partial L}{\\partial B_i}$$\n",
        "\n",
        "$\\alpha$ : 学習率（層ごとに変えることも可能だが、基本的には全て同じとする）\n",
        "\n",
        "$\\frac{\\partial L}{\\partial W_i}$ : $W_i$ に関する損失 $L$ の勾配\n",
        "\n",
        "$\\frac{\\partial L}{\\partial B_i}$ : $B_i$ に関する損失 $L$ の勾配\n",
        "\n",
        "この更新方法はSprint3線形回帰やsprint4ロジスティック回帰における最急降下法と同様です。より効果的な更新方法が知られており、それは次のSprintで扱います。\n",
        "\n",
        "勾配 $\\frac{\\partial L}{\\partial W_i}$ や $\\frac{\\partial L}{\\partial B_i}$ を求めるために、バックプロパゲーションを行います。以下の数式です。ハイパボリックタンジェント関数を使用した例を載せました。シグモイド関数の場合の数式はその後ろにあります。\n",
        "\n",
        "「3層目」\n",
        "\n",
        "\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial A_3} = Z_{3} - Y$$\n",
        "$$frac{\\partial L}{\\partial B_3} = \\sum_{j}^{n_b}\\frac{\\partial L}{\\partial A_{3\\_j}}$$\n",
        "$$frac{\\partial L}{\\partial W_3} = Z_{2}^{T}\\cdot \\frac{\\partial L}{\\partial A_3}$$\n",
        "$$frac{\\partial L}{\\partial Z_2} = \\frac{\\partial L}{\\partial A_3} \\cdot W_3^T$$\n",
        "\n",
        "$\\frac{\\partial L}{\\partial A_3}$ : $A_3$ に関する損失 $L$ の勾配 (1, n_output)\n",
        "\n",
        "$\\frac{\\partial L}{\\partial B_3}$ : $B_3$ に関する損失 $L$ の勾配 (1, n_output)\n",
        "\n",
        "$\\frac{\\partial L}{\\partial W_3}$ : $W_3$ に関する損失 $L$ の勾配 (n_nodes2, n_output)\n",
        "\n",
        "$\\frac{\\partial L}{\\partial Z_2}$ : $Z_2$ に関する損失 $L$ の勾配 (1, n_nodes2)\n",
        "\n",
        "$Z_{3_j} : $j$ 番目のサンプルの3層目の出力 (1, n_output)\n",
        "\n",
        "$Y_j$ : $j$ 番目のサンプルの正解ラベル (1, n_output)\n",
        "\n",
        "$Z_{2_j}$ :$j$ 番目のサンプルの2層目の出力 (n_nodes2, 1)\n",
        "\n",
        "$W_3$ : 3層目の重み (n_nodes2, n_output)\n",
        "\n",
        "「2層目」\n",
        "\n",
        "$$frac{\\partial L}{\\partial A_2} = \\frac{\\partial L}{\\partial Z_2} \\odot \\{1-tanh^2(A_{2})\\}$$\n",
        "$$frac{\\partial L}{\\partial B_2} = \\sum_{j}^{n_b}\\frac{\\partial L}{\\partial A_{2\\_j}}$$\n",
        "$$frac{\\partial L}{\\partial W_2} = Z_{1}^T \\cdot \\frac{\\partial L}{\\partial A_2}$$\n",
        "$$frac{\\partial L}{\\partial Z_1} = \\frac{\\partial L}{\\partial A_2} \\cdot W_2^T$$\n",
        "\n",
        "$\\frac{\\partial L}{\\partial A_2}$ : $A_2$ に関する損失 $L$ の勾配 (1, n_nodes2)\n",
        "\n",
        "$\\frac{\\partial L}{\\partial B_2}$ : $B_2$ に関する損失 $L$ の勾配 (1, n_nodes2)\n",
        "\n",
        "$\\frac{\\partial L}{\\partial W_2}$ : $W_2$ に関する損失 $L$ の勾配 (n_nodes1, n_nodes2)\n",
        "\n",
        "$\\frac{\\partial L}{\\partial Z_2}$ : $Z_2$ に関する損失 $L$ の勾配 (1, n_nodes2)\n",
        "\n",
        "$Z_{2_j}$ : $j$ 番目のサンプルの2層目の出力 (1, n_nodes2)\n",
        "\n",
        "$A_{2_j}$ : $j$ 番目のサンプルの2層目の活性化関数の出力 (1, n_nodes2)\n",
        "\n",
        "$Z_{1_j}$ : $j$ 番目のサンプルの1層目の出力 (n_nodes1, 1)\n",
        "\n",
        "$W_2$ : 2層目の重み (n_nodes1, n_nodes2)\n",
        "\n",
        "「1層目」\n",
        "\n",
        "$$frac{\\partial L}{\\partial A_1} = \\frac{\\partial L}{\\partial Z_1} \\odot \\{1-tanh^2(A_{1})\\}$$\n",
        "$$frac{\\partial L}{\\partial B_1} = \\sum_{j}^{n_b}\\frac{\\partial L}{\\partial A_{1\\_j}}$$\n",
        "$$frac{\\partial L}{\\partial W_1} = X^T \\cdot \\frac{\\partial L}{\\partial A_1}$$\n",
        "\n",
        "\n",
        "$\\frac{\\partial L}{\\partial A_1}$ : $A_1$ に関する損失 $L$ の勾配 (1, n_nodes1)\n",
        "\n",
        "$\\frac{\\partial L}{\\partial B_1}$ : $B_1$ に関する損失 $L$ の勾配 (1, n_nodes1)\n",
        "\n",
        "$\\frac{\\partial L}{\\partial W_1}$ : $W_1$ に関する損失 $L$ の勾配 (n_features, n_nodes1)\n",
        "\n",
        "$\\frac{\\partial L}{\\partial Z_1}$ : $Z_1$ に関する損失 $L$ の勾配 (1, n_nodes1)\n",
        "\n",
        "$Z_{1_j}$ : $j$ 番目のサンプルの1層目の出力 (1, n_nodes2)\n",
        "\n",
        "$A_{1_j}$ : $j$ 番目のサンプルの1層目の活性化関数の出力 (1, n_nodes1)\n",
        "\n",
        "$X_j$ : $j$ 番目のサンプル (n_features, 1)\n",
        "\n",
        "$W_1$ : 1層目の重み (n_features, n_nodes1)\n",
        "\n",
        "《補足》\n",
        "\n",
        "\n",
        "活性化関数にシグモイド関数を使用した場合は、次のようになります。\n",
        "\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial A_2} = \\frac{\\partial L}{\\partial Z_2} \\odot  \\{1-sigmoid(A_{2})\\}sigmoid(A_{2})$$\n",
        "$$frac{\\partial L}{\\partial A_1} = \\frac{\\partial L}{\\partial Z_1} \\odot  \\{1-sigmoid(A_{1})\\}sigmoid(A_{1})$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyvfkqZ-mFBr"
      },
      "source": [
        "## 【問題5】推定\n",
        "推定を行うメソッドを作成してください。\n",
        "\n",
        "\n",
        "フォワードプロパゲーションによって出力された10個の確率の中で、最も高いものはどれかを判定します。\n",
        "\n",
        "\n",
        "numpy.argmax — NumPy v1.17 Manual  \n",
        "https://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snRzAz6koVmu"
      },
      "source": [
        "## 解答用クラスコード"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ4hjFDzoTtH"
      },
      "source": [
        "class ScratchSimpleNeuralNetrowkClassifier():\n",
        "    \"\"\"\n",
        "    シンプルな三層ニューラルネットワーク分類器\n",
        "    Parameters\n",
        "    ----------\n",
        "    Attributes\n",
        "    ----------\n",
        "    \"\"\"\n",
        "    def __init__(self, num_iter=10, lr=0.1, bias=1, sigma=0.01, batch_size=20, n_nodes1=400, n_nodes2=200, n_output=10, verbose = True):\n",
        "        self.iter = num_iter\n",
        "        self.lr = lr\n",
        "        self.bias = bias\n",
        "        self.batch_size = batch_size\n",
        "        self.n_features = self.X\n",
        "        self.n_nodes1 = n_nodes1\n",
        "        self.n_nodes2 = n_nodes2\n",
        "        self.n_output = n_output\n",
        "        self.verbose = verbose\n",
        "        self.loss = np.zeros(self.iter)\n",
        "        self.val_loss = np.zeros(self.iter)\n",
        "## 問題１（解答）-----------------------------------------------------------------------------\n",
        "        sigma = sigma\n",
        "        self.w1 = sigma * np.random.randn(n_features, n_nodes1)\n",
        "        self.b1 = sigma * np.random.randn(1, self.n_nodes1)\n",
        "\n",
        "        self.w2 = sigma * np.random.randn(n_nodes1, n_nodes2)\n",
        "        self.b2 = sigma * np.random.randn(1, self.n_nodes２)\n",
        "\n",
        "        self.w3 = sigma * np.random.randn(n_nodes2, n_output)\n",
        "        self.b3 = sigma * np.random.randn(1, self.n_output)\n",
        "## 問題2（解答）-----------------------------------------------------------------------------\n",
        "    #ソフトマックス関数\n",
        "    def _softmax(self, x):\n",
        "      return np.exp(x)/np.sum(np.exp(x), axis=1, leepdims=True)\n",
        "\n",
        "    # シグモイド関数\n",
        "    def _sigmoid(self,z):\n",
        "        return 1 / (1+np.exp(-z))\n",
        "\n",
        "    # フォワードプロパゲーションの実装\n",
        "    def _forward_propagation(self, x):\n",
        "      self.a1 = x@self.w1+self.b1\n",
        "      self.z1 = np.tanh(a1)\n",
        "      \n",
        "      self.a2 = z1@self.w2+self.b2\n",
        "      self.z2 = np.tanh(a2)\n",
        "      \n",
        "      self.a3 = z2@self.w3+self.b3\n",
        "      self.z3 = 　self._softmax(a3)\n",
        "## 問題3（解答）-----------------------------------------------------------------------------\n",
        "    def _cross_entropy_error(y,t): # tはone_hot_vector（即ち、1or0のベクトル）\n",
        "      if y.ndim == 1:\n",
        "        t = t.reshape(1, t.size)\n",
        "        y = y.reshape(1, y.size)\n",
        "\n",
        "    batch_size = y.shape[0]\n",
        "    return -np.sum(t*np.log(y[np.arange(bathch_size), t])) / bathc_size\n",
        "## 問題4（解答）------------------------------------------------------------------------------\n",
        "    def _back_propagation(self, x):\n",
        "      gt_a3 = self.z3 - y\n",
        "      gt_b3 = np.sum(gt_a3)\n",
        "      gt_w3 = (self.z2.T)@gt_a3\n",
        "      gt_z2 = gt_a3@(self.w3.T)\n",
        "      self.w3 = self.w3 - (self.lr*gt_w3)\n",
        "      self.b3 = self.b3 - (self.lr*gt_b3)\n",
        "\n",
        "      gt_a2 = gt_z2@{1-np.tanh(self.a2)}\n",
        "      gt_b2 = np.sum(gt_a2)\n",
        "      gt_w2 = (self.z1.T)@gt_a2\n",
        "      gt_z1 = gt_a2@(self.w2.T)\n",
        "      self.w2 = self.w2 - (self.lr*gt_w2)\n",
        "      self.b2 = self.b2 - (self.lr*gt_b2)\n",
        "\n",
        "      gt_a1 = gt_z1@{1-np.tanh(self.a1)}\n",
        "      gt_b1 = np.sum(gt_a1)\n",
        "      gt_w1 = (self.x.T)@gt_a1\n",
        "      self.w1 = self.w1 - (self.lr*gt_w1)\n",
        "      self.b1 = self.b1 - (self.lr*gt_b1)\n",
        "## 問題6（解答）-----------------------------------------------------------------------------\n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        \"\"\"\n",
        "        ニューラルネットワーク分類器を学習する。\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : 次の形のndarray, shape (n_samples, n_features)\n",
        "            訓練データの特徴量\n",
        "        y : 次の形のndarray, shape (n_samples, )\n",
        "            訓練データの正解値\n",
        "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
        "            検証データの特徴量\n",
        "        y_val : 次の形のndarray, shape (n_samples, )\n",
        "            検証データの正解値\n",
        "        \"\"\"\n",
        "        if (type(X_val) != bool):\n",
        "                self.val =1\n",
        "                X2 = np.concatenate([np.ones((X_val.shape[0],1)), X_val], axis=1)\n",
        "                z_val = np.dot(X2, self.theta.T)\n",
        "                y_hat_val = self._sigmoid(z_val)\n",
        "                self.val_loss[i] = self._loss(y_val, y_hat_val) \n",
        "            \n",
        "            # verboseをTrueにした際は学習過程を出力\n",
        "            if self.verbose :\n",
        "                print(f\"--{i+1}回目~loss~-------\\n{self.loss[i]}\")\n",
        "                print(f\"--{i+1}回目~loss_val~---\\n{self.val_loss[i]}\")\n",
        "\n",
        "        # ミニバッチの取り出し\n",
        "        get_mini_batch = GetMiniBatch(X_train, y_train, batch_size=20)\n",
        "        print(len(get_mini_batch)) # 2400\n",
        "        print(get_mini_batch[5]) # 5番目のミニバッチが取得できる\n",
        "        for mini_X_train, mini_y_train in get_mini_batch:\n",
        "            # このfor文内でミニバッチが使える\n",
        "            pass\n",
        "\n",
        "## 問題5（解答）------------------------------------------------------------------------------\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        ニューラルネットワーク分類器を使い推定する。\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : 次の形のndarray, shape (n_samples, n_features)\n",
        "            サンプル\n",
        "        Returns\n",
        "        -------\n",
        "            次の形のndarray, shape (n_samples, 1)\n",
        "            推定結果\n",
        "        \"\"\"\n",
        "        self._forward_propagation(self.X_)\n",
        "        return np.argmax(self.z3, axis=1)\n",
        "# 問題7（解答）-------------------------------------------------------------------------------    \n",
        "    def plot_cost(self):\n",
        "        \"\"\"\n",
        "        損失の推移をグラフ化する。    \n",
        "        検証用データが入力されていれば、学習用と検証用の損失推移を重ねてグラフ化\n",
        "        \"\"\"\n",
        "        plt.title(\"Num_of_Iteration vs Loss\")\n",
        "        plt.xlabel(\"Num_of_Iteration\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        a = range(self.iter)\n",
        "        plt.plot(range(len(self.loss)), self.loss, color=\"b\", label=\"train_loss\")\n",
        "        if self.val ==1:\n",
        "            plt.plot(range(len(self.val_loss)), self.val_loss, color=\"orange\", label=\"val_loss\")\n",
        "        plt.grid()\n",
        "        plt.legend()\n",
        "## -----------------------------------------------------------------------------------------------\n",
        "    class GetMiniBatch:\n",
        "    \"\"\"\n",
        "    ミニバッチを取得するイテレータ\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : 次の形のndarray, shape (n_samples, n_features)\n",
        "      訓練データ\n",
        "    y : 次の形のndarray, shape (n_samples, 1)\n",
        "      正解値\n",
        "    batch_size : int\n",
        "      バッチサイズ\n",
        "    seed : int\n",
        "      NumPyの乱数のシード\n",
        "    \"\"\"\n",
        "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self._X = X[shuffle_index]\n",
        "        self._y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self._X[p0:p1], self._y[p0:p1]        \n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self._X[p0:p1], self._y[p0:p1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQFUifmAn2dR"
      },
      "source": [
        "# 4.検証\n",
        "\n",
        "## 【問題6】学習と推定\n",
        "MNISTのデータを学習・推定し、Accuracyを計算してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ68sUdGn9mZ"
      },
      "source": [
        "## 【問題7】学習曲線のプロット\n",
        "学習曲線をプロットしてください。\n",
        "\n",
        "\n",
        "ニューラルネットワークは過学習が発生しやすいため、学習曲線の確認が重要です。訓練データと検証データに対するエポックごとの損失（交差エントロピー誤差）を記録できるようにする必要があります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_5IT8NyoBG5"
      },
      "source": [
        "## 【問題8】（アドバンス課題）誤分類の確認\n",
        "誤分類した画像はどのようなものだったかを確認してください。推定値を用意し、以下のコードを実行してください。\n",
        "\n",
        "\n",
        "《コード》"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "oLEV1PKVoFXm",
        "outputId": "27540f31-8571-4fef-a371-ac45c9901729"
      },
      "source": [
        "\"\"\"\n",
        "語分類結果を並べて表示する。画像の上の表示は「推定結果/正解」である。\n",
        "\n",
        "Parameters:\n",
        "----------\n",
        "y_pred : 推定値のndarray (n_samples,)\n",
        "y_val : 検証データの正解ラベル(n_samples,)\n",
        "X_val : 検証データの特徴量（n_samples, n_features)\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "num = 36 # いくつ表示するか\n",
        "true_false = y_pred==y_val\n",
        "false_list = np.where(true_false==False)[0].astype(np.int)\n",
        "if false_list.shape[0] < num:\n",
        "    num = false_list.shape[0]\n",
        "fig = plt.figure(figsize=(6, 6))\n",
        "fig.subplots_adjust(left=0, right=0.8,  bottom=0, top=0.8, hspace=1, wspace=0.5)\n",
        "for i in range(num):\n",
        "    ax = fig.add_subplot(6, 6, i + 1, xticks=[], yticks=[])\n",
        "    ax.set_title(\"{} / {}\".format(y_pred[false_list[i]],y_val[false_list[i]]))\n",
        "    ax.imshow(X_val.reshape(-1,28,28)[false_list[i]], cmap='gray')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-b84815bb0ae6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m36\u001b[0m \u001b[0;31m# いくつ表示するか\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtrue_false\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mfalse_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_false\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfalse_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McaGjuXZoIi5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}