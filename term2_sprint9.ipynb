{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sprint9 深層学習スクラッチ ニューラルネットワーク",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1x0ncqXZSnJu8BQJMsfWocIYdJT1Pwt4x",
      "authorship_tag": "ABX9TyMYd7Kz3mh8HyC8xPquU9Uq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/T-Sawao/diveintocode-ml/blob/master/term2_sprint9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XC87SJCf3c3"
      },
      "source": [
        "# 2.MNISTデータセット\n",
        "\n",
        "ニューラルネットワークスクラッチの検証にはMNISTデータセットを使用します。各種ライブラリやサイトからダウンロードできますが、ここでは深層学習フレームワークのKerasを用います。以下のコードを実行すればデータセットをダウンロードし、展開まで行えます。\n",
        "\n",
        "\n",
        "《データセットをダウンロードするコード》"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8dATX-XjFmt"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as setattr\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TK_cHv3hf16i"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANj91yBrhVlu"
      },
      "source": [
        "**《MNISTとは？》**\n",
        "\n",
        "\n",
        "画像分類のための定番データセットで、手書き数字認識を行います。このデータセットには訓練用6万枚、テスト用1万枚の28×28ピクセルの白黒画像、およびそれらが0〜9のどの数字であるかというラベルが含まれています。\n",
        "\n",
        "\n",
        "**《画像データとは？》**\n",
        "\n",
        "\n",
        "デジタル画像は点の集合で、これをピクセルと呼びます。一般的に白黒画像であればピクセルには0〜255の値が含まれます。一方、カラー画像であればR（赤）、G（緑）、B（青）それぞれに対応する0〜255の値が含まれます。機械学習をする上では、この0〜255の値一つひとつが特徴量として扱われます。0〜255は符号なしの8ビット整数で表せる範囲になるため、NumPyであれば「uint8」型の変数として保持できます。\n",
        "\n",
        "\n",
        "**データセットの確認**\n",
        "どういったデータなのかを見てみます。\n",
        "\n",
        "\n",
        "**《サンプルコード》**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SN-ETfZMg-oW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd197e27-f6bb-4136-f65e-8c6379bde0a0"
      },
      "source": [
        "print(X_train.shape) # (60000, 28, 28)\n",
        "print(X_test.shape) # (10000, 28, 28)\n",
        "print(X_train[0].dtype) # uint8\n",
        "print(X_train[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n",
            "uint8\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
            "  175  26 166 255 247 127   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
            "  225 172 253 242 195  64   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
            "   93  82  82  56  39   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
            "   25   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
            "  150  27   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
            "  253 187   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
            "  253 249  64   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
            "  253 207   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
            "  250 182   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
            "   78   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YJO0avohaQc"
      },
      "source": [
        "各データは28×28ピクセルの白黒画像です。\n",
        "\n",
        "\n",
        "**平滑化**  \n",
        "(1, 28, 28)の各画像を、(1, 784)に変換します。これまで学んできた機械学習手法や、今回扱う全結合層のみのニューラルネットワークではこの形で扱います。全てのピクセルが一列になっていることを、 平滑化（flatten） してあるという風に表現します。\n",
        "\n",
        "\n",
        "**《サンプルコード》**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3fBa8J0hbqR"
      },
      "source": [
        "X_train = X_train.reshape(-1, 784)\n",
        "X_test = X_test.reshape(-1, 784)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZucq4mcuV7L"
      },
      "source": [
        "**《補足》**\n",
        "\n",
        "\n",
        "ここまで機械学習を学んでくる中で、特徴量の数を「次元」と呼んできました。その視点ではMNISTは784次元のデータです。一方で、NumPyのshapeが(784,)の状態を1次元配列とも呼びます。画像としての縦横の情報を持つ（28, 28)の状態であれば、2次元配列です。この視点では2次元のデータです。さらに、もしもカラー画像であれば(28, 28, 3)ということになり、3次元配列です。先ほどの視点では3次元のデータになります。しかし、白黒でもカラーでも平面画像であり、立体データではないという視点で、2次元のデータです。画像データを扱う際にはこのように「次元」という言葉が複数の意味合いで使われることに注意してください。\n",
        "\n",
        "\n",
        "## 画像データの可視化\n",
        "画像データを可視化します。plt.imshowに渡します。\n",
        "\n",
        "\n",
        "**《サンプルコード》**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMPyAGiluVu9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "25a9aa25-c86c-413a-eb4b-3ae0be266b4e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "index = 0\n",
        "image = X_train[index].reshape(28,28)\n",
        "# X_train[index]: (784,)\n",
        "# image: (28, 28)\n",
        "plt.imshow(image, 'gray')\n",
        "plt.title('label : {}'.format(y_train[index]))\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arGUeurkix_m"
      },
      "source": [
        "numpy.reshape — NumPy v1.17 Manual  \n",
        "https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html\n",
        "\n",
        "matplotlib.pyplot.imshow — Matplotlib 3.1.1 documentation  \n",
        "https://matplotlib.org/api/_as_gen/matplotlib.pyplot.imshow.html\n",
        "\n",
        "\n",
        "**《発展的話題》**\n",
        "\n",
        "\n",
        "画像データは符号なし8ビット整数のuint8型で保持されることが一般的ですが、plt.imshowはより自由な配列を画像として表示することが可能です。例えば、以下のようにマイナスの値を持ったfloat64型の浮動小数点であってもエラーにはならないし、先ほどと全く同じ風に表示されます。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BnZscP4FTSu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d28e5724-b86b-40d4-a138-1468bcd660f7"
      },
      "source": [
        "index = 0\n",
        "image = X_train[index].reshape(28,28)\n",
        "image = image.astype(np.float) # float型に変換\n",
        "image -= 105.35 # 意図的に負の小数値を作り出してみる\n",
        "plt.imshow(image, 'gray')\n",
        "plt.title('label : {}'.format(y_train[index]))\n",
        "plt.show()\n",
        "print(image) # 値を確認"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[[-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -102.35  -87.35  -87.35  -87.35   20.65   30.65\n",
            "    69.65  -79.35   60.65  149.65  141.65   21.65 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -75.35\n",
            "   -69.35  -11.35   48.65   64.65  147.65  147.65  147.65  147.65  147.65\n",
            "   119.65   66.65  147.65  136.65   89.65  -41.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -56.35  132.65\n",
            "   147.65  147.65  147.65  147.65  147.65  147.65  147.65  147.65  145.65\n",
            "   -12.35  -23.35  -23.35  -49.35  -66.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35  113.65\n",
            "   147.65  147.65  147.65  147.65  147.65   92.65   76.65  141.65  135.65\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -25.35\n",
            "    50.65    1.65  147.65  147.65   99.65  -94.35 -105.35  -62.35   48.65\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "   -91.35 -104.35   48.65  147.65  -15.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35   33.65  147.65   84.65 -103.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35  -94.35   84.65  147.65  -35.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35  -70.35  135.65  119.65   54.65    2.65 -104.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35  -24.35  134.65  147.65  147.65   13.65\n",
            "   -80.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35  -60.35   80.65  147.65  147.65\n",
            "    44.65  -78.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -89.35  -12.35  146.65\n",
            "   147.65   81.65 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  143.65\n",
            "   147.65  143.65  -41.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35  -59.35   24.65   77.65  147.65\n",
            "   147.65  101.65 -103.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35  -66.35   42.65  123.65  147.65  147.65  147.65\n",
            "   144.65   76.65 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35  -81.35    8.65  115.65  147.65  147.65  147.65  147.65   95.65\n",
            "   -27.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -82.35\n",
            "   -39.35  107.65  147.65  147.65  147.65  147.65   92.65  -24.35 -103.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35   65.65  113.65\n",
            "   147.65  147.65  147.65  147.65   89.65  -25.35  -96.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35  -50.35   66.65  120.65  147.65  147.65\n",
            "   147.65  147.65  138.65   27.65  -94.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35   30.65  147.65  147.65  147.65  106.65\n",
            "    29.65   26.65  -89.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]\n",
            " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
            "  -105.35]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhxXBf50kAsC"
      },
      "source": [
        "これは、自動的に値を0〜255の整数に変換して処理するように作られているからです。uint8型であっても最小値が0、最大値が255でない場合には色合いがおかしくなります。それを防ぐためには次のように引数を入れてください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73RcT2XGkHvv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "5ba7a075-9e53-47f4-83b2-3c6bdcd8a8eb"
      },
      "source": [
        "plt.imshow(image, 'gray', vmin = 0, vmax = 255)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fedaf0e2b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDf3h29dnbGS"
      },
      "source": [
        "画像関係のライブラリではこの自動的なスケーリングが思わぬ結果を生むことがあるので、新しいメソッドを使うときには確認しておきましょう。\n",
        "\n",
        "\n",
        "## 前処理\n",
        "画像は0から255のuint8型で表されますが、機械学習をする上では0から1のfloat型で扱うことになります。以下のコードで変換可能です。\n",
        "\n",
        "\n",
        "**《サンプルコード》**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYslQq_roh8C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46ee77d0-a6bf-460c-aab5-52db6057069a"
      },
      "source": [
        "X_train = X_train.astype(np.float)\n",
        "X_test = X_test.astype(np.float)\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(X_train.max()) # 1.0\n",
        "print(X_train.min()) # 0.0"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGv552fVCOo2"
      },
      "source": [
        "また、正解ラベルは0から9の整数ですが、ニューラルネットワークで多クラス分類を行う際には one-hot表現 に変換します。scikit-learnのOneHotEncoderを使用したコードが以下です。このone-hot表現による値はそのラベルである確率を示していることになるため、float型で扱います。\n",
        "\n",
        "\n",
        "《サンプルコード》"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqdCYUbjCOTA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83350ea9-342c-4adf-b328-a5665b0a53fc"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
        "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
        "print(y_train.shape) # (60000,)\n",
        "print(y_train_one_hot.shape) # (60000, 10)\n",
        "print(y_train_one_hot.dtype) # float64"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000,)\n",
            "(60000, 10)\n",
            "float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icdFEvl31yLQ"
      },
      "source": [
        "sklearn.preprocessing.OneHotEncoder — scikit-learn 0.21.3 documentation  \n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n",
        "\n",
        "さらに、訓練データ6万枚の内2割を検証データとして分割してください。訓練データが48000枚、検証データが12000枚となります。\n",
        "\n",
        "\n",
        "《サンプルコード》"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4Lzj9o5lHgI",
        "outputId": "6d7e84d2-e9ec-48ea-aa9c-e7d8ab6ff92b"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
        "print(X_train.shape) # (48000, 784)\n",
        "print(X_val.shape) # (12000, 784)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48000, 784)\n",
            "(12000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnL0UXs3lI1j"
      },
      "source": [
        "# 3.ニューラルネットワークスクラッチ\n",
        "\n",
        "ニューラルネットワークのクラスをスクラッチで作成していきます。NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。\n",
        "\n",
        "\n",
        "今回は多クラス分類を行う3層のニューラルネットワークを作成します。層の数などは固定した上でニューラルネットワークの基本を学びます。次のSprintで層を自由に変えられる設計にしていきます。\n",
        "\n",
        "\n",
        "以下に雛形を用意してあります。このScratchSimpleNeuralNetrowkClassifierクラスにコードを書き加えていってください。\n",
        "\n",
        "\n",
        "**《雛形》**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAOAa1zSlJQG"
      },
      "source": [
        "class ScratchSimpleNeuralNetrowkClassifier():\n",
        "    \"\"\"\n",
        "    シンプルな三層ニューラルネットワーク分類器\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    \"\"\"\n",
        "    def __init__(self, verbose = True):\n",
        "        self.verbose = verbose\n",
        "        pass\n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        \"\"\"\n",
        "        ニューラルネットワーク分類器を学習する。\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : 次の形のndarray, shape (n_samples, n_features)\n",
        "            訓練データの特徴量\n",
        "        y : 次の形のndarray, shape (n_samples, )\n",
        "            訓練データの正解値\n",
        "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
        "            検証データの特徴量\n",
        "        y_val : 次の形のndarray, shape (n_samples, )\n",
        "            検証データの正解値\n",
        "        \"\"\"\n",
        "        if self.verbose:\n",
        "            #verboseをTrueにした際は学習過程などを出力する\n",
        "            print()\n",
        "        pass\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        ニューラルネットワーク分類器を使い推定する。\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : 次の形のndarray, shape (n_samples, n_features)\n",
        "            サンプル\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "            次の形のndarray, shape (n_samples, 1)\n",
        "            推定結果\n",
        "        \"\"\"\n",
        "        pass\n",
        "        return"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDHfNYsHlJhJ"
      },
      "source": [
        "## ミニバッチ処理\n",
        "これまでの機械学習スクラッチでは、全てのサンプルを一度に計算していました。しかし、ニューラルネットワークではデータを分割して入力する 確率的勾配降下法 が一般的です。分割した際のひとかたまりを ミニバッチ 、そのサンプル数を バッチサイズ と呼びます。\n",
        "\n",
        "\n",
        "今回はバッチサイズを20とします。今回使う訓練データは48000枚ですから、48000÷20で2400回の更新を繰り返すことになります。ニューラルネットワークではこれを2400回 イテレーション（iteration） すると呼びます。訓練データを一度全て見ると1回の エポック（epoch） が終わったことになります。このエポックを複数回繰り返し、学習が完了します。\n",
        "\n",
        "\n",
        "これを実現するための簡素なイテレータを用意しました。for文で呼び出すと、ミニバッチを取得できます。\n",
        "\n",
        "\n",
        "《コード》"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqckuvYKlKiE"
      },
      "source": [
        "class GetMiniBatch:\n",
        "    \"\"\"\n",
        "    ミニバッチを取得するイテレータ\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : 次の形のndarray, shape (n_samples, n_features)\n",
        "      訓練データ\n",
        "    y : 次の形のndarray, shape (n_samples, 1)\n",
        "      正解値\n",
        "    batch_size : int\n",
        "      バッチサイズ\n",
        "    seed : int\n",
        "      NumPyの乱数のシード\n",
        "    \"\"\"\n",
        "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self._X = X[shuffle_index]\n",
        "        self._y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self._X[p0:p1], self._y[p0:p1]        \n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self._X[p0:p1], self._y[p0:p1]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTMSAqsTFRTh"
      },
      "source": [
        "このクラスをインスタンス化し、for文を使うことでミニバッチが取り出せます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aU-gjZuvmk5Q",
        "outputId": "af11a27a-1938-4f61-8bc1-0798db6e1469"
      },
      "source": [
        "get_mini_batch = GetMiniBatch(X_train, y_train, batch_size=20)\n",
        "print(len(get_mini_batch)) # 2400\n",
        "print(get_mini_batch[5]) # 5番目のミニバッチが取得できる\n",
        "for mini_X_train, mini_y_train in get_mini_batch:\n",
        "    # このfor文内でミニバッチが使える\n",
        "    pass"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2400\n",
            "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       ...,\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.]]), array([0, 7, 1, 1, 4, 8, 0, 0, 0, 6, 7, 5, 7, 3, 1, 8, 9, 9, 8, 1],\n",
            "      dtype=uint8))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y686rxuqmolU"
      },
      "source": [
        "__getitem__や__next__は__init__と同じ特殊メソッドの一種です。\n",
        "\n",
        "\n",
        "**学習**  \n",
        "ニューラルネットワークの学習はフォワードプロパゲーションとバックプロパゲションの繰り返しになります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6zShQCkmorj"
      },
      "source": [
        "## 【問題1】重みの初期値を決めるコードの作成\n",
        "ニューラルネットワークの各層の重みの初期値を決めるコードを作成してください。\n",
        "\n",
        "\n",
        "重みの初期値は様々な方法が提案されていますが、今回はガウス分布による単純な初期化を行います。バイアスに関しても同様です。\n",
        "\n",
        "\n",
        "以下のコードを参考にしてください。標準偏差の値sigmaはハイパーパラメータです。発展的な重みの初期化方法については次のSprintで扱います。\n",
        "\n",
        "\n",
        "《サンプルコード》\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nofElv2zmoxY"
      },
      "source": [
        "n_features = 784\n",
        "n_nodes1 = 400\n",
        "sigma = 0.01 # ガウス分布の標準偏差\n",
        "W1 = sigma * np.random.randn(n_features, n_nodes1)\n",
        "# W1: (784, 400)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5YEdHLBmo27"
      },
      "source": [
        "numpy.random.randn — NumPy v1.15 Manual  \n",
        "https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.randn.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0nTE3fqmo5N"
      },
      "source": [
        "## 【問題2】フォワードプロパゲーションの実装\n",
        "三層のニューラルネットワークの フォワードプロパゲーション を作成してください。以下の説明ではノード数は1層目は400、2層目は200としますが、変更しても構いません。\n",
        "\n",
        "\n",
        "各層の数式を以下に示します。今回はそれぞれの記号が表す配列が、実装上どのようなndarrayのshapeになるかを併記してあります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EuK6I11moz5"
      },
      "source": [
        "batch_size = 20 # バッチサイズ\n",
        "n_features = 784 # 特徴量の数\n",
        "n_nodes1 = 400 # 1層目のノード数\n",
        "n_nodes2 = 200 # 2層目のノード数\n",
        "n_output = 10 # 出力のクラス数（3層目のノード数）"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XcD-2sKmouI"
      },
      "source": [
        "「1層目」\n",
        "\n",
        "$$A_1 = X \\cdot W_1 + B_1$$\n",
        "\n",
        "X\n",
        "  : 特徴量ベクトル (batch_size, n_features)\n",
        "\n",
        "\n",
        "W\n",
        "1\n",
        " : 1層目の重み (n_features, n_nodes1)\n",
        "\n",
        "\n",
        "B\n",
        "1\n",
        " : 1層目のバイアス (n_nodes1,)\n",
        "\n",
        "\n",
        "A\n",
        "1\n",
        " : 出力 (batch_size, n_nodes1)\n",
        "\n",
        "\n",
        "「1層目の活性化関数」\n",
        "\n",
        "$$Z_1 = f(A_1)$$\n",
        "f\n",
        "(\n",
        ")\n",
        "  : 活性化関数\n",
        "\n",
        "\n",
        "Z\n",
        "1\n",
        " 出力 (batch_size, n_nodes1)\n",
        "\n",
        "\n",
        "「2層目」\n",
        "\n",
        "$$A_2 = Z_1 \\cdot W_2 + B_2$$\n",
        "\n",
        "W\n",
        "2\n",
        "  : 2層目の重み (n_nodes1, n_nodes2)\n",
        "\n",
        "\n",
        "B\n",
        "2\n",
        " : 2層目のバイアス (n_nodes2,)\n",
        "\n",
        "\n",
        "A\n",
        "2\n",
        " : 出力 (batch_size, n_nodes2)\n",
        "\n",
        "\n",
        "「2層目の活性化関数」\n",
        "\n",
        "$$Z_2 = f(A_2)$$\n",
        "\n",
        "f\n",
        "(\n",
        ")\n",
        " : 活性化関数\n",
        "\n",
        "\n",
        "Z\n",
        "2\n",
        " 出力 (batch_size, n_nodes2)\n",
        "\n",
        "\n",
        "「3層目（出力層）」\n",
        "\n",
        "$$A_3 = Z_2 \\cdot W_3 + B_3$$\n",
        "\n",
        "W\n",
        "3\n",
        "  : 3層目の重み (n_nodes2, n_output)\n",
        "\n",
        "\n",
        "B\n",
        "3\n",
        " : 3層目のバイアス (n_output,)\n",
        "\n",
        "\n",
        "A\n",
        "3\n",
        " : 出力 (batch_size, n_output)\n",
        "\n",
        "\n",
        "「3層目の活性化関数」\n",
        "\n",
        "$$Z_3 = softmax(A_3)$$\n",
        "s\n",
        "o\n",
        "f\n",
        "t\n",
        "m\n",
        "a\n",
        "x\n",
        "(\n",
        ")\n",
        " : ソフトマックス関数\n",
        "\n",
        "\n",
        "Z\n",
        "3\n",
        " 出力 (batch_size, n_output)\n",
        "\n",
        "\n",
        "Z\n",
        "3\n",
        " は各ラベル（0〜9）に対する確率の配列である。\n",
        "\n",
        "\n",
        "\n",
        "**活性化関数（フォワードプロバゲーション）**  \n",
        "\n",
        "活性化関数を作成し、フォワードプロパゲーションの中で使用します。切り替えられるように実装することを推奨しますが、片方でも構いません。\n",
        "\n",
        "\n",
        "「シグモイド関数」\n",
        "\n",
        "$$f(Z) = sigmoid(A) = \\frac{1}{1+exp(-A)}$$\n",
        "\n",
        "指数関数 \n",
        "e\n",
        "x\n",
        "p\n",
        "(\n",
        "−\n",
        "A\n",
        ")\n",
        " の計算はnp.expを使用してください。\n",
        "\n",
        "\n",
        "numpy.exp — NumPy v1.15 Manual  \n",
        "https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.exp.html\n",
        "\n",
        "\n",
        "「ハイパボリックタンジェント関数」\n",
        "\n",
        "\n",
        "次の数式で表されますが、np.tanhひとつで実現できます。\n",
        "\n",
        "$$f(Z) = tanh(A) = \\frac{exp(A) - exp(-A)}{exp(A) + exp(-A)}$$\n",
        "\n",
        "numpy.tanh — NumPy v1.15 Manual  \n",
        "https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.tanh.html\n",
        "\n",
        "\n",
        "＊現在ではこれらの代わりにReLUと呼ばれる活性化関数が一般的です。次のSprintで扱います。\n",
        "\n",
        "\n",
        "**ソフトマックス関数**  \n",
        "ソフトマックス関数を作成し、フォワードプロパゲーションの中で使用します。これも活性化関数の一種ですが、多クラス分類の出力層で使われる特性上、区別して扱われることが多いです。\n",
        "\n",
        "\n",
        "次の数式です。\n",
        "$$Z_{3\\_k} = \\frac{exp(A_{3\\_k})}{\\sum_{i=1}^{n_c}exp(A_{3\\_i})}$$\n",
        "\n",
        "Z\n",
        "3\n",
        "k\n",
        " : \n",
        "k\n",
        " 番目のクラスの確率ベクトル (batch_size,)\n",
        "\n",
        "\n",
        "A\n",
        "3\n",
        "k\n",
        " : \n",
        "k\n",
        " 番目のクラスにあたる前の層からのベクトル (batch_size,)\n",
        "\n",
        "\n",
        "n\n",
        "c\n",
        " : クラスの数、n_output。今回のMNISTでは10。\n",
        "\n",
        "\n",
        "分母は全てのクラスに相当する値を指数関数に通した上で足し合わせたものです。その中で、分子に \n",
        "k\n",
        " 番目のクラスを持ってくることで、 \n",
        "k\n",
        " 番目のクラスである確率が求まります。\n",
        "\n",
        "\n",
        "これを10クラス分計算し、合わせたものが \n",
        "Z\n",
        "3\n",
        " です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBT8EmxumooX"
      },
      "source": [
        "## 【問題3】交差エントロピー誤差の実装\n",
        "目的関数（損失関数）を作成します。\n",
        "\n",
        "\n",
        "多クラス分類の目的関数である交差エントロピー誤差 $L$ は次の数式です。\n",
        "\n",
        "\n",
        "$$L = - \\frac{1}{n_b}\\sum_{j}^{n_b}\\sum_{k}^{n_c}y_{jk} log(z_{3\\_jk})$$\n",
        "$y_{ij}$ : $j$ 番目のサンプルの $k$ 番目のクラスの正解ラベル（one-hot表現で0か1のスカラー）\n",
        "\n",
        "\n",
        "$z_{3_ij}$ : $j$ 番目のサンプルの $k$ 番目のクラスの確率（スカラー）\n",
        "\n",
        "\n",
        "$n_{b}$ : バッチサイズ、batch_size\n",
        "\n",
        "\n",
        "$n_{c}$ : クラスの数、n_output（今回のMNISTでは10）\n",
        "\n",
        "\n",
        "サンプル1つあたりの誤差が求まります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkdVoHnJmofV"
      },
      "source": [
        "## 【問題4】バックプロパゲーションの実装\n",
        "三層のニューラルネットワークのバックプロパゲーションを作成してください。確率的勾配降下法を行う部分です。\n",
        "\n",
        "\n",
        "数式を以下に示します。\n",
        "\n",
        "\n",
        "まず、i層目の重みとバイアスの更新式です。 \n",
        "W\n",
        "i\n",
        " と \n",
        "B\n",
        "i\n",
        " に対し、更新後の \n",
        "W\n",
        "′\n",
        "i\n",
        " と \n",
        "B\n",
        "′\n",
        "i\n",
        " は次の数式で求められます。\n",
        "\n",
        " $$W_i^{\\prime} = W_i - \\alpha \\frac{\\partial L}{\\partial W_i} \\\\\n",
        "B_i^{\\prime} = B_i - \\alpha \\frac{\\partial L}{\\partial B_i}$$\n",
        "\n",
        "$\\alpha$ : 学習率（層ごとに変えることも可能だが、基本的には全て同じとする）\n",
        "\n",
        "$\\frac{\\partial L}{\\partial W_i}$ : $W_i$ に関する損失 $L$ の勾配\n",
        "\n",
        "$\\frac{\\partial L}{\\partial B_i}$ : $B_i$ に関する損失 $L$ の勾配\n",
        "\n",
        "この更新方法はSprint3線形回帰やsprint4ロジスティック回帰における最急降下法と同様です。より効果的な更新方法が知られており、それは次のSprintで扱います。\n",
        "\n",
        "勾配 $\\frac{\\partial L}{\\partial W_i}$ や $\\frac{\\partial L}{\\partial B_i}$ を求めるために、バックプロパゲーションを行います。以下の数式です。ハイパボリックタンジェント関数を使用した例を載せました。シグモイド関数の場合の数式はその後ろにあります。\n",
        "\n",
        "「3層目」\n",
        "\n",
        "\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial A_3} = Z_{3} - Y\\\\\n",
        "\\frac{\\partial L}{\\partial B_3} = \\sum_{j}^{n_b}\\frac{\\partial L}{\\partial A_{3\\_j}}\\\\\n",
        "\\frac{\\partial L}{\\partial W_3} = Z_{2}^{T}\\cdot \\frac{\\partial L}{\\partial A_3}\\\\\n",
        "\\frac{\\partial L}{\\partial Z_2} = \\frac{\\partial L}{\\partial A_3} \\cdot W_3^T$$\n",
        "\n",
        "$\\frac{\\partial L}{\\partial A_3}$ : $A_3$ に関する損失 $L$ の勾配 (1, n_output)\n",
        "\n",
        "$\\frac{\\partial L}{\\partial B_3}$ : $B_3$ に関する損失 $L$ の勾配 (1, n_output)\n",
        "\n",
        "$\\frac{\\partial L}{\\partial W_3}$ : $W_3$ に関する損失 $L$ の勾配 (n_nodes2, n_output)\n",
        "\n",
        "$\\frac{\\partial L}{\\partial Z_2}$ : $Z_2$ に関する損失 $L$ の勾配 (1, n_nodes2)\n",
        "\n",
        "$Z_{3_j} : $j$ 番目のサンプルの3層目の出力 (1, n_output)\n",
        "\n",
        "$Y_j$ : $j$ 番目のサンプルの正解ラベル (1, n_output)\n",
        "\n",
        "$Z_{2_j}$ :$j$ 番目のサンプルの2層目の出力 (n_nodes2, 1)\n",
        "\n",
        "$W_3$ : 3層目の重み (n_nodes2, n_output)\n",
        "\n",
        "「2層目」\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial A_2} = \\frac{\\partial L}{\\partial Z_2} \\odot \\{1-tanh^2(A_{2})\\}\\\\\n",
        "\\frac{\\partial L}{\\partial B_2} = \\sum_{j}^{n_b}\\frac{\\partial L}{\\partial A_{2\\_j}}\\\\\n",
        "\\frac{\\partial L}{\\partial W_2} = Z_{1}^T \\cdot \\frac{\\partial L}{\\partial A_2}\\\\\n",
        "\\frac{\\partial L}{\\partial Z_1} = \\frac{\\partial L}{\\partial A_2} \\cdot W_2^T$$\n",
        "\n",
        "$\\frac{\\partial L}{\\partial A_2}$ : $A_2$ に関する損失 $L$ の勾配 (1, n_nodes2)\n",
        "\n",
        "$\\frac{\\partial L}{\\partial B_2}$ : $B_2$ に関する損失 $L$ の勾配 (1, n_nodes2)\n",
        "\n",
        "$\\frac{\\partial L}{\\partial W_2}$ : $W_2$ に関する損失 $L$ の勾配 (n_nodes1, n_nodes2)\n",
        "\n",
        "$\\frac{\\partial L}{\\partial Z_2}$ : $Z_2$ に関する損失 $L$ の勾配 (1, n_nodes2)\n",
        "\n",
        "$Z_{2_j}$ : $j$ 番目のサンプルの2層目の出力 (1, n_nodes2)\n",
        "\n",
        "$A_{2_j}$ : $j$ 番目のサンプルの2層目の活性化関数の出力 (1, n_nodes2)\n",
        "\n",
        "$Z_{1_j}$ : $j$ 番目のサンプルの1層目の出力 (n_nodes1, 1)\n",
        "\n",
        "$W_2$ : 2層目の重み (n_nodes1, n_nodes2)\n",
        "\n",
        "「1層目」\n",
        "\n",
        "$$frac{\\partial L}{\\partial A_1} = \\frac{\\partial L}{\\partial Z_1} \\odot \\{1-tanh^2(A_{1})\\}\\\\\n",
        "\\frac{\\partial L}{\\partial B_1} = \\sum_{j}^{n_b}\\frac{\\partial L}{\\partial A_{1\\_j}}\\\\\n",
        "\\frac{\\partial L}{\\partial W_1} = X^T \\cdot \\frac{\\partial L}{\\partial A_1}$$\n",
        "\n",
        "\n",
        "$\\frac{\\partial L}{\\partial A_1}$ : $A_1$ に関する損失 $L$ の勾配 (1, n_nodes1)\n",
        "\n",
        "$\\frac{\\partial L}{\\partial B_1}$ : $B_1$ に関する損失 $L$ の勾配 (1, n_nodes1)\n",
        "\n",
        "$\\frac{\\partial L}{\\partial W_1}$ : $W_1$ に関する損失 $L$ の勾配 (n_features, n_nodes1)\n",
        "\n",
        "$\\frac{\\partial L}{\\partial Z_1}$ : $Z_1$ に関する損失 $L$ の勾配 (1, n_nodes1)\n",
        "\n",
        "$Z_{1_j}$ : $j$ 番目のサンプルの1層目の出力 (1, n_nodes2)\n",
        "\n",
        "$A_{1_j}$ : $j$ 番目のサンプルの1層目の活性化関数の出力 (1, n_nodes1)\n",
        "\n",
        "$X_j$ : $j$ 番目のサンプル (n_features, 1)\n",
        "\n",
        "$W_1$ : 1層目の重み (n_features, n_nodes1)\n",
        "\n",
        "《補足》\n",
        "\n",
        "\n",
        "活性化関数にシグモイド関数を使用した場合は、次のようになります。\n",
        "\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial A_2} = \\frac{\\partial L}{\\partial Z_2} \\odot  \\{1-sigmoid(A_{2})\\}sigmoid(A_{2})\n",
        "\\\\\n",
        "\\frac{\\partial L}{\\partial A_1} = \\frac{\\partial L}{\\partial Z_1} \\odot  \\{1-sigmoid(A_{1})\\}sigmoid(A_{1})$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyvfkqZ-mFBr"
      },
      "source": [
        "## 【問題5】推定\n",
        "推定を行うメソッドを作成してください。\n",
        "\n",
        "\n",
        "フォワードプロパゲーションによって出力された10個の確率の中で、最も高いものはどれかを判定します。\n",
        "\n",
        "\n",
        "numpy.argmax — NumPy v1.17 Manual  \n",
        "https://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snRzAz6koVmu"
      },
      "source": [
        "## 解答用クラスコード"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ4hjFDzoTtH"
      },
      "source": [
        "class ScratchSimpleNeuralNetrowkClassifier():\n",
        "    \"\"\"\n",
        "    シンプルな三層ニューラルネットワーク分類器\n",
        "    Parameters\n",
        "    ----------\n",
        "    Attributes\n",
        "    ----------\n",
        "    \"\"\"\n",
        "    def __init__(self, lr=0.01, bias=1, sigma=0.01, epoch_num=1, batch_size=100, n_features=784, n_nodes1=400, n_nodes2=200, n_output=10, verbose = True):\n",
        "        # self.iter = num_iter num_iter=10, \n",
        "        self.lr = lr\n",
        "        self.bias = bias\n",
        "        self.epoch = epoch_num\n",
        "        self.batch_size = batch_size\n",
        "        self.n_features = n_features\n",
        "        self.n_nodes1 = n_nodes1\n",
        "        self.n_nodes2 = n_nodes2\n",
        "        self.n_output = n_output\n",
        "        self.verbose = verbose\n",
        "        self.loss = np.zeros(self.epoch)\n",
        "        self.val_loss = np.zeros(self.epoch)\n",
        "        self.acc = np.zeros(self.epoch)\n",
        "        self.acc_val = np.zeros(self.epoch)\n",
        "\n",
        "## 問題１（解答）-----------------------------------------------------------------------------\n",
        "        sigma = sigma\n",
        "        self.w1 = sigma * np.random.randn(self.n_features, self.n_nodes1)\n",
        "        self.b1 = sigma * np.random.randn(1, self.n_nodes1)\n",
        "\n",
        "        self.w2 = sigma * np.random.randn(self.n_nodes1, self.n_nodes2)\n",
        "        self.b2 = sigma * np.random.randn(1, self.n_nodes２)\n",
        "\n",
        "        self.w3 = sigma * np.random.randn(self.n_nodes2, self.n_output)\n",
        "        self.b3 = sigma * np.random.randn(1, self.n_output)\n",
        "## 問題2（解答）-----------------------------------------------------------------------------\n",
        "    #ソフトマックス関数\n",
        "    def _softmax(self, x):\n",
        "      a = np.exp(x) / np.sum(np.exp(x), axis = 1).reshape(-1,1)\n",
        "      return a\n",
        "\n",
        "    # シグモイド関数\n",
        "    def _sigmoid(self,z):\n",
        "        return 1 / (1+np.exp(-z))\n",
        "\n",
        "    # フォワードプロパゲーションの実装\n",
        "    def _forward_propagation(self, x):\n",
        "      self.a1 = x@self.w1+self.b1\n",
        "      self.z1 = np.tanh(self.a1)\n",
        "\n",
        "      self.a2 = self.z1@self.w2+self.b2\n",
        "      self.z2 = np.tanh(self.a2)\n",
        "\n",
        "      self.a3 = self.z2@self.w3+self.b3\n",
        "      self.z3 = self._softmax(self.a3)\n",
        "\n",
        "      # print(\"a1\\n\", self.a1.shape, \"\\nz1\\n\", self.z1.shape)\n",
        "      # print(\"a2\\n\", self.a2.shape, \"\\nz2\\n\", self.z2.shape)\n",
        "      # print(\"a3\\n\", self.a3.shape, \"\\nz3\\n\", self.z3.shape)\n",
        "\n",
        "      return self.z3\n",
        "## 問題3（解答）-----------------------------------------------------------------------------\n",
        "    def _cross_entropy_error(self, y, t):\n",
        "      return -np.mean(t * np.log(y + 1e-7))\n",
        "## 問題4（解答）------------------------------------------------------------------------------\n",
        "    def _back_propagation(self, x, y):\n",
        "      gt_a3 = self.z3 -y\n",
        "      gt_b3 = np.sum(gt_a3, axis=0)\n",
        "      gt_w3 = (self.z2.T)@gt_a3\n",
        "      gt_z2 = gt_a3@(self.w3.T)\n",
        "      self.w3 -= self.lr*gt_w3\n",
        "      self.b3 -= self.lr*gt_b3\n",
        "\n",
        "      gt_a2 = gt_z2*(1-np.tanh(self.a2)**2)\n",
        "      gt_b2 = np.sum(gt_a2, axis=0)\n",
        "      gt_w2 = (self.z1.T)@gt_a2\n",
        "      gt_z1 = gt_a2@(self.w2.T)\n",
        "      self.w2 -= self.lr*gt_w2\n",
        "      self.b2 -= self.lr*gt_b2\n",
        "\n",
        "      gt_a1 = gt_z1*(1-np.tanh(self.a1)**2)\n",
        "      gt_b1 = np.sum(gt_a1, axis=0)\n",
        "      gt_w1 = (x.T)@gt_a1\n",
        "      self.w1 -= self.lr*gt_w1\n",
        "      self.b1 -= self.lr*gt_b1\n",
        "## 問題6（解答）-----------------------------------------------------------------------------\n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        \"\"\"\n",
        "        ニューラルネットワーク分類器を学習する。\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : 次の形のndarray, shape (n_samples, n_features)\n",
        "            訓練データの特徴量\n",
        "        y : 次の形のndarray, shape (n_samples, )\n",
        "            訓練データの正解値\n",
        "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
        "            検証データの特徴量\n",
        "        y_val : 次の形のndarray, shape (n_samples, )\n",
        "            検証データの正解値\n",
        "        \"\"\"\n",
        "        for i in range(self.epoch):\n",
        "          # ミニバッチの取り出し\n",
        "          get_mini_batch = GetMiniBatch(X, y, self.batch_size)\n",
        "          for mini_X_train, mini_y_train in get_mini_batch:\n",
        "            y_hat = self._forward_propagation(mini_X_train)\n",
        "            loss = self._cross_entropy_error(y_hat, mini_y_train)\n",
        "            self._back_propagation(mini_X_train, mini_y_train)\n",
        "\n",
        "            # print(\"x_batch\", mini_X_train.shape)\n",
        "            # print(\"y_batch\", mini_y_train)\n",
        "            # print(\"loss\\n\", loss)\n",
        "            # print(\"parama W\\n\", self.w1, \"parama b\\n\", self.b1)\n",
        "\n",
        "          self.loss[i] += loss\n",
        "          # self.acc[i] = accuracy_score(np.argmax(y, axis=1), np.argmax(y_hat, axis=1))\n",
        "\n",
        "          if (type(X_val) != bool):\n",
        "            self.val = 1\n",
        "            y_hat_val = self._forward_propagation(x_val)\n",
        "            loss_val = self._cross_entropy_error(y_hat_val, y_val)\n",
        "            self.val_loss[i] += loss_val\n",
        "\n",
        "            # self.acc_val[i] = accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_hat_val, axis=1))\n",
        "\n",
        "          # verboseをTrueにした際は学習過程を出力\n",
        "          if self.verbose :\n",
        "            print(f\"--{i+1}回目~loss~-------\\n{self.loss[i]}\")\n",
        "            print(f\"--{i+1}回目~loss_val~---\\n{self.val_loss[i]}\")\n",
        "            # print(f'epoch:{self.epoch:>3} loss:{self.loss:>8,.3f}')\n",
        "\n",
        "## 問題5（解答）------------------------------------------------------------------------------\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        ニューラルネットワーク分類器を使い推定する。\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : 次の形のndarray, shape (n_samples, n_features)\n",
        "            サンプル\n",
        "        Returns\n",
        "        -------\n",
        "            次の形のndarray, shape (n_samples, 1)\n",
        "            推定結果\n",
        "        \"\"\"\n",
        "        y_hat = self._forward_propagation(X)\n",
        "        return np.argmax(y_hat, axis=1)\n",
        "# 問題7（解答）-------------------------------------------------------------------------------    \n",
        "    def plot_cost(self):\n",
        "        \"\"\"\n",
        "        損失の推移をグラフ化する。    \n",
        "        検証用データが入力されていれば、学習用と検証用の損失推移を重ねてグラフ化\n",
        "        \"\"\"\n",
        "        plt.title(\"Num_of_Iteration vs Loss\")\n",
        "        plt.xlabel(\"Num_of_Iteration\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        a = range(self.epoch)\n",
        "        plt.plot(range(1, self.epoch+1), self.loss, color=\"b\", label=\"train_loss\")\n",
        "        if self.val ==1:\n",
        "            plt.plot(range(1, self.epoch+1), self.val_loss, color=\"orange\", label=\"val_loss\")\n",
        "        plt.grid()\n",
        "        plt.legend()\n",
        "## -----------------------------------------------------------------------------------------------\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQFUifmAn2dR"
      },
      "source": [
        "# 4.検証\n",
        "\n",
        "## 【問題6】学習と推定\n",
        "MNISTのデータを学習・推定し、Accuracyを計算してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYI1WuP5ZxeS"
      },
      "source": [
        "### 6.1.1（前処理）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GjEBr6YvRHx",
        "outputId": "eb26b089-6fd1-4d3b-b16e-2643f1efab3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "print(X_train.shape)\n",
        "print(X_train.dtype)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "uint8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyScR91DaJJs",
        "outputId": "8a190967-6b47-404b-f03f-8ae63fe53dfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 平滑化（flatten）\n",
        "X_train_fltten = X_train.reshape(-1, 784)\n",
        "X_test_fltten = X_test.reshape(-1, 784)\n",
        "print(X_train_fltten.shape)\n",
        "print(X_train_fltten.dtype)\n",
        "print(X_train_fltten)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "uint8\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re2neNUhZ8QZ",
        "outputId": "d730c71c-85be-4d09-b23f-a9e1b77569d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# float化と0or1処理\n",
        "X_train_flt = X_train_fltten.astype(np.float)\n",
        "X_test_flt = X_test_fltten.astype(np.float)\n",
        "X_train_flt /= 255\n",
        "X_test_flt /= 255\n",
        "print(X_train_flt.max()) # 1.0\n",
        "print(X_train_flt.min()) # 0.0"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9LTOzOKZ7Ql",
        "outputId": "a827a384-9b8d-429d-a462-17e6fceb59a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# one hot処理\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
        "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
        "print(y_train.shape) # (60000,)\n",
        "print(y_train_one_hot.shape) # (60000, 10)\n",
        "print(y_train_one_hot.dtype) # float64\n",
        "\n",
        "y_test_one_hot.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000,)\n",
            "(60000, 10)\n",
            "float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOBCgxrC5nMk",
        "outputId": "8dcf409e-6eba-4158-ff76-93ee59c124a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# train, testの分割\n",
        "x_train, x_val, y_train_one_hot, y_val_one_hot = train_test_split(X_train_flt, y_train_one_hot, test_size=0.2)\n",
        "print(x_train.shape) # (48000, 784)\n",
        "print(x_val.shape) # (12000, 784)\n",
        "print(y_train_one_hot.shape) # (48000, 784)\n",
        "print(y_val_one_hot.shape) # (12000, 784)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48000, 784)\n",
            "(12000, 784)\n",
            "(48000, 10)\n",
            "(12000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEDXmFIalTDB"
      },
      "source": [
        "### 6.2.1（解答）学習"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUqEl8XDf9av",
        "outputId": "7b9debf0-9ce0-42c1-c868-8c546daefa8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "snc = ScratchSimpleNeuralNetrowkClassifier(lr=0.001, bias=1, sigma=0.01, epoch_num=15)\n",
        "snc.fit(x_train, y_train_one_hot, x_val, y_val_one_hot)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--1回目~loss~-------\n",
            "0.03702156913058171\n",
            "--1回目~loss_val~---\n",
            "0.04193225947547966\n",
            "--2回目~loss~-------\n",
            "0.029357492374479703\n",
            "--2回目~loss_val~---\n",
            "0.032754327710891165\n",
            "--3回目~loss~-------\n",
            "0.02482854403236712\n",
            "--3回目~loss_val~---\n",
            "0.028485053719548386\n",
            "--4回目~loss~-------\n",
            "0.022297214923923316\n",
            "--4回目~loss_val~---\n",
            "0.024997069746708015\n",
            "--5回目~loss~-------\n",
            "0.02060201963065515\n",
            "--5回目~loss_val~---\n",
            "0.022076318724856117\n",
            "--6回目~loss~-------\n",
            "0.019360193958840068\n",
            "--6回目~loss_val~---\n",
            "0.01964230965878367\n",
            "--7回目~loss~-------\n",
            "0.018488334358816326\n",
            "--7回目~loss_val~---\n",
            "0.01769637762082159\n",
            "--8回目~loss~-------\n",
            "0.017891768341487216\n",
            "--8回目~loss_val~---\n",
            "0.01614296210661129\n",
            "--9回目~loss~-------\n",
            "0.017430137358424566\n",
            "--9回目~loss_val~---\n",
            "0.014887010199257197\n",
            "--10回目~loss~-------\n",
            "0.0169689176135819\n",
            "--10回目~loss_val~---\n",
            "0.013862757868151655\n",
            "--11回目~loss~-------\n",
            "0.01643429583480173\n",
            "--11回目~loss_val~---\n",
            "0.013023603188591994\n",
            "--12回目~loss~-------\n",
            "0.015806517103018065\n",
            "--12回目~loss_val~---\n",
            "0.012332284938211393\n",
            "--13回目~loss~-------\n",
            "0.015100731766136083\n",
            "--13回目~loss_val~---\n",
            "0.01175757929270587\n",
            "--14回目~loss~-------\n",
            "0.014350884949435991\n",
            "--14回目~loss_val~---\n",
            "0.011273682107222143\n",
            "--15回目~loss~-------\n",
            "0.013592131231973514\n",
            "--15回目~loss_val~---\n",
            "0.010860843397035209\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc_eql2SnInO"
      },
      "source": [
        "### 6.3.1（解答）推定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeVTAbLgnKH6",
        "outputId": "f9460b23-2df5-4fb6-9cb2-01e25a5637f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "a = snc.predict(X_test_flt)\n",
        "print(a[:100])"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7 2 1 0 4 1 4 9 6 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7\n",
            " 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9\n",
            " 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WM26GsWuaPHD",
        "outputId": "02268593-427c-464b-ce3b-0318e618c495",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test,a)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9663"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPSLuiLzajRM",
        "outputId": "abcf3b55-6aac-4923-f42d-20559dcd97f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(y_test[:100])"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7\n",
            " 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9\n",
            " 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ68sUdGn9mZ"
      },
      "source": [
        "## 【問題7】学習曲線のプロット\n",
        "学習曲線をプロットしてください。\n",
        "\n",
        "\n",
        "ニューラルネットワークは過学習が発生しやすいため、学習曲線の確認が重要です。訓練データと検証データに対するエポックごとの損失（交差エントロピー誤差）を記録できるようにする必要があります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IoxGXYKGA1y",
        "outputId": "d816fd6c-d4a5-4ae9-e44b-8d60256b811b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "snc.plot_cost()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_5IT8NyoBG5"
      },
      "source": [
        "## 【問題8】（アドバンス課題）誤分類の確認　未回答\n",
        "誤分類した画像はどのようなものだったかを確認してください。推定値を用意し、以下のコードを実行してください。\n",
        "\n",
        "\n",
        "《コード》"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "oLEV1PKVoFXm",
        "outputId": "e2d558ee-b9cc-4091-a3aa-8d0863eddfaa"
      },
      "source": [
        "\"\"\"\n",
        "語分類結果を並べて表示する。画像の上の表示は「推定結果/正解」である。\n",
        "\n",
        "Parameters:\n",
        "----------\n",
        "y_pred : 推定値のndarray (n_samples,)\n",
        "y_val : 検証データの正解ラベル(n_samples,)\n",
        "X_val : 検証データの特徴量（n_samples, n_features)\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "num = 36 # いくつ表示するか\n",
        "\n",
        "true_false = y_pred==y_val\n",
        "false_list = np.where(true_false==False)[0].astype(np.int)\n",
        "if false_list.shape[0] < num:\n",
        "    num = false_list.shape[0]\n",
        "fig = plt.figure(figsize=(6, 6))\n",
        "fig.subplots_adjust(left=0, right=0.8,  bottom=0, top=0.8, hspace=1, wspace=0.5)\n",
        "for i in range(num):\n",
        "    ax = fig.add_subplot(6, 6, i + 1, xticks=[], yticks=[])\n",
        "    ax.set_title(\"{} / {}\".format(y_pred[false_list[i]],y_val[false_list[i]]))\n",
        "    ax.imshow(X_val.reshape(-1,28,28)[false_list[i]], cmap='gray')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-721920803ea1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m36\u001b[0m \u001b[0;31m# いくつ表示するか\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtrue_false\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mfalse_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_false\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfalse_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McaGjuXZoIi5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}