{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sprint10 深層学習スクラッチ ディープニューラルネットワーク.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN9tl25Zqox8XPXhwM2/6U8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/T-Sawao/diveintocode-ml/blob/master/term2_sprint10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1X2D195xUqRu"
      },
      "source": [
        "## ベースクラス"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfEovpOnkz6h"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as setattr\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0j5MQlOyQ08L"
      },
      "source": [
        "class ScratchDeepNeuralNetworkClassifier():\n",
        "  def __init__(self, bias=1, epoch_num=1, batch_size=20, verbose=True):\n",
        "        self.bias = bias\n",
        "        self.epoch = epoch_num\n",
        "        self.batch_size = batch_size\n",
        "        self.verbose = verbose\n",
        "\n",
        "  def fit(self, X, y, X_val=None, y_val=None, sigma=0.01, lr=0.01,  n_nodes1=400, n_nodes2=200, n_output=10):\n",
        "        self.sigma = sigma\n",
        "        self.lr = lr\n",
        "        self.n_nodes1 = n_nodes1\n",
        "        self.n_nodes2 = n_nodes2\n",
        "        self.n_output = n_output\n",
        "\n",
        "        self.loss = np.zeros(self.epoch)\n",
        "        self.val_loss = np.zeros(self.epoch)\n",
        "        \n",
        "        # 最適化クラスの呼び出し  \n",
        "        optimizer = SGD(self.lr)\n",
        "\n",
        "        # 全結合層にインスタンスを渡す\n",
        "        self.FC1 = FC(self.n_features, self.n_nodes1, SimpleInitializer(self.sigma), optimizer)\n",
        "        self.activation1 = Tanh()\n",
        "        self.FC2 = FC(self.n_nodes1, self.n_nodes2, SimpleInitializer(self.sigma), optimizer)\n",
        "        self.activation2 = Tanh()\n",
        "        self.FC3 = FC(self.n_nodes2, self.n_output, SimpleInitializer(self.sigma), optimizer)\n",
        "        self.activation3 = Softmax()\n",
        "\n",
        "        # エポック数分の学習\n",
        "        for i in range(self.epoch):\n",
        "          # ミニバッチの作成\n",
        "          get_mini_batch = GetMiniBatch(X, y, self.batch_size)\n",
        "          # 1エポック（全バッチ）の学習\n",
        "          for X, Y in get_mini_batch:\n",
        "\n",
        "            # フォワードプロパゲーションの実行\n",
        "            A1 = self.FC1.forward(X)\n",
        "            Z1 = self.activation1.forward(A1)\n",
        "            A2 = self.FC2.forward(Z1)\n",
        "            Z2 = self.activation2.forward(A2)\n",
        "            A3 = self.FC3.forward(Z2)\n",
        "            Z3 = self.activation3.forward(A3)\n",
        "\n",
        "            # バックプロパゲーションの実行\n",
        "            dA3 = self.activation3.backward(Z3, Y) # 交差エントロピー誤差とソフトマックスを合わせている\n",
        "            dZ2 = self.FC3.backward(dA3)\n",
        "            dA2 = self.activation2.backward(dZ2)\n",
        "            dZ1 = self.FC2.backward(dA2)\n",
        "            dA1 = self.activation1.backward(dZ1)\n",
        "            dZ0 = self.FC1.backward(dA1) # dZ0は使用しない\n",
        "\n",
        "          self.loss[i] += loss\n",
        "\n",
        "          if (type(X_val) != bool):\n",
        "            self.val = 1\n",
        "            y_hat_val = self._forward_propagation(x_val)\n",
        "            loss_val = self._cross_entropy_error(y_hat_val, y_val)\n",
        "            self.val_loss[i] += loss_val\n",
        "\n",
        "            # self.acc_val[i] = accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_hat_val, axis=1))\n",
        "            # verboseをTrueにした際は学習過程を出力\n",
        "          if self.verbose :\n",
        "            print(f\"--{i+1}回目~loss~-------\\n{self.loss[i]}\")\n",
        "            print(f\"--{i+1}回目~loss_val~---\\n{self.val_loss[i]}\")\n",
        "            # print(f'epoch:{self.epoch:>3} loss:{self.loss:>8,.3f}')\n",
        "\n",
        "## 問題5（解答）------------------------------------------------------------------------------\n",
        "    def predict(self, X):\n",
        "        y_hat = self._forward_propagation(X)\n",
        "        return np.argmax(y_hat, axis=1)\n",
        "# 問題7（解答）-------------------------------------------------------------------------------    \n",
        "    def plot_cost(self):\n",
        "        plt.title(\"Num_of_Iteration vs Loss\")\n",
        "        plt.xlabel(\"Num_of_Iteration\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        a = range(self.epoch)\n",
        "        plt.plot(range(1, self.epoch+1), self.loss, color=\"b\", label=\"train_loss\")\n",
        "        if self.val ==1:\n",
        "            plt.plot(range(1, self.epoch+1), self.val_loss, color=\"orange\", label=\"val_loss\")\n",
        "        plt.grid()\n",
        "        plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPfEot4nU3UK"
      },
      "source": [
        "## 全結合層のクラス"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1IyVS8VU0BW"
      },
      "source": [
        "class FC:\n",
        "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
        "        self.optimizer = optimizer\n",
        "        self.n_nodes1 = n_nodes1\n",
        "        self.n_nodes2 = n_nodes2\n",
        "        self.W = initializer.W(self.n_nodes1, self.n_nodes2)\n",
        "        self.B = initializer.B(1, self.n_nodes1)\n",
        "        # 初期化\n",
        "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
        "\n",
        "    # フォワードプロパゲーション時の処理\n",
        "    def forward(self, X):\n",
        "      out = X@self.W+self.B\n",
        "      return out\n",
        "    \n",
        "    # バックプロパゲーション時の処理\n",
        "    def backward(self, dA):\n",
        "      dZ = dA@(self.w.T)\n",
        "      dW = (dz.T)@dA\n",
        "      dB = np.sum(dA, axis=0)\n",
        "      \n",
        "      # 更新\n",
        "      self.W = self.optimizer.update(dW, self.W)\n",
        "      self.B = self.optimizer.update(dB, self.B)\n",
        "      return dZ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIvwIyo8U3sJ"
      },
      "source": [
        "### 初期化クラス"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrm7OHgNU2Ki"
      },
      "source": [
        "# SimpleInitializer ------------------------------------------------------------\n",
        "class SimpleInitializer:\n",
        "    def __init__(self, sigma):\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        W = sigma * np.random.randn(n_nodes1, n_nodes2)\n",
        "        return W\n",
        "\n",
        "    def B(self, n_nodes2):\n",
        "        B = sigma * np.random.randn(1, n_nodes2)\n",
        "        return B\n",
        "\n",
        "# XavierInitializer ------------------------------------------------------------\n",
        "class XavierInitializer:\n",
        "    def __init__(self, Xavier):\n",
        "        self.Xavier = Xavier\n",
        "\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        W = np.random.randn(n_nodes1, n_nodes2) * np.sqrt(1.0 / n_nodes1)\n",
        "        return W\n",
        "\n",
        "    def B(self, n_nodes2):\n",
        "        B = np.random.randn(1, n_nodes2) * np.sqrt(1.0 / 1.0)\n",
        "        return B\n",
        "\n",
        "# He-----------------------------------------------------------------------------\n",
        "class HeInitializer:\n",
        "    def __init__(self, He):\n",
        "        self.He = He\n",
        "\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        W = p.random.randn(n_nodes1, n_nodes2) * np.sqrt(2.0 / n_nodes1)\n",
        "        return W\n",
        "\n",
        "    def B(self, n_nodes2):\n",
        "        B = p.random.randn(1, n_nodes2) * np.sqrt(2.0 / 1)\n",
        "        return B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Khu9OKHYU4SQ"
      },
      "source": [
        "## 最適化クラス"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXMTjo1SVLrB"
      },
      "source": [
        "# SGD---------------------------------------------\n",
        "class SGD:\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr\n",
        "        \n",
        "    def update(self, dWorB, WorB):\n",
        "      self.WorB = WorB\n",
        "      self.WorB -= self.lr*dWorB\n",
        "      return self.WorB\n",
        "\n",
        "# AdaGrad----------------------------------------\n",
        "class  AdaGrad:\n",
        "    def __init__(self, lr=0.01):\n",
        "        self.lr = lr\n",
        "        self.h = None\n",
        "\n",
        "    def update(self, dWorB, WorB):\n",
        "      self.WorB = WorB\n",
        "      self.WorB -= self.lr*dWorB\n",
        "      \n",
        "      if self.h is None:\n",
        "        self.h = {}\n",
        "        for key, val in WorB.items():\n",
        "            self.h[key] = np.zeros_like(val)\n",
        "\n",
        "      for key in WorB.keys():\n",
        "          self.h[key] += dWorB[key] * dWorB[key]\n",
        "          WorB[key] -= self.lr * dWorB[key] / (np.sqrt(self.h[key]) + 1e-7)\n",
        "      return self.WorB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFvs3cBEWDN9"
      },
      "source": [
        "### 活性化関数クラス"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bn2HG37fU2g8"
      },
      "source": [
        "# ソフトマックス関数のクラス----------------------------------------------\n",
        "class Softmax:\n",
        "  def __init__(self):\n",
        "\n",
        "    # forward時の処理\n",
        "    def forward(self, X):\n",
        "      y_hat = np.exp(X) / np.sum(np.exp(X), axis = 1).reshape(-1,1)\n",
        "      return y_hat\n",
        "\n",
        "    # backward時の処理\n",
        "    def backward(self, X, Y):\n",
        "      loss = self._cross_entropy_error(self, X, Y)\n",
        "      dA3 = X -Y\n",
        "      return dA3\n",
        "\n",
        "    # 交差エントロピー誤差の関数\n",
        "    def _cross_entropy_error(self, X, Y):\n",
        "      return -np.mean(Y * np.log(X + 1e-7))\n",
        "\n",
        "# ReLU関数のクラス----------------------------------------------\n",
        "class ReLU:\n",
        "  def __init__(self):\n",
        "\n",
        "    # forward時の処理\n",
        "    def forward(self, X):\n",
        "      return np.maximum(0, X)\n",
        "\n",
        "    # backward時の処理\n",
        "    def backward(self, X, Y):\n",
        "      loss = self._cross_entropy_error(self, X, Y)\n",
        "      return np.maximum(0, X)\n",
        "\n",
        "    # 交差エントロピー誤差の関数\n",
        "    def _cross_entropy_error(self, X, Y):\n",
        "      return -np.mean(Y * np.log(X + 1e-7))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZefiE4VU2AH"
      },
      "source": [
        "## 前処理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmRXmaCpY4Ps"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# 平滑化（flatten）\n",
        "X_train_fltten = X_train.reshape(-1, 784)\n",
        "X_test_fltten = X_test.reshape(-1, 784)\n",
        "\n",
        "# float化と0or1処理\n",
        "X_train_flt = X_train_fltten.astype(np.float)\n",
        "X_test_flt = X_test_fltten.astype(np.float)\n",
        "X_train_flt /= 255\n",
        "X_test_flt /= 255\n",
        "\n",
        "# one hot処理\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
        "y_test_one_hot = enc.transform(y_test[:, np.newaxis])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCLWp-O9fMn1"
      },
      "source": [
        "# train, testの分割\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train_one_hot, y_val_one_hot = train_test_split(X_train_flt, y_train_one_hot, test_size=0.2)\n",
        "print(\"x_train\",x_train.shape, \"x_val\", x_val.shape, \"y_train_one_hot.shape\", y_train_one_hot.shape, \"y_val_one_hot\", y_val_one_hot.shape) # (48000, 784)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_GXPVTGlrH3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}