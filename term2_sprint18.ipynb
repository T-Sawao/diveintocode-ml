{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "term2_sprint18.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1dmd-ZcUVTQAQqShCSZi6mNHh94G7FV3F",
      "authorship_tag": "ABX9TyP1k8rEfQJJfm1+xe7vXOwo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/T-Sawao/diveintocode-ml3/blob/main/term2_sprint18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7-PacnuRZfn"
      },
      "source": [
        "# term2_sprint18.ipynb データセットの作成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dt9dXxm9HRTI"
      },
      "source": [
        "## 1.このSprintについて\n",
        "\n",
        "### Sprintの目的\n",
        "- データセットを作成し学習する\n",
        "- データ拡張を行う\n",
        "\n",
        "# どのように学ぶか\n",
        "自作のデータセットを作り、さらにデータ拡張も行なっていきます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kzc_kin7HRGG"
      },
      "source": [
        "### 【問題1】自作データセットでの分類の学習\n",
        "自作のデータセットに対して分類問題を解いてください。任意の実装を使用してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDdCHZGlVgAK"
      },
      "source": [
        "### 1.1.1（解答）前処理_学習用データの作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhiyr7nQRRVO"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense, Dropout\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.optimizers import Adagrad\n",
        "from keras.optimizers import Adam\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5_OY9SzXw_8"
      },
      "source": [
        "import os\n",
        "\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks')\n",
        "\n",
        "# カレントディレクトリの取得\n",
        "print(os.getcwd())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GBkgQFspcTl"
      },
      "source": [
        "cd term2_sprint18_data/img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHqc3Iq-pcIX"
      },
      "source": [
        "rm -r .ipynb_checkpoints/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaGCgV4_pb9s"
      },
      "source": [
        "cd cat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYw5F8bmp6O8"
      },
      "source": [
        "rm -r .ipynb_checkpoints/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aspv1UYyp_7v"
      },
      "source": [
        "cd ../../../"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPJ3v1jjRU7s"
      },
      "source": [
        "# 学習用のデータを作る.\n",
        "image_list = []\n",
        "label_list = []\n",
        "\n",
        "# ./data/train 以下のorange,appleディレクトリ以下の画像を読み込む。\n",
        "for dir in os.listdir(\"term2_sprint18_data/img/\"):\n",
        "    if dir == \".DS_Store\":\n",
        "        continue\n",
        "\n",
        "    dir1 = \"term2_sprint18_data/img/\" + dir \n",
        "    label = 0\n",
        "\n",
        "    if dir == \"cat\":    # appleはラベル0\n",
        "        label = 0\n",
        "    elif dir == \"dog\": # orangeはラベル1\n",
        "        label = 1\n",
        "\n",
        "    for file in os.listdir(dir1):\n",
        "        if file != \".DS_Store\":\n",
        "            # 配列label_listに正解ラベルを追加(cat:0 dog:1)\n",
        "            label_list.append(label)\n",
        "            filepath = dir1 + \"/\" + file\n",
        "            # 画像を25x25pixelに変換し、1要素が[R,G,B]3要素を含む配列の25x25の２次元配列として読み込む。\n",
        "            # [R,G,B]はそれぞれが0-255の配列。\n",
        "            image = np.array(Image.open(filepath).resize((25, 25)))\n",
        "            # print(filepath)\n",
        "            # 配列を変換し、[[Redの配列],[Greenの配列],[Blueの配列]] のような形にする。\n",
        "            image = image.transpose(2, 0, 1)\n",
        "            # さらにフラットな1次元配列に変換。最初の1/3はRed、次がGreenの、最後がBlueの要素がフラットに並ぶ。\n",
        "            image = image.reshape(1, image.shape[0] * image.shape[1] * image.shape[2]).astype(\"float32\")[0]\n",
        "            # 出来上がった配列をimage_listに追加。\n",
        "            image_list.append(image / 255.)\n",
        "\n",
        "# kerasに渡すためにnumpy配列に変換。\n",
        "image_list = np.array(image_list)\n",
        "\n",
        "# onehotエンコーディング\n",
        "# cat = 0 -> [1,0], dog = 1 -> [0,1] 。\n",
        "Y = to_categorical(label_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2JdBodmOvra"
      },
      "source": [
        "image_list[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vg13ul2dVqm_"
      },
      "source": [
        "### 1.2.1（解答）kerasでのDeepLearning実装"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyYzKEuFXGiG"
      },
      "source": [
        "# モデルを生成してニューラルネットを構築\n",
        "model = Sequential()\n",
        "model.add(Dense(200, input_dim=1875))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(200))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(2))\n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "# オプティマイザにAdamを使用\n",
        "opt = Adam(lr=0.001)\n",
        "\n",
        "# モデルをコンパイル\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "\n",
        "# 学習を実行。10%はテストに使用。\n",
        "model.fit(image_list, Y, epochs=50, batch_size=100, validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HfAnpQxRCUe"
      },
      "source": [
        "### 1.3.1（解答）予測"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc-diVbLOA-9"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "# 検証する画像データを読み込む\n",
        "filepath = \"term2_sprint18_data/test/cat2.jpg\"\n",
        "image = np.array(Image.open(filepath).resize((25, 25)))\n",
        "\n",
        "# 画像データの型番の順番をmodelに合わせる\n",
        "image = image.transpose(2, 0, 1)\n",
        "# shape(1875,)の形に変換\n",
        "image = image.reshape(1, image.shape[0] * image.shape[1] * image.shape[2]).astype(\"float32\")[0]\n",
        "result = model.predict(np.array([image / 255.]))\n",
        "print(\"result:\", result, \"（ねこ : いぬ）\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOUuIJEmXGGr"
      },
      "source": [
        "## 【問題2】分類データセットに対するデータ拡張\n",
        "データ拡張（Data Augmentation）を行ってください。\n",
        "\n",
        "\n",
        "**《データ拡張のためのライブラリ》**\n",
        "\n",
        "\n",
        "データ拡張にはalbumentationsなどがあります。\n",
        "\n",
        "\n",
        "albu/albumentations: fast image augmentation library and easy to use wrapper around other libraries  \n",
        "https://github.com/albu/albumentations\n",
        "\n",
        "\n",
        "また、Kerasを使う場合はImageDataGeneratorも便利です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-w6XSfAXJEi"
      },
      "source": [
        "### 2.1.1 読み込み画像の指定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDPQCklMXe3X"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.python.keras.preprocessing import image\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSXmi9DOXsOM"
      },
      "source": [
        "# 読み込み画像へのpath\n",
        "path      = \"term2_sprint18_data/img/cat/\" \n",
        "# 画像の名称\n",
        "pic_name  = \"0\"\n",
        "# 拡張子\n",
        "extension = \".png\"\n",
        "# 生成された画像の格納path\n",
        "save_path = \"term2_sprint18_data/padding_img/cat/\"\n",
        "# 格納先ディレクトリが存在しなければ作成する\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# 1-1. テスト用画像の読み込み\n",
        "img = image.load_img(path + pic_name + extension)\n",
        "# 1-2. 画像の配列化\n",
        "img = np.array(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HL0JuMFXsDe"
      },
      "source": [
        "# 2. 配列を四次元に整形\n",
        "print(\"整形前の配列shape : {}\".format(img.shape))\n",
        "print(\"( 四次元配列でないとジェネレータに渡せないので、np.newaxisで次元追加 )\")\n",
        "img = img[np.newaxis]\n",
        "print(\"追加後shape      : {}\".format(img.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sx9gG5Dki3Af"
      },
      "source": [
        "### 2.2.1 ImageDataGeneratorの設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hx8Ncs4cyVC"
      },
      "source": [
        "# 3. ジェネレータの定義\n",
        "# データ拡張のパターンを指定する\n",
        "glasses_gen = ImageDataGenerator(\n",
        "    rotation_range=120, # 回転\n",
        "    width_shift_range=0.2, # 左右スライド\n",
        "    height_shift_range=0.2, # 上下スライド\n",
        "    shear_range=40, # せん断写像\n",
        "    zoom_range=0, # 拡大縮小\n",
        "    horizontal_flip=True, # 左右反転\n",
        "    vertical_flip=False) # 上下反転\n",
        " \n",
        " # 4. ジェネレータを生成。\n",
        "gen = glasses_gen.flow(img, \n",
        "                     batch_size  = 1,         ## 起動バッチ数の指定。今回は画像1枚なので1\n",
        "                     save_to_dir = \"term2_sprint18_data/padding_img/cat\", ## 保存先ディレクトリのpath\n",
        "                     save_format = \"jpg\"      ## 保存形式の指定\n",
        "                    )\n",
        "  \n",
        "plt.figure(figsize=(10,8))  # 表示画像サイズ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OA5N35EjjLSJ"
      },
      "source": [
        "### 2.3.1 画像の表示"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcUENWDndY-0"
      },
      "source": [
        "# 5. 9枚の画像を生成する\n",
        "for i in range(9):\n",
        " \n",
        "    # ジェネレータにおけるイテレータを進める\n",
        "    batches = next(gen)\n",
        "    \n",
        "    # 1次元目は次元合わせだったので読み飛ばす。\n",
        "    # 画像として表示するために、floatからuint8に変換する。\n",
        "    g_img = batches[0].astype(np.uint8)\n",
        " \n",
        "    # matplotlib.pyplot.subplot\n",
        "    #  ... 一つの図の中に複数のイメージを格納したいときに用いる。\n",
        "    #      引数は前から、行数、列数、何番目のプロットとして表示するかの指定。\n",
        "    #      下の記述で言えば、 3x3 の表示枠を一つの図中に用意し、順番に表示データを当て込んでいる。\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    plt.imshow(g_img)\n",
        "    \n",
        "    # matplotlib.pyplot.axis\n",
        "    # ... 座標軸を表示するかどうかを指定する。off 指定で表示されなくなる。\n",
        "    plt.axis('off')\n",
        " \n",
        "# 6. 表示\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDypb0QYBg9M"
      },
      "source": [
        "### 2.4.1 Albumentations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-D-zuAnBeV9"
      },
      "source": [
        "!pip install -U albumentations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn7Wv7brBkqM"
      },
      "source": [
        "import albumentations as A\n",
        "import cv2\n",
        "\n",
        "\n",
        "# Declare an augmentation pipeline\n",
        "transform = A.Compose([\n",
        "    A.RandomCrop(width=256, height=256),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.2),\n",
        "])\n",
        "\n",
        "# Read an image with OpenCV and convert it to the RGB colorspace\n",
        "image = cv2.imread(\"/content/drive/MyDrive/Colab Notebooks/term2_sprint18_data/img/cat/1.png\")\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Augment an image\n",
        "transformed = transform(image=image)\n",
        "transformed_image = transformed[\"image\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZZR02G4DOYq"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(transformed_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tzv9FyIsXN3_"
      },
      "source": [
        "## 【問題3】物体検出データセットの用意\n",
        "次に、物体検出を行います。バウンディングボックスのアノテーションを行い物体検出のためのデータセットを作成してください。\n",
        "\n",
        "\n",
        "《アノテーションのためのツール》\n",
        "\n",
        "\n",
        "アノテーションツールにはLabelImgなどがあります。\n",
        "\n",
        "\n",
        "tzutalin/labelImg: LabelImg is a graphical image annotation tool and label object bounding boxes in images\n",
        "https://github.com/tzutalin/labelImg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwzEque7l9-C"
      },
      "source": [
        "### 3.1.1 （解答）Labellmgの初期設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtJSOcBHmisI"
      },
      "source": [
        "!pip3 install pyqt5 lxml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlMQYsdgg5Sg"
      },
      "source": [
        "cd labelImg-master"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6vhO4fxmpnw"
      },
      "source": [
        "!make qt5py3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zc7GWQClGB9b"
      },
      "source": [
        "!python3 labelImg.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmZrgoFBln6B"
      },
      "source": [
        "本来上記の手順でlabellmgが起動するはずがcolabでは起動できず、condaで起動。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1H7nMOgmQAq"
      },
      "source": [
        "# 作成したデータ\n",
        "labellmg_data = \"/content/drive/MyDrive/Colab Notebooks/term2_sprint18_data/cat_xml/1.xml\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pbxt2NpPnUHL"
      },
      "source": [
        "## 【問題4】物体検出データセットに対するデータ拡張\n",
        "データ拡張（Data Augmentation）を行ってください。前述のalbumentationsはバウンディングボックスを合わせての加工が可能です。詳細はREADME.mdを確認してください。\n",
        "\n",
        "\n",
        "物体検出の学習を行なうかどうかは任意とします。  \n",
        "\n",
        "参考資料  \n",
        "https://qiita.com/sino20023/items/0314438d397240e56576"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jbt7Scv4mJub"
      },
      "source": [
        "### 4.1.1 （解答） XMLファイル操作"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EC1V4stUrCO9"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjKfygNZbPFc"
      },
      "source": [
        "# 読み込み画像へのpath\n",
        "path      = \"term2_sprint18_data/cat_xml/\" \n",
        "# 画像の名称\n",
        "pic_name  = \"1\"\n",
        "# 拡張子\n",
        "extension = \".xml\"\n",
        "# 生成された画像の格納path\n",
        "save_path = \"term2_sprint18_data/padding_img/cat/\"\n",
        "# 格納先ディレクトリが存在しなければ作成する\n",
        "os.makedirs(save_path, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gb3AYAOmr_fk"
      },
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "#xmlデータを読み込みます\n",
        "img = ET.parse(path + pic_name + extension)\n",
        "#一番上の階層の要素を取り出します\n",
        "img = img.getroot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZYE_nOeu1E7"
      },
      "source": [
        "for i in img:\n",
        "    print(i.tag)\n",
        "    print(i.attrib)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZX-XHRdxSFvf"
      },
      "source": [
        "object = [] # 並び(xmin,ymin,xmax,ymax)\n",
        "for name in img.iter('object'):\n",
        "    for i in name:\n",
        "        object.append(i.text)\n",
        "object"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2p6eyCbT1vax"
      },
      "source": [
        "bndbox = [] # 並び(xmin,ymin,xmax,ymax)\n",
        "for name in img.iter('bndbox'):\n",
        "    for i in name:\n",
        "        bndbox.append(i.text)\n",
        "bndbox"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Jl-ReW_5YEu"
      },
      "source": [
        "size = [] # 並び(width,height,depth)\n",
        "for name in img.iter('size'):\n",
        "    for i in name:\n",
        "        size.append(i.text)\n",
        "size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdYO7YXCNB9M"
      },
      "source": [
        "### 4.2.1 （解答） データ拡張"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIUAoq6KNI3W"
      },
      "source": [
        "BOX_COLOR = (255, 0, 0) # Red\n",
        "TEXT_COLOR = (255, 255, 255) # White\n",
        "\n",
        "\n",
        "def visualize_bbox(img, bbox, class_name, color=BOX_COLOR, thickness=2):\n",
        "    \"\"\"Visualizes a single bounding box on the image\"\"\"\n",
        "    x_min, y_min, w, h = bbox\n",
        "    x_min, x_max, y_min, y_max = int(x_min), int(x_min + w), int(y_min), int(y_min + h)\n",
        "\n",
        "    cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color=color, thickness=thickness)\n",
        "\n",
        "    ((text_width, text_height), _) = cv2.getTextSize(class_name, cv2.FONT_HERSHEY_SIMPLEX, 0.35, 1)    \n",
        "    cv2.rectangle(img, (x_min, y_min - int(1.3 * text_height)), (x_min + text_width, y_min), BOX_COLOR, -1)\n",
        "    cv2.putText(\n",
        "        img,\n",
        "        text=class_name,\n",
        "        org=(x_min, y_min - int(0.3 * text_height)),\n",
        "        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
        "        fontScale=0.35, \n",
        "        color=TEXT_COLOR, \n",
        "        lineType=cv2.LINE_AA,\n",
        "    )\n",
        "    return img\n",
        "\n",
        "\n",
        "def visualize(image, bboxes, category_ids, category_id_to_name):\n",
        "    img = image.copy()\n",
        "    for bbox, category_id in zip(bboxes, category_ids):\n",
        "        class_name = category_id_to_name[category_id]\n",
        "        img = visualize_bbox(img, bbox, class_name)\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWjnxw5SNgMr"
      },
      "source": [
        "image = cv2.imread('/content/drive/MyDrive/Colab Notebooks/term2_sprint18_data/img/cat/1.png')\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bztKJZR5NlQd"
      },
      "source": [
        "# x_min、y_min、width、height]\n",
        "bboxes = [bndbox]\n",
        "category_ids = [object[3]]\n",
        "\n",
        "# We will use the mapping from category_id to the class name\n",
        "# to visualize the class label for the bounding box on the image\n",
        "category_id_to_name = {object[3]: object[0]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAjP67oPOjT7"
      },
      "source": [
        "visualize(image, bboxes, category_ids, category_id_to_name)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}