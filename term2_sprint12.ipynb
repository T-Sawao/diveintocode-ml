{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "term2_sprint12.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOk/ppahGE+uHS15iivc6de",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/T-Sawao/diveintocode-ml/blob/master/term2_sprint12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HczNh-9AOdE"
      },
      "source": [
        "# 2.2次元の畳み込みニューラルネットワークスクラッチ\n",
        "\n",
        "2次元に対応した畳み込みニューラルネットワーク（CNN）のクラスをスクラッチで作成していきます。NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。\n",
        "\n",
        "\n",
        "プーリング層なども作成することで、CNNの基本形を完成させます。クラスの名前はScratch2dCNNClassifierとしてください。\n",
        "\n",
        "\n",
        "### データセットの用意  \n",
        "引き続きMNISTデータセットを使用します。2次元畳み込み層へは、28×28の状態で入力します。\n",
        "\n",
        "\n",
        "今回は白黒画像ですからチャンネルは1つしかありませんが、チャンネル方向の軸は用意しておく必要があります。\n",
        "\n",
        "\n",
        "(n_samples, n_channels, height, width)のNCHWまたは(n_samples, height, width, n_channels)のNHWCどちらかの形にしてください。\n",
        "\n",
        "\n",
        "## 【問題1】2次元畳み込み層の作成  \n",
        "1次元畳み込み層のクラスConv1dを発展させ、2次元畳み込み層のクラスConv2dを作成してください。\n",
        "\n",
        "\n",
        "フォワードプロパゲーションの数式は以下のようになります。\n",
        "$$a_{i, j, m} = \\sum_{k=0}^{K-1} \\sum_{s=0}^{F_h -1}\\sum_{t=0}^{F_w -1} x_{(i+s),(j+t),k}w_{s,t,k,m} + b_m$$\n",
        "$a_{i,j,m}$ : 出力される配列のi行j列、mチャンネルの値\n",
        "\n",
        "$i$ : 配列の行方向のインデックス\n",
        "\n",
        "$j$ : 配列の列方向のインデックス\n",
        "\n",
        "$m$ : 出力チャンネルのインデックス\n",
        "\n",
        "$K$ : 入力チャンネル数\n",
        "\n",
        "$F_h,F_w$ : 高さ方向（h）と幅方向（w）のフィルタのサイズ\n",
        "\n",
        "$x_{(i+s),(j+t),k}$ : 入力の配列の(i+s)行(j+t)列、kチャンネルの値\n",
        "\n",
        "$w_{s,t,k,m}$ : 重みの配列のs行t列目。kチャンネルの入力に対して、mチャンネルへ出力する重み\n",
        "\n",
        "$b_m$ : mチャンネルへの出力のバイアス項\n",
        "\n",
        "全てスカラーです。\n",
        "\n",
        "次に更新式です。1次元畳み込み層や全結合層と同じ形です。\n",
        "$$w'_{s, t, k, m} = w_{s, t, k, m} - \\alpha \\frac{\\partial L}{\\partial w_{s, t, k, m}}$$\n",
        "\n",
        "$$b'_m = b_m - \\alpha \\frac{\\partial L}{\\partial b_m}$$\n",
        "\n",
        "$\\alpha$ : 学習率\n",
        "\n",
        "$\\frac{\\partial L}{\\partial w_{s, t, k, m}}$ ： $w_{s,t,k,m}$ に関する損失 $L$ の勾配\n",
        "\n",
        "$\\frac{\\partial L}{\\partial b_m}$ : $b_m$ に関する損失$L$ の勾配\n",
        "\n",
        "勾配$\\frac{\\partial L}{\\partial w_{s, t, k, m}}$ や $\\frac{\\partial L}{\\partial b_m}$ を求めるためのバックプロパゲーションの数式が以下である。\n",
        "$$\\frac{\\partial L}{\\partial w_{s, t, k, m}} = \\sum_{i=0}^{N_{out, h}-1} \\sum_{j=0}^{N_{out, w}-1} \\frac{\\partial L}{\\partial a_{i,j,m}} x_{(i+s)(j+k),k}$$$$\\frac{\\partial L}{\\partial b_m} =  \\sum_{i=0}^{N_{out, h}-1} \\sum_{j=0}^{N_{out, w}-1} \\frac{\\partial L}{\\partial a_{i,j,m}}$$\n",
        "\n",
        "$\\frac{\\partial L}{\\partial a_{i,j,m}}$ : 勾配の配列のi行j列、mチャンネルの値\n",
        "\n",
        "$N_{out,h},N_{out,w}$ : 高さ方向（h）と幅方向（w）の出力のサイズ\n",
        "\n",
        "前の層に流す誤差の数式は以下です。\n",
        "$$\\frac{\\partial L}{\\partial x_{i,j,k}} = \\sum_{m=0}^{M-1} \\sum_{s=0}^{F_{h-1}} \\sum_{t=0}^{F_{w-1}} \\frac{\\partial L}{\\partial a_{(i-s)(j-t),m}}w_{s, t, k, m}$$\n",
        "\n",
        "$\\frac{\\partial L}{\\partial x_{i,j,k}}$ : 前の層に流す誤差の配列のi列j行、kチャンネルの値\n",
        "\n",
        "$M$ : 出力チャンネル数\n",
        "ただし、$i−s&lt;0$ または$i−s&gt;N_{out,h}−1$ または$j−t&lt;0$ または $j−t&gt;N_{out,w}−1$ のとき\n",
        "$\\frac{\\partial L}{\\partial a_{(i-s)(j-t),m}}w_{s, t, k, m}=0$です。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfEovpOnkz6h"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as setattr\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gj8HqmI5ArPd"
      },
      "source": [
        "### 1.1.1（予備知識) im2colクラスの作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRW6YbdZ7iiP"
      },
      "source": [
        "class im2col():\n",
        "  def __init__(self, filter_h=3, filter_w=3, stride=1, padding=0):\n",
        "    self.FH = filter_h       # フィルターの高さ\n",
        "    self.FW = filter_w      #　フィルターの幅\n",
        "    self.str = stride        # ストライド値\n",
        "    self.pad = padding     # パディング(今回未使用)\n",
        "\n",
        "  def im2col(self, X):\n",
        "    N, C, H, W = X.shape\n",
        "    print('========X===========\\n', X.shape)\n",
        "    print('=====================')\n",
        "    print('========FH===========\\n', self.FH)\n",
        "    print('=====================')\n",
        "    print('========FW===========\\n', self.FW)\n",
        "    print('=====================')\n",
        "\n",
        "    # h(上下)、w(左右)にフィルターが移動する回数\n",
        "    out_h, out_w = self._output_size(H, W)\n",
        "    print('========out_h===========\\n', out_h)\n",
        "    print('=====================')\n",
        "    print('========out_w===========\\n', out_w)\n",
        "    print('=====================')\n",
        "\n",
        "    #パディングの作成\n",
        "    # img = np.pad(img, [(前0画像セット数, 後0画像セット数), (前0画像数, 後0画像数), (上0埋め数, 下0埋め数), (左0埋め数, 右0埋め数)], 'constant')\n",
        "    # https://qiita.com/jun40vn/items/7be9f288edede284db97\n",
        "    img = np.pad(X, [(0,0), (0,0), (self.pad, self.pad), (self.pad, self.pad)], 'constant')\n",
        "\n",
        "    # 出力値を記載する枠を作成\n",
        "    col = np.zeros([N, C, self.FH, self.FW, out_h, out_w])\n",
        "    print('========col0===========\\n', col)\n",
        "    print('=====================')\n",
        "\n",
        "    for y in range(self.FH):\n",
        "      y_max = y + self.str * out_h\n",
        "      for x in range(self.FW):\n",
        "        x_max = x + self.str * out_w\n",
        "        col[:, :, y, x, :, :] = img[:, :, y:y_max:self.str, x:x_max:self.str]\n",
        "                                      #-----------------\n",
        "                                      #0~列の端までstride数飛ばしで習得する\n",
        "    print('========col1===========\\n', col)\n",
        "    print('=====================')\n",
        "\n",
        "    # transposeで配列の入れ替え（N, out_h, out_w, C, self.FH, self.FW)の順番に変更。 \n",
        "    # reshapeに-1を指定することで、指定した行数になるように列数は自動調整。\n",
        "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N * out_h * out_w, -1)\n",
        "    return col\n",
        "\n",
        "  def col2im(self, col, input_shape):\n",
        "               # ----------------\n",
        "               #入力データの形状(例:(10, 1, 28, 28))\n",
        "    N, C, H, W = input_shape\n",
        "    out_h, out_w = self._output_size(H, W)\n",
        "\n",
        "    # transposeで配列の入れ替え（N, C, self.FH, self.FW, out_h, out_w)の順番に変更。 \n",
        "    col = col.reshape(N, out_h, out_w, C, self.FH, self.FW).transpose(0, 3, 4, 5, 1, 2)\n",
        "\n",
        "    img = np.zeros((N, C, H + 2*self.pad + self.str - 1, W + 2*self.pad + self.str - 1))\n",
        "    for y in range(self.FH):\n",
        "        y_max = y + self.str*out_h\n",
        "        for x in range(self.FW):\n",
        "            x_max = x + self.str*out_w\n",
        "            img[:, :, y:y_max:self.str, x:x_max:self.str] += col[:, :, y, x, :, :]\n",
        "\n",
        "    return img[:, :, self.pad:H + self.pad, self.pad:W + self.pad]\n",
        "\n",
        "# 問題2 ----------------------------------------------\n",
        "  def _output_size(self, H, W):\n",
        "    out_h = int((H + 2*self.pad - self.FH) / self.str + 1)       \n",
        "    out_w = int((W + 2*self.pad - self.FW) / self.str + 1)\n",
        "    return out_h, out_w "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aLKwDTWBBvZ"
      },
      "source": [
        "### 1.1.2 （予備知識） サンプルデータ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YX5U0BkigdUL"
      },
      "source": [
        "data = np.random.rand(1, 1, 7, 7) * 100 // 1\n",
        "print('========== input ==========\\n', data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CZ4NBvNBmAy"
      },
      "source": [
        "### 1.1.3 （予備知識） im2colメソッドの動作確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI4i9VhTBlqy"
      },
      "source": [
        "col = im2col()\n",
        "cc = col.im2col(data)\n",
        "print(\"col.im2col(data).shape:\",cc.shape)\n",
        "print(cc[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJAxwGuuChwz"
      },
      "source": [
        "### 1.1.4 （予備知識） col2imメソッドの動作確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAzQL1QUCiil"
      },
      "source": [
        "dcc = col.col2im(cc, data.shape)\n",
        "print(dcc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boRD3nA0QU8D"
      },
      "source": [
        "### 1.2.1　（解答） 畳み込み層の実装"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OumpXwgX80II"
      },
      "source": [
        "# チャンネル数１の畳み込みネットワーク\n",
        "class Conv2d:\n",
        "    def __init__(self, w, b, stride=1, padding=0):\n",
        "      self.w = w\n",
        "      self.b = b\n",
        "      self.str = stride\n",
        "      self.pad = padding\n",
        "\n",
        "      # 中間データ(backward時に使用)\n",
        "      self.x = None\n",
        "      self.col = None\n",
        "      self.col_W = None\n",
        "\n",
        "      # 重み・バイアスパラメーターの勾配\n",
        "      self.dw = None\n",
        "      self.db = None\n",
        "\n",
        "    def forward(self, x):\n",
        "      self.x = x\n",
        "      FN, C, FH, FW = self.w.shape\n",
        "      N, C, H, W = x.shape\n",
        "      out_h = 1 + ((H + (2 * self.pad)  - FH) // self.str)\n",
        "      out_w = 1 + ((W + (2 * self.pad) - FW) // self.str)\n",
        "      \n",
        "      # im2colクラスを定義し、実行する。\n",
        "      self.col = im2col(filter_h=FH, filter_w=FW, stride=self.str, padding=self.pad)\n",
        "      self.col_im = self.col.im2col(self.x)\n",
        "      self.col_w = self.w.reshape(FN, -1).T\n",
        "      # print('==========col===========\\n', self.col_im)\n",
        "      # print('=====================')\n",
        "      # print('=========col_w===========\\n', self.col_w)\n",
        "      # print('=====================')\n",
        "\n",
        "      out = (self.col_im @ self.col_w) + self.b\n",
        "      # print('=========out1===========\\n', out)\n",
        "      # print('=====================')\n",
        "      # reshapeで出力サイズを指定の形状に再構成、transposeで順番を入れ替え。\n",
        "      out = out.reshape(N, out_h, out_w, -1).transpose(0,3,1,2)\n",
        "      # print('=========out2===========\\n', out)\n",
        "      # print('=====================')\n",
        "      return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "      FN, C, FH, FW = self.w.shape\n",
        "      # print('========dout1===========\\n', dout)\n",
        "      # print('=====================')\n",
        "      dout = dout.transpose(0,2,3,1).reshape(-1,FN)\n",
        "      # print('========dout2===========\\n', dout)\n",
        "      # print('=====================')\n",
        "\n",
        "      self.db = np.sum(dout, axis=0)\n",
        "      # print('==========db===========\\n', self.db)\n",
        "      # print('=====================')\n",
        "      self.dw = self.col_im.T @ dout\n",
        "      # print('==========dw1===========\\n', self.dw)\n",
        "      # print('=====================')\n",
        "      self.dw = self.dw.transpose(1, 0).reshape(FN, C, FH, FW)\n",
        "      # print('=========dw2===========\\n', self.dw)\n",
        "      # print('=====================')\n",
        "      dcol = dout @ self.col_w.T\n",
        "      # print('========dcol===========\\n', dcol)\n",
        "      # print('=====================')\n",
        "      # im2col状態を戻す処理\n",
        "      dx = self.col.col2im(dcol, self.x.shape)\n",
        "      # print('==========dx===========\\n', dx)\n",
        "      # print('=====================')\n",
        "      return dx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdFzJoyJQs7J"
      },
      "source": [
        "### 1.2.2（解答）フォワードプロパゲーション"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5fp8UkPEoVo"
      },
      "source": [
        "x = np.array([[2, 3, 4, 5], [1, 2, 3, 4]]) # shape(2, 4)で、（入力チャンネル数、特徴量数）\n",
        "w = np.array([[[[1,1,1],\n",
        "            [1,1,1]],\n",
        "            [[1,1,1],\n",
        "            [2,1,1]],\n",
        "            [[2,1,1],\n",
        "            [1,1,2]]]])\n",
        "b = np.array([3, 2, 1]) # （出力チャンネル数）\n",
        "b=np.array([b]*1)\n",
        "display(\"b.shape:\", b.shape)\n",
        "w = w.transpose(1,0,2,3)\n",
        "display(\"w.shape:\", w.shape)\n",
        "x = np.array([[x]*1]*1)\n",
        "display(\"x.shape:\", x.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUrpXH_BM0mS"
      },
      "source": [
        "con = Conv2d(w, b)\n",
        "x_con = con.forward(x)\n",
        "x_con"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXSVXRu2Rh1t"
      },
      "source": [
        "### 1.2.3 （解答）バックプロパゲーション"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mhco0D3TOtqh"
      },
      "source": [
        "dout = np.array([[[52,56]],\n",
        "                 [[32,35]],\n",
        "                 [[9,11]]])\n",
        "dout = np.array([dout]*1)\n",
        "dout.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMudFpU7R59U"
      },
      "source": [
        "dout_im =con.backward(dout)\n",
        "dout_im"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sTrK_bFfl5Y"
      },
      "source": [
        "## 【問題2】2次元畳み込み後の出力サイズ\n",
        "畳み込みを行うと特徴マップのサイズが変化します。どのように変化するかは以下の数式から求められます。この計算を行う関数を作成してください。\n",
        "$$N_{h, out} = \\frac{N_{h, in} + 2P_h - F_h}{S_h} + 1$$$$N_{w, out} = \\frac{N_{w, in} + 2P_w - F_w}{S_w} + 1$$\n",
        "\n",
        "$N_{out}$ : 出力のサイズ（特徴量の数）\n",
        "\n",
        "$N_{in}$ : 入力のサイズ（特徴量の数）\n",
        "\n",
        "$P$ : ある方向へのパディングの数\n",
        "\n",
        "$F$ : フィルタのサイズ\n",
        "\n",
        "$S$ : ストライドのサイズ\n",
        "\n",
        "$h$ が高さ方向、$w$ が幅方向である"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLy2-2D_ksRb"
      },
      "source": [
        "### 2.1.1（解答）　 im2colクラスへ実装済み"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zJeJIbok-Q1"
      },
      "source": [
        "## 【問題3】最大プーリング層の作成 最大プーリング層のクラスMaxPool2Dを作成してください。プーリング層は数式で表さない方が分かりやすい部分もありますが、数式で表すとフォワードプロパゲーションは以下のようになります。\n",
        "$$a_{i,j,k} = \\max_{(p,q)\\in P_{i,j}}x_{p,q,k}$$\n",
        "\n",
        "$P_{i,j}$ : i行j列への出力する場合の入力配列のインデックスの集合。 $S_h×S_w$ の範囲内の行$（p）$と列$（q）$\n",
        "\n",
        "$S_h,S_w$ : 高さ方向$（h）$と幅方向$（w）$のストライドのサイズ\n",
        "\n",
        "$(p,q)\\in P_{i,j}$ : $P_{i,j}$ に含まれる行$（p）$と列$（q）$のインデックス\n",
        "\n",
        "$a_{i,j,m}$ : 出力される配列のi行j列、kチャンネルの値\n",
        "\n",
        "$x_{p,q,k}$ : 入力の配列の$p$行$q$列、$k$チャンネルの値\n",
        "\n",
        "ある範囲の中でチャンネル方向の軸は残したまま最大値を計算することになります。\n",
        "\n",
        "バックプロパゲーションのためには、フォワードプロパゲーションのときの最大値のインデックス $(p,q)$ を保持しておく必要があります。フォワード時に最大値を持っていた箇所にそのままの誤差を流し、そこ以外には0を入れるためです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itllCvLa-Xjh"
      },
      "source": [
        "class Pooling:\n",
        "  def __init__(self, pool_h=2, pool_w=2, stride=2, padding=0):\n",
        "    self.PH = pool_h\n",
        "    self.PW = pool_w\n",
        "    self.str = stride\n",
        "    self.pad = padding\n",
        "    # im2colクラスの定義\n",
        "    self.col = im2col(filter_h=self.PH, filter_w=self.PW, stride=self.str, padding=self.pad)\n",
        "\n",
        "    self.x = None\n",
        "    self.arg_max = None\n",
        "\n",
        "  def forward(self, x):\n",
        "    print('=========x===========\\n', x.shape)\n",
        "    print('=====================')\n",
        "    N, C, H, W = x.shape\n",
        "    # out_h = int(1 + (H - self.pool_h) / self.stride)\n",
        "    # out_w = int(1 + (W - self.pool_w) / self.stride)\n",
        "    # im2colクラスのメソッドで、フィルターの上下、左右への移動数を求める。\n",
        "    out_h, out_w = self.col._output_size(self.PH, self.PW)\n",
        "    print('=========out_h===========\\n', out_h)\n",
        "    print('=====================')\n",
        "    print('=========out_w===========\\n', out_w)\n",
        "    print('=====================')\n",
        "\n",
        "    # col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
        "    # col = col.reshape(-1, self.pool_h*self.pool_w)\n",
        "    # 2次元配列に整形（2x2のフィルターで区切り、各カーネルの値を一列に並べフィルターを最後まで掛ける）\n",
        "    self.col_im = self.col.im2col(x)\n",
        "    print('=========col1===========\\n', self.col_im)\n",
        "    print('=====================')\n",
        "    # １行をPHxPW（４）列の配列に整形。\n",
        "    col = self.col_im.reshape(-1, self.PH*self.PW)\n",
        "    print('=========col2===========\\n', col)\n",
        "    print('=====================')\n",
        "\n",
        "    # colの最大値のindexを返す\n",
        "    arg_max = np.argmax(col, axis=1)\n",
        "    print('=========max===========\\n', arg_max)\n",
        "    print('=====================')\n",
        "    # indexから値を返す。\n",
        "    out = np.max(col, axis=1)\n",
        "    print('=========out1===========\\n', out)\n",
        "    print('=====================')\n",
        "    # 配列順を変更し、次に渡したい型に整形。\n",
        "    out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
        "    print('=========out2===========\\n', out)\n",
        "    print('=====================')\n",
        "\n",
        "    self.x = x\n",
        "    self.arg_max = arg_max\n",
        "\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    print('=========dout1===========\\n', dout)\n",
        "    print('=====================')\n",
        "    dout = dout.transpose(0, 2, 3, 1)\n",
        "    print('=========dout2===========\\n', dout)\n",
        "    print('=====================')\n",
        "    \n",
        "    pool_size = self.PH * self.PW\n",
        "    print('=========pool_size===========\\n', pool_size)\n",
        "    print('=====================')\n",
        "    dmax = np.zeros((dout.size, pool_size))\n",
        "    print('=========dmax1===========\\n', dmax)\n",
        "    print('=====================')\n",
        "    dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()\n",
        "    print('=========dmax2===========\\n', dmax)\n",
        "    print('=====================')\n",
        "    dmax = dmax.reshape(dout.shape + (pool_size,)) \n",
        "    print('=========dmax3===========\\n', dmax)\n",
        "    print('=====================')\n",
        "    \n",
        "    dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
        "    print('=========dcol===========\\n', dcol)\n",
        "    print('=====================')\n",
        "    dx = self.col.col2im(dcol, self.x.shape)\n",
        "    print('=========dx===========\\n', dx)\n",
        "    print('=====================')\n",
        "    \n",
        "    return dx"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojdJHIriaQVe"
      },
      "source": [
        "xin = np.array([[[[1,3,2,9],\n",
        "                  [7,4,1,5],\n",
        "                  [8,5,2,3],\n",
        "                  [4,2,1,4]],\n",
        "                 \n",
        "                 [[1,3,2,9],\n",
        "                  [7,4,1,5],\n",
        "                  [8,5,2,3],\n",
        "                  [4,2,1,4]]],\n",
        "               [[[1,3,2,9],\n",
        "                  [7,4,1,5],\n",
        "                  [8,5,2,3],\n",
        "                  [4,2,1,4]],\n",
        "                 \n",
        "                 [[1,3,2,9],\n",
        "                  [7,4,1,5],\n",
        "                  [8,5,2,3],\n",
        "                  [4,2,1,4]]]])\n",
        "pool=Pooling()\n",
        "pool.forward(xin).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLwdm4-lbGA1"
      },
      "source": [
        "dP = np.array([[[[1,2],\n",
        "                 [3,4]],\n",
        "                \n",
        "                [[1,2],\n",
        "                 [3,4]]],\n",
        "              [[[1,2],\n",
        "                 [3,4]],\n",
        "                \n",
        "                [[1,2],\n",
        "                 [3,4]]]])\n",
        "pool.backward(dP)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxhuCn5STTaB"
      },
      "source": [
        "## 【問題5】平滑化  \n",
        "平滑化するためのFlattenクラスを作成してください。\n",
        "\n",
        "\n",
        "フォワードのときはチャンネル、高さ、幅の3次元を1次元にreshapeします。その値は記録しておき、バックワードのときに再びreshapeによって形を戻します。\n",
        "\n",
        "\n",
        "この平滑化のクラスを挟むことで出力前の全結合層に適した配列を作ることができます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYjTPt--SAzd"
      },
      "source": [
        "class Flatten():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  \n",
        "  def forward(self, x):\n",
        "    self.x = x\n",
        "    N, C, H, W = self.x.shape\n",
        "    x = x.reshape(N, -1)\n",
        "    return x\n",
        "\n",
        "  def backward(self, dout):\n",
        "    N, C, H, W = self.x.shape\n",
        "    dout = dout.reshape(N, C, H, W)\n",
        "    return dout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwO1Hc-0qJx1"
      },
      "source": [
        "fla = Flatten()\n",
        "a =fla.forward(pool.forward(xin))\n",
        "display(a)\n",
        "fla.backward(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErI_43MNr-2t"
      },
      "source": [
        "# 3.検証\n",
        "\n",
        "## 【問題6】学習と推定\n",
        "作成したConv2dを使用してMNISTを学習・推定し、Accuracyを計算してください。\n",
        "\n",
        "\n",
        "精度は低くともまずは動くことを目指してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Oatnu0s9Cg0"
      },
      "source": [
        "# メインクラス\n",
        "class ScratchDeepNeuralNetworkClassifier():\n",
        "  \"\"\"\n",
        "  送られてくるパラメーター\n",
        "  sdnn = ScratchDeepNeuralNetworkClassifier(epoch_num=7)\n",
        "  sdnn.fit(HeInitializer, ReLU, AdaGrad, x_train, y_train_one_hot, x_val, y_val_one_hot, sigma=0.01, lr=0.01)\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, FN=3, n_output=10, epoch_num=1, batch_size=100, sigma=0.01, lr=0.01, verbose=True): \n",
        "    self.FN = FN\n",
        "    self.n_output = n_output\n",
        "    self.epoch = epoch_num\n",
        "    self.batch_size = batch_size\n",
        "    self.sigma = sigma\n",
        "    self.lr = lr\n",
        "    self.verbose = verbose\n",
        "    self.num = 2\n",
        "    self.loss = np.zeros(self.epoch)\n",
        "    self.val_loss = np.zeros(self.epoch)\n",
        "\n",
        "  def fit(self, initializing, act, optimization, X, y, X_val=None, y_val=None, n_features=784, n_nodes1=400, n_nodes2=200):  \n",
        "    self.initializing0 = SimpleInitializer # CNN用の初期化クラスの設定\n",
        "    self.initializing = initializing        # 初期化クラスの設定\n",
        "    self.activation = act              # 活性化関数クラスの設定\n",
        "    self.optimization = optimization      # 最適化クラスの設定\n",
        "    self.h = None                    # 最適化クラス adagraidで使用\n",
        "    self.x = x\n",
        "    XN, XC, XH, XW = self.x.shape\n",
        "\n",
        "    # 最適化クラスの設定\n",
        "    optimizer0 = self.optimization(self.lr)\n",
        "    optimizer1 = self.optimization(self.lr)\n",
        "    optimizer2 = self.optimization(self.lr)\n",
        "    optimizer3 = self.optimization(self.lr)\n",
        "\n",
        "    # 畳み込みネットワークの設定\n",
        "    self.CN1 = Conv2d(self.initializing0(self.sigma), optimizer0, XC, self.FN)\n",
        "    self.activation1 = self.activation()\n",
        "    # プーリング層の設定\n",
        "    self.MaxPL1=Pooling()\n",
        "    # 平滑化の設定\n",
        "    self.FLAT1 = Flatten()\n",
        "    # 全結合層にインスタンスを渡す\n",
        "    self.FC1 = FC(n_features, n_nodes1, self.initializing(self.sigma), optimizer1)\n",
        "    self.activation2 = self.activation()     \n",
        "    self.FC2 = FC(n_nodes1, n_nodes2, self.initializing(self.sigma), optimizer2)\n",
        "    self.activation３ = self.activation()        \n",
        "    self.FC3 = FC(n_nodes2, self.n_output, self.initializing(self.sigma), optimizer3)\n",
        "    self.activation4 = Softmax()\n",
        "\n",
        "    # エポック数分の学習\n",
        "    for i in range(self.epoch):\n",
        "      # ミニバッチの作成\n",
        "      get_mini_batch = GetMiniBatch(X, y, self.batch_size)\n",
        "      # 1エポック（全バッチ）の学習\n",
        "      for x_min, y_min in get_mini_batch:\n",
        "        y_hat = self._forward_propagation(x_min)\n",
        "        loss = self._back_propagation(X=y_hat, Y=y_min)\n",
        "        # print(\"y_hat\",y_hat[:1])\n",
        "\n",
        "      self.loss[i] += loss\n",
        "      if (type(X_val) != bool):\n",
        "        self.val = 1\n",
        "        y_hat_val = self._forward_propagation(X_val)\n",
        "        loss_val = -np.mean(y_val_one_hot * np.log(y_hat_val + 1e-7))\n",
        "        self.val_loss[i] += loss_val\n",
        "\n",
        "      # self.acc_val[i] = accuracy_score(np.argmax(y_val, axis=1), np.argmax(y_hat_val, axis=1))\n",
        "      # verboseをTrueにした際は学習過程を出力\n",
        "      if self.verbose :\n",
        "        print(f\"--{i+1}回目~loss~-------\\n{self.loss[i]}\")\n",
        "        print(f\"--{i+1}回目~loss_val~---\\n{self.val_loss[i]}\")\n",
        "        # print(f'epoch:{self.epoch:>3} loss:{self.loss:>8,.3f}')\n",
        "\n",
        "  # フォワードプロパゲーションの実行\n",
        "  def _forward_propagation(self, x):\n",
        "    print(\"x\",x)\n",
        "    CN1 = self.CN1.forward(x)\n",
        "    Z1 = self.activation1.forward(CN1)\n",
        "    PL1 = self.MaxPL1.forward(Z1)\n",
        "    FL1 =self.FLAT1.forward(PL1) \n",
        "\n",
        "    A1 = self.FC1.forward(FL1)\n",
        "    Z2 = self.activation2.forward(A1)\n",
        "    A2 = self.FC2.forward(Z1)\n",
        "    Z3 = self.activation3.forward(A2)\n",
        "    A3 = self.FC3.forward(Z2)\n",
        "    Z4 = self.activation4.forward(A3)\n",
        "    return Z4\n",
        "\n",
        "  # バックプロパゲーションの実行\n",
        "  def _back_propagation(self, X, Y):\n",
        "    dA4, loss = self.activation4.backward(X, Y) # 交差エントロピー誤差とソフトマックスを合わせている\n",
        "    dZ3 = self.FC3.backward(dA4)\n",
        "    dA3 = self.activation3.backward(dZ3)\n",
        "    dZ2 = self.FC2.backward(dA3)\n",
        "    dA2 = self.activation2.backward(dZ2)\n",
        "    dZ1 = self.FC1.backward(dA2)\n",
        "\n",
        "    dFL1 = self.FLAT1.backward(dZ1)\n",
        "    dPL1 = self.MaxPL1.backward(dFL1)\n",
        "    dZ0 = self.activation1.backward(dPL1)\n",
        "    dCN1 = self.CN1.backward(dZ0)\n",
        "    return dCN1\n",
        "\n",
        "  def predict(self, X):\n",
        "    y_hat = self._forward_propagation(X)\n",
        "    return np.argmax(y_hat, axis=1)\n",
        "\n",
        "  def plot_cost(self):\n",
        "    plt.title(\"Num_of_Iteration vs Loss\")\n",
        "    plt.xlabel(\"Num_of_Iteration\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    a = range(self.epoch)\n",
        "    plt.plot(range(1, self.epoch+1), self.loss, color=\"b\", label=\"train_loss\")\n",
        "    if self.val ==1:\n",
        "        plt.plot(range(1, self.epoch+1), self.val_loss, color=\"orange\", label=\"val_loss\")\n",
        "    plt.grid()\n",
        "    plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovFwVpyKqir4"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYyixhizLy5s"
      },
      "source": [
        "sdnn = ScratchDeepNeuralNetworkClassifier(epoch_num=1, sigma=0.01, lr=0.01)\n",
        "sdnn.fit(HeInitializer, ReLU, AdaGrad, x_train, y_train, x_val, y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3co0urqbrXFi"
      },
      "source": [
        "## layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPTM4YV39gO1"
      },
      "source": [
        "# チャンネル数１の畳み込みネットワーク\n",
        "class Conv2d():\n",
        "  def __init__(self, initializer, optimizer, FC, FN, FH=3, FW=3, stride=1, padding=0):\n",
        "    self.optimizer = optimizer\n",
        "    self.w = initializer.W(FC, FN)\n",
        "    self.b = initializer.B(FN)\n",
        "    self.str = stride\n",
        "    self.pad = padding\n",
        "    self.col1 = im2col(filter_h=FH, filter_w=FW, stride=self.str, padding=self.pad)\n",
        "    \n",
        "\n",
        "    # 中間データ(backward時に使用)\n",
        "    self.x = None\n",
        "    self.col = None\n",
        "    self.col_W = None\n",
        "\n",
        "    # 重み・バイアスパラメーターの勾配\n",
        "    self.dw = None\n",
        "    self.db = None\n",
        "\n",
        "  def forward(self, x):\n",
        "    self.x = x\n",
        "    FN, C, FH, FW = self.w.shape\n",
        "    N, C, H, W = x.shape\n",
        "    out_h, out_w = self.col1._output_size(H, W)\n",
        "    \n",
        "    # im2colクラスを定義し、実行する。\n",
        "    self.col_im = self.col1.im2col(self.x)\n",
        "    self.col_w = self.w.reshape(FN, -1).T\n",
        "    # print('==========col===========\\n', self.col_im)\n",
        "    # print('=====================')\n",
        "    # print('=========col_w===========\\n', self.col_w)\n",
        "    # print('=====================')\n",
        "\n",
        "    out = (self.col_im @ self.col_w) + self.b\n",
        "    # print('=========out1===========\\n', out)\n",
        "    # print('=====================')\n",
        "    # reshapeで出力サイズを指定の形状に再構成、transposeで順番を入れ替え。\n",
        "    out = out.reshape(N, out_h, out_w, -1).transpose(0,3,1,2)\n",
        "    # print('=========out2===========\\n', out)\n",
        "    # print('=====================')\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    FN, C, FH, FW = self.w.shape\n",
        "    # print('========dout1===========\\n', dout)\n",
        "    # print('=====================')\n",
        "    dout = dout.transpose(0,2,3,1).reshape(-1,FN)\n",
        "    # print('========dout2===========\\n', dout)\n",
        "    # print('=====================')\n",
        "\n",
        "    self.db = np.sum(dout, axis=0)\n",
        "    # print('==========db===========\\n', self.db)\n",
        "    # print('=====================')\n",
        "    self.dw = self.col_im.T @ dout\n",
        "    # print('==========dw1===========\\n', self.dw)\n",
        "    # print('=====================')\n",
        "    self.dw = self.dw.transpose(1, 0).reshape(FN, C, FH, FW)\n",
        "    # print('=========dw2===========\\n', self.dw)\n",
        "    # print('=====================')\n",
        "    dcol = dout @ self.col_w.T\n",
        "    # print('========dcol===========\\n', dcol)\n",
        "    # print('=====================')\n",
        "    # im2col状態を戻す処理\n",
        "    dx = self.col.col2im(dcol, self.x.shape)\n",
        "    # print('==========dx===========\\n', dx)\n",
        "    # print('=====================')\n",
        "    \n",
        "    # 更新\n",
        "    self = self.optimizer.update(self)\n",
        "    \n",
        "    return self.dx\n",
        "\n",
        "# Pooling層ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "class Pooling:\n",
        "  def __init__(self, pool_h=2, pool_w=2, stride=2, padding=0):\n",
        "    self.PH = pool_h\n",
        "    self.PW = pool_w\n",
        "    self.str = stride\n",
        "    self.pad = padding\n",
        "    # im2colクラスの定義\n",
        "    self.col2 = im2col(filter_h=self.PH, filter_w=self.PW, stride=self.str, padding=self.pad)\n",
        "\n",
        "    self.x = None\n",
        "    self.arg_max = None\n",
        "\n",
        "  def forward(self, x):\n",
        "    # print('=========x===========\\n', x.shape)\n",
        "    # print('=====================')\n",
        "    N, C, H, W = x.shape\n",
        "    # out_h = int(1 + (H - self.pool_h) / self.stride)\n",
        "    # out_w = int(1 + (W - self.pool_w) / self.stride)\n",
        "    # im2colクラスのメソッドで、フィルターの上下、左右への移動数を求める。\n",
        "    out_h, out_w = self.col2._output_size(H, W)\n",
        "    # print('=========out_h===========\\n', out_h)\n",
        "    # print('=====================')\n",
        "    # print('=========out_w===========\\n', out_w)\n",
        "    # print('=====================')\n",
        "\n",
        "    # col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
        "    # col = col.reshape(-1, self.pool_h*self.pool_w)\n",
        "    # 2次元配列に整形（2x2のフィルターで区切り、各カーネルの値を一列に並べフィルターを最後まで掛ける）\n",
        "    self.col_im = self.col2.im2col(x)\n",
        "    # print('=========col1===========\\n', self.col_im)\n",
        "    # print('=====================')\n",
        "    # １行をPHxPW（４）列の配列に整形。\n",
        "    col = self.col_im.reshape(-1, self.PH*self.PW)\n",
        "    print('=========col2===========\\n', col)\n",
        "    print('=====================')\n",
        "\n",
        "    # colの最大値のindexを返す\n",
        "    arg_max = np.argmax(col, axis=1)\n",
        "    print('=========max===========\\n', arg_max)\n",
        "    print('=====================')\n",
        "    # indexから値を返す。\n",
        "    out = np.max(col, axis=1)\n",
        "    print('=========out1===========\\n', out)\n",
        "    print('=====================')\n",
        "    # 配列順を変更し、次に渡したい型に整形。\n",
        "    out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
        "    print('=========out2===========\\n', out.shape)\n",
        "    print('=====================')\n",
        "\n",
        "\n",
        "    self.x = x\n",
        "    self.arg_max = arg_max\n",
        "\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    # print('=========dout1===========\\n', dout)\n",
        "    # print('=====================')\n",
        "    dout = dout.transpose(0, 2, 3, 1)\n",
        "    # print('=========dout2===========\\n', dout)\n",
        "    # print('=====================')\n",
        "    \n",
        "    pool_size = self.PH * self.PW\n",
        "    # print('=========pool_size===========\\n', pool_size)\n",
        "    # print('=====================')\n",
        "    dmax = np.zeros((dout.size, pool_size))\n",
        "    # print('=========dmax1===========\\n', dmax)\n",
        "    # print('=====================')\n",
        "    dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()\n",
        "    # print('=========dmax2===========\\n', dmax)\n",
        "    # print('=====================')\n",
        "    dmax = dmax.reshape(dout.shape + (pool_size,)) \n",
        "    # print('=========dmax3===========\\n', dmax)\n",
        "    # print('=====================')\n",
        "    \n",
        "    dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
        "    # print('=========dcol===========\\n', dcol)\n",
        "    # print('=====================')\n",
        "    dx = self.col.col2im(dcol, self.x.shape)\n",
        "    # print('=========dx===========\\n', dx)\n",
        "    # print('=====================')\n",
        "    \n",
        "    return dx\n",
        "\n",
        "# 平滑化ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "class Flatten():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  \n",
        "  def forward(self, x):\n",
        "    print('=======x===========\\n', x.shape)\n",
        "    print('=====================')\n",
        "    self.x = x\n",
        "    N, C, H, W = self.x.shape\n",
        "    x = x.reshape(N, -1)\n",
        "    return x\n",
        "\n",
        "  def backward(self, dout):\n",
        "    N, C, H, W = self.x.shape\n",
        "    dout = dout.reshape(N, C, H, W)\n",
        "    return dout\n",
        "\n",
        "# 全結合層ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "class FC:\n",
        "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
        "        self.optimizer = optimizer\n",
        "        self.n_nodes1 = n_nodes1\n",
        "        self.n_nodes2 = n_nodes2\n",
        "        self.W = initializer.W(self.n_nodes1, self.n_nodes2)\n",
        "        self.B = initializer.B(self.n_nodes2)\n",
        "        # 初期化\n",
        "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
        "\n",
        "    # フォワードプロパゲーション時の処理\n",
        "    def forward(self, X):\n",
        "      print('=======X===========\\n', X.shape)\n",
        "      print('=====================')\n",
        "      print('========W=========\\n', self.W.shape)\n",
        "      print('=====================')\n",
        "      self.X = X\n",
        "      print(\"W\", )\n",
        "      out = X@self.W+self.B\n",
        "      return out\n",
        "    \n",
        "    # バックプロパゲーション時の処理\n",
        "    def backward(self, dA):\n",
        "      self.dZ = dA@(self.W.T)\n",
        "      self.dW = (self.X.T)@dA\n",
        "      self.dB = np.sum(dA, axis=0)\n",
        "      \n",
        "      # 更新\n",
        "      self = self.optimizer.update(self)\n",
        "      return self.dZ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Jhu_rJd9gU3"
      },
      "source": [
        "# 初期化クラス\n",
        "# SimpleInitializer ------------------------------------------------------------\n",
        "class SimpleInitializer:\n",
        "    def __init__(self, sigma):\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def W(self, FC, FN, FH=3, FW=3):\n",
        "        W = self.sigma * np.random.randn(FN, FC, FH, FW)\n",
        "        return W\n",
        "\n",
        "    def B(self, FN):\n",
        "      B = self.sigma * np.random.randn(1, FN)\n",
        "      return B\n",
        "\n",
        "# XavierInitializer ------------------------------------------------------------\n",
        "class XavierInitializer:\n",
        "    def __init__(self, sigma):\n",
        "      self.sigma = sigma\n",
        "\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        W = np.random.randn(n_nodes1, n_nodes2)/np.sqrt(n_nodes1)\n",
        "        return W\n",
        "\n",
        "    def B(self, n_nodes2):\n",
        "        return np.zeros(n_nodes2)\n",
        "\n",
        "# He-----------------------------------------------------------------------------\n",
        "class HeInitializer:\n",
        "    def __init__(self, sigma):\n",
        "      self.sigma = sigma\n",
        "\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        W = np.random.randn(n_nodes1, n_nodes2) * np.sqrt(2/n_nodes1) \n",
        "        return W\n",
        "\n",
        "    def B(self, n_nodes2):\n",
        "        return np.zeros(n_nodes2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRTtZxoA9ga5"
      },
      "source": [
        "# 最適化クラス\n",
        "# SGD---------------------------------------------\n",
        "class SGD:\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr\n",
        "\n",
        "    def update(self, layer):\n",
        "      layer.W -= self.lr * layer.dW\n",
        "      layer.B -= self.lr * layer.dB\n",
        "      return layer\n",
        "\n",
        "# AdaGrad----------------------------------------\n",
        "class AdaGrad:\n",
        "    def __init__(self, lr):\n",
        "      self.lr = lr\n",
        "      self.hw = 0\n",
        "      self.hb = 0\n",
        "  \n",
        "    def update(self, layer):\n",
        "        self.hw += layer.dW * layer.dW\n",
        "        self.hb = layer.dB * layer.dB\n",
        "        layer.W -= self.lr * layer.dW / (np.sqrt(self.hw) +1e-7)\n",
        "        layer.B -= self.lr * layer.dB / (np.sqrt(self.hb) +1e-7)\n",
        "        return layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAndz8vR9gYS"
      },
      "source": [
        "# 活性化関数クラス\n",
        "# ソフトマックス関数のクラス----------------------------------------------\n",
        "class Softmax:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  # forward時の処理\n",
        "  def forward(self, X):\n",
        "    y_hat = np.exp(X) / np.sum(np.exp(X), axis = 1).reshape(-1,1)\n",
        "    return y_hat\n",
        "\n",
        "  # backward時の処理\n",
        "  def backward(self, X, Y):\n",
        "    loss = -np.mean(Y * np.log(X + 1e-7))\n",
        "    dA3 = X - Y\n",
        "    return dA3, loss\n",
        "\n",
        "# ReLU関数のクラス----------------------------------------------\n",
        "class ReLU:\n",
        "  def __init__(self):\n",
        "        pass\n",
        "  # forward時の処理\n",
        "  def forward(self, X):\n",
        "    self.X =X\n",
        "    return np.maximum(0, X)\n",
        "    \n",
        "  # backward時の処理\n",
        "  def backward(self, dout):\n",
        "    return np.where(self.X > 0, dout, 0)\n",
        "\n",
        "# tanh関数のクラス----------------------------------------------\n",
        "class Tanh:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  # forward時の処理\n",
        "  def forward(self, X):\n",
        "    self.out = np.tanh(X)\n",
        "    return self.out\n",
        "\n",
        "  # backward時の処理\n",
        "  def backward(self, X):\n",
        "    return X*(1-self.out**2)\n",
        "\n",
        "# sigmoid関数のクラス----------------------------------------------\n",
        "class Sigmoid:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  # forward時の処理\n",
        "  def forward(self, z):\n",
        "    self.out = 1 / (1+np.exp(-z))\n",
        "    return self.out\n",
        "\n",
        "  # backward時の処理\n",
        "  def backward(self, z):\n",
        "    return z*(1-self.out)*self.out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UDiVexjLvLk"
      },
      "source": [
        "### 前処理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f8VReAI9gRy"
      },
      "source": [
        "class GetMiniBatch:\n",
        "    \"\"\"\n",
        "    ミニバッチを取得するイテレータ\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : 次の形のndarray, shape (n_samples, n_features)\n",
        "      訓練データ\n",
        "    y : 次の形のndarray, shape (n_samples, 1)\n",
        "      正解値\n",
        "    batch_size : int\n",
        "      バッチサイズ\n",
        "    seed : int\n",
        "      NumPyの乱数のシード\n",
        "    \"\"\"\n",
        "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self._X = X[shuffle_index]\n",
        "        self._y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self._X[p0:p1], self._y[p0:p1]        \n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self._X[p0:p1], self._y[p0:p1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7vbiylz9gM0"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# # 平滑化（flatten）\n",
        "# X_train_fltten = X_train.reshape(-1, 784)\n",
        "# X_test_fltten = X_test.reshape(-1, 784)\n",
        "\n",
        "# float化と0or1処理\n",
        "X_train_flt = X_train.astype(np.float)\n",
        "X_test_flt = X_test.astype(np.float)\n",
        "X_train_flt /= 255\n",
        "X_test_flt /= 255\n",
        "\n",
        "X_train = X_train_flt[:, np.newaxis,:,:]\n",
        "X_test = X_test_flt[:, np.newaxis,:,:]\n",
        "\n",
        "# one hot処理\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
        "y_test_one_hot = enc.transform(y_test[:, np.newaxis])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "949gNi7o9gLZ"
      },
      "source": [
        "# train, testの分割\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(np.array(X_train), np.array(y_train_one_hot), test_size=0.2)\n",
        "print(\"x_train\",x_train.shape, \"x_val\", x_val.shape, \"y_train.shape\", y_train.shape, \"y_val,shape\", y_val.shape) # (48000, 784)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqZRbrUy02QE"
      },
      "source": [
        "y_pred = sdnn.predict(X_test_flt)\n",
        "y_pred[:100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWkyK1br080g"
      },
      "source": [
        "y_test[:100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOvt0FXQ1oRD"
      },
      "source": [
        "sdnn.plot_cost()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJLkQJE62UcZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}