{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "term2_sprint20_VGG19Code.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/T-Sawao/diveintocode-ml3/blob/main/term2_sprint20_VGG19Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtrJc7gqQf1i"
      },
      "source": [
        "# term2_sprint20_VGG19Code\n",
        "（ResNetから修正）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6RTx1PLU81U"
      },
      "source": [
        "## Model architecture tuning & score optimization\n",
        "\n",
        "\n",
        "Some ideas and code taken from ealier [kernel](https://www.kaggle.com/wrosinski/clean-workflow-in-keras) and last prepared notebook.\n",
        "\n",
        "Having dealt with data processing & engineering of channel features, next step of modeling is preparation and tuning of model architecture. Earlier notebooks provided a way to create images with three channels, which will facilitate usage of pretrained models.\n",
        "\n",
        "For segmentation tasks, a pretrained model can be used as encoder part of the final architecture. \n",
        "In order to use pretrained models, we will have to extract features from a few intermediate layers, which will then serve as a basis for layers coming afterwards and for skip connections between encoder and decoder part.\n",
        "\n",
        "ResNet50 is a good starting point, because it consists of 4 blocks, where each one of them can serve as feature extractor with first layer serving as the 5th extractor to achieve consistency with standard UNet architecture.\n",
        "\n",
        "**モデルアーキテクチャの調整とスコアの最適化**  \n",
        "\n",
        "より簡単なカーネルと最後に準備されたノートブックから取られたいくつかのアイデアとコード。\n",
        "\n",
        "チャネル機能のデータ処理とエンジニアリングを扱った後、モデリングの次のステップは、モデルアーキテクチャの準備と調整です。以前のノートブックには、3つのチャネルを持つ画像を作成する方法が用意されていたため、事前学習済みのモデルを簡単に使用できます。\n",
        "\n",
        "セグメンテーションタスクの場合、事前トレーニング済みのモデルを最終アーキテクチャのエンコーダ部分として使用できます。事前学習済みのモデルを使用するには、いくつかの中間層から特徴を抽出する必要があります。この中間層は、その後に来る層の基礎として機能し、エンコーダーとデコーダー部分間の接続をスキップします。\n",
        "\n",
        "ResNet50は4つのブロックで構成されており、それぞれが機能抽出機能として機能し、最初のレイヤーが5番目の抽出機能として機能し、標準UNetアーキテクチャとの整合性を実現できるため、出発点として適しています。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRDH3GjcNzKB",
        "outputId": "090691aa-8444-4e01-e5ca-f459574b61b5"
      },
      "source": [
        "!pip install keras==2.2.4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==2.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\r\u001b[K     |█                               | 10kB 15.0MB/s eta 0:00:01\r\u001b[K     |██                              | 20kB 9.8MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30kB 8.5MB/s eta 0:00:01\r\u001b[K     |████▏                           | 40kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 61kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 81kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 92kB 5.4MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 102kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 112kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 122kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 133kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 143kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 153kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 163kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 174kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 184kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 194kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 204kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 215kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 225kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 235kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 245kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 256kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 266kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 276kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 286kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 296kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 307kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 317kB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.1.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.19.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (3.13)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.9MB/s \n",
            "\u001b[?25hInstalling collected packages: keras-applications, keras\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed keras-2.2.4 keras-applications-1.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cBuIpvqN0zc",
        "outputId": "64290d5d-e869-4135-bbe2-13bd4786c16f"
      },
      "source": [
        "!pip install tensorflow==1.14.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 87kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.36.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 23.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.12.4)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 32.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.32.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.19.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.3.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (51.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.7.4.3)\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.4.0\n",
            "    Uninstalling tensorboard-2.4.0:\n",
            "      Successfully uninstalled tensorboard-2.4.0\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorflow 2.4.0\n",
            "    Uninstalling tensorflow-2.4.0:\n",
            "      Successfully uninstalled tensorflow-2.4.0\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iuksktt5N8Un",
        "outputId": "8443fc8f-5c60-43a2-c536-9b917649fd42"
      },
      "source": [
        "# !pip install tensorflow-gpu==1.14.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/04/43153bfdfcf6c9a4c38ecdb971ca9a75b9a791bb69a764d652c359aca504/tensorflow_gpu-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (377.0MB)\n",
            "\u001b[K     |████████████████████████████████| 377.0MB 41kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (3.12.4)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.19.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.36.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.32.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.14.0) (51.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.3.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.4.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOZxlBM_OGM0",
        "outputId": "d93e8a4d-2094-41ab-c9ae-08a9dea0779c"
      },
      "source": [
        "import tensorflow\n",
        "import keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VOvkDB3mOa8o",
        "outputId": "af288d61-e3fa-416a-96f8-0bc5c8fc5e71"
      },
      "source": [
        "tensorflow.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.14.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDF--AkxxqMl",
        "outputId": "7f17a13f-faad-45af-f248-3aaea9f6af4f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwYhyXpZ2dmd",
        "outputId": "e55702af-cd76-46fe-83b5-87d9295f2b44"
      },
      "source": [
        "cd drive/MyDrive/unet/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/unet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpeMuDbSU81e"
      },
      "source": [
        "import gc\n",
        "import glob\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from tqdm import tqdm\n",
        "\n",
        "from keras import optimizers\n",
        "from keras.callbacks import *\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.layers import *\n",
        "from keras.models import Model, load_model, save_model\n",
        "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
        "# 下記エンコーダをVGG19に書き換え\n",
        "from keras.applications.vgg19 import VGG19, preprocess_input\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0acaQGypU81f"
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (12, 9)\n",
        "# plt.style.use('ggplot')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPhHCE5uU81g"
      },
      "source": [
        "def compute_coverage(df, masks):\n",
        "    \n",
        "    df = df.copy()\n",
        "    \n",
        "    def cov_to_class(val):\n",
        "        for i in range(0, 11):\n",
        "            if val * 10 <= i:\n",
        "                return i\n",
        "\n",
        "    # Output percentage of area covered by class\n",
        "    # クラスがカバーする領域の出力パーセンテージ\n",
        "    df['coverage'] = np.mean(masks, axis=(1, 2))\n",
        "    # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
        "    # because each coverage will occur only once.\n",
        "    # カバレッジはビンに分割する必要があります。そうしないと、階層化された分割ができません。\n",
        "    # 各カバレッジは1回だけ発生するためです。\n",
        "    df['coverage_class'] = df.coverage.map(\n",
        "        cov_to_class)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def create_depth_abs_channels(image_tensor):\n",
        "    image_tensor = image_tensor.astype(np.float32)\n",
        "    h, w, c = image_tensor.shape\n",
        "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
        "        image_tensor[row, :, 1] = const\n",
        "    image_tensor[:, :, 2] = (\n",
        "        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n",
        "\n",
        "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n",
        "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n",
        "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n",
        "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n",
        "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
        "\n",
        "    return image_tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fnt7Gz_xU81g"
      },
      "source": [
        "X_train = np.asarray(\n",
        "    [cv2.imread('/content/drive/MyDrive/unet/competition_data/train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
        "    dtype=np.uint8) / 255.X_train = np.asarray(\n",
        "    [cv2.imread('/content/drive/MyDrive/unet/competition_data/train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
        "    dtype=np.uint8) / 255.X_train = np.asarray(\n",
        "    [cv2.imread('/content/drive/MyDrive/unet/competition_data/train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
        "    dtype=np.uint8) / 255.X_train = np.asarray(\n",
        "    [cv2.imread('/content/drive/MyDrive/unet/competition_data/train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
        "    dtype=np.uint8) / 255.X_train = np.asarray(\n",
        "    [cv2.imread('/content/drive/MyDrive/unet/competition_data/train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
        "    dtype=np.uint8) / 255.X_train = np.asarray(\n",
        "    [cv2.imread('/content/drive/MyDrive/unet/competition_data/train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
        "    dtype=np.uint8) / 255.X_train = np.asarray(\n",
        "    [cv2.imread('/content/drive/MyDrive/unet/competition_data/train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
        "    dtype=np.uint8) / 255.X_train = np.asarray(\n",
        "    [cv2.imread('/content/drive/MyDrive/unet/competition_data/train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
        "    dtype=np.uint8) / 255.X_train = np.asarray(\n",
        "    [cv2.imread('/content/drive/MyDrive/unet/competition_data/train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
        "    dtype=np.uint8) / 255.X_train = np.asarray(\n",
        "    [cv2.imread('/content/drive/MyDrive/unet/competition_data/train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
        "    dtype=np.uint8) / 255.X_train = np.asarray(\n",
        "    [cv2.imread('/content/drive/MyDrive/unet/competition_data/train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
        "    dtype=np.uint8) / 255.X_train = np.asarray(\n",
        "    [cv2.imread('/content/drive/MyDrive/unet/competition_data/train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
        "    dtype=np.uint8) / 255.vvccccaaaaaaaaaaaaaaaaaaaaaa Data loading & depth merge:(データの読み込みと深度のマージ：)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTkZFqwEU81h",
        "outputId": "a5cc7c5a-9b9c-4dd9-9b48-0d7825eac9c5"
      },
      "source": [
        "train = pd.read_csv('competition_data/train.csv')\n",
        "# test = pd.read_csv('competition_data/sample_submission.csv')\n",
        "depth = pd.read_csv('competition_data/depths.csv')\n",
        "\n",
        "train_src = '../input/train/'\n",
        "\n",
        "print('train:\\n{}'.format(train.head()))\n",
        "print('\\ntest:\\n{}'.format(test.head()))\n",
        "\n",
        "\n",
        "train = train.merge(depth, how='left', on='id')\n",
        "# test = test.merge(depth, how='left', on='id')\n",
        "\n",
        "print('\\n{}'.format(train.head()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train:\n",
            "           id  ... 000e218f21.png\n",
            "0  000e218f21  ...            NaN\n",
            "1  003c477d7c  ...            NaN\n",
            "2  00441f1cf2  ...            NaN\n",
            "3  0050766ae2  ...            NaN\n",
            "4  005b452274  ...            NaN\n",
            "\n",
            "[5 rows x 3 columns]\n",
            "\n",
            "test:\n",
            "           id rle_mask    z\n",
            "0  3e06571ef3      1 1  232\n",
            "1  a51b08d882      1 1  470\n",
            "2  c32590b06f      1 1  682\n",
            "3  15f7a047c7      1 1  653\n",
            "4  e8827bc832      1 1  103\n",
            "\n",
            "           id  ...    z\n",
            "0  000e218f21  ...  841\n",
            "1  003c477d7c  ...  673\n",
            "2  00441f1cf2  ...  330\n",
            "3  0050766ae2  ...  835\n",
            "4  005b452274  ...  657\n",
            "\n",
            "[5 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlsRWmqvU81j"
      },
      "source": [
        "### Load images and masks, examine random sample:  \n",
        "画像とマスクをロードし、ランダムサンプルを調べます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TecLSQTHbKV7"
      },
      "source": [
        "X_train = np.asarray(\n",
        "    [cv2.imread('/content/drive/MyDrive/unet/competition_data/train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
        "    dtype=np.uint8) / 255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGNeUr6LIlOf"
      },
      "source": [
        "y_train = np.asarray(\n",
        "    [cv2.imread('/content/drive/MyDrive/unet/competition_data/train/masks/{}.png'.format(x), 0) for x in train.id.tolist()],\n",
        "    dtype=np.uint8) / 255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fs1ZEAVQI3dW",
        "outputId": "f1af1d54-e32f-4787-d2e9-7e71d1802581"
      },
      "source": [
        "print(X_train.shape, y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9, 101, 101) (9, 101, 101)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "7Z1HdRsfU81k",
        "scrolled": true,
        "outputId": "0095fc5c-8872-43d4-ad9a-5bb0166543c8"
      },
      "source": [
        "random_index = np.random.randint(0, X_train.shape[0])\n",
        "\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "\n",
        "ax[0].imshow(X_train[random_index], cmap='gray')\n",
        "ax[1].imshow(y_train[random_index], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f9bfaf4a8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfFlHzNJU81k"
      },
      "source": [
        "### Compute salt coverage (this will serve as a basis for stratified split):  \n",
        "ソルトカバレッジを計算します（これは、階層化された分割の基礎として機能します）。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3Nw_pVwU81l"
      },
      "source": [
        "train = compute_coverage(train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXG4905fU81l"
      },
      "source": [
        "### Prepare data for training:  \n",
        "トレーニング用のデータを準備します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PoCQfplU81l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c80fa8d-c690-402e-da07-9d1262ef5bed"
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=2, random_state=1337)\n",
        "\n",
        "# Add channel features\n",
        "# チャネル機能を追加する\n",
        "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)\n",
        "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n",
        "\n",
        "# Resize to 224x224, default VGG19 image size\n",
        "# 224x224、デフォルトのVGG19画像サイズにサイズ変更します\n",
        "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
        "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
        "\n",
        "\n",
        "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n",
        "    \n",
        "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
        "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
        "    \n",
        "    break\n",
        "    \n",
        "\n",
        "y_tr = np.expand_dims(y_tr, axis=-1)\n",
        "y_val = np.expand_dims(y_val, axis=-1)\n",
        "\n",
        "print(X_tr.shape, y_tr.shape)\n",
        "print(X_val.shape, y_val.shape)\n",
        "\n",
        "\n",
        "del X_train_ch, y_resized\n",
        "del X_resized\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(4, 224, 224, 3) (4, 224, 224, 1)\n",
            "(5, 224, 224, 3) (5, 224, 224, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "627"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NViQ1BdyU81m"
      },
      "source": [
        "### Loss functions & metric:  \n",
        "損失関数とメトリック："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vTQjPh8U81m"
      },
      "source": [
        "from keras.losses import binary_crossentropy\n",
        "\n",
        "\n",
        "# Dice & combined\n",
        "# サイコロと組み合わせ\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred = K.cast(y_pred, 'float32')\n",
        "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
        "    return score\n",
        "\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return 1. - score\n",
        "\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "\n",
        "\n",
        "def bce_logdice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
        "\n",
        "\n",
        "\n",
        "# Lovash loss:  https://github.com/bermanmaxim/LovaszSoftmax\n",
        "def lovasz_grad(gt_sorted):\n",
        "    \"\"\"\n",
        "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
        "    See Alg. 1 in paper\n",
        "    Lovasz拡張機能の勾配を計算しますw.r.tソートされたエラー Algを参照してください。紙に1\n",
        "    \"\"\"\n",
        "    gts = tf.reduce_sum(gt_sorted)\n",
        "    intersection = gts - tf.cumsum(gt_sorted)\n",
        "    union = gts + tf.cumsum(1. - gt_sorted)\n",
        "    jaccard = 1. - intersection / union\n",
        "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
        "    return jaccard\n",
        "\n",
        "\n",
        "# --------------------------- BINARY LOSSES ---------------------------バイナリ損失\n",
        "\n",
        "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
        "    \"\"\"\n",
        "    Binary Lovasz hinge loss\n",
        "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
        "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
        "      per_image: compute the loss per image instead of per batch\n",
        "      ignore: void class id\n",
        "\n",
        "      バイナリLovaszヒンジ損失 ロジット：\n",
        "      [B、H、W]変数、各ピクセルでのロジット（-\\ inftyと+ \\ inftyの間）\n",
        "      ラベル：[B、H、W]テンソル、バイナリグラウンドトゥルースマスク（0または1） \n",
        "      per_image：バッチごとではなく画像ごとの損失を計算します 無視：voidクラスID\n",
        "    \"\"\"\n",
        "    if per_image:\n",
        "        def treat_image(log_lab):\n",
        "            log, lab = log_lab\n",
        "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
        "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
        "            return lovasz_hinge_flat(log, lab)\n",
        "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
        "        loss = tf.reduce_mean(losses)\n",
        "    else:\n",
        "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
        "    return loss\n",
        "\n",
        "\n",
        "def lovasz_hinge_flat(logits, labels):\n",
        "    \"\"\"\n",
        "    Binary Lovasz hinge loss\n",
        "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
        "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
        "      ignore: label to ignore\n",
        "      \n",
        "      バイナリLovaszヒンジ損失 ロジット：\n",
        "      [P]変数、各予測でのロジット（-\\ inftyと+ \\ inftyの間）\n",
        "      ラベル：[P]テンソル、バイナリグラウンドトゥルースラベル（0または1） 無視：無視するラベル\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def compute_loss():\n",
        "        labelsf = tf.cast(labels, logits.dtype)\n",
        "        signs = 2. * labelsf - 1.\n",
        "        errors = 1. - logits * tf.stop_gradient(signs)\n",
        "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
        "        gt_sorted = tf.gather(labelsf, perm)\n",
        "        grad = lovasz_grad(gt_sorted)\n",
        "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
        "        return loss\n",
        "\n",
        "    # deal with the void prediction case (only void pixels)\n",
        "    # ボイド予測の場合に対処する（ボイドピクセルのみ）\n",
        "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
        "                   lambda: tf.reduce_sum(logits) * 0.,\n",
        "                   compute_loss,\n",
        "                   strict=True,\n",
        "                   name=\"loss\"\n",
        "                   )\n",
        "    return loss\n",
        "\n",
        "\n",
        "def flatten_binary_scores(scores, labels, ignore=None):\n",
        "    \"\"\"\n",
        "    Flattens predictions in the batch (binary case)\n",
        "    Remove labels equal to 'ignore'\n",
        "\n",
        "    バッチ内の予測をフラット化します（バイナリの場合） 'ignore'に等しいラベルを削除します\n",
        "    \"\"\"\n",
        "    scores = tf.reshape(scores, (-1,))\n",
        "    labels = tf.reshape(labels, (-1,))\n",
        "    if ignore is None:\n",
        "        return scores, labels\n",
        "    valid = tf.not_equal(labels, ignore)\n",
        "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
        "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
        "    return vscores, vlabels\n",
        "\n",
        "\n",
        "def lovasz_loss(y_true, y_pred):\n",
        "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
        "    #logits = K.log(y_pred / (1. - y_pred))\n",
        "    logits = y_pred #Jiaxin\n",
        "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
        "    return loss\n",
        "\n",
        "\n",
        "# IoU metric for observation during training\n",
        "# トレーニング中の観察のためのoUメトリック\n",
        "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
        "def get_iou_vector(A, B):\n",
        "    # Numpy version    \n",
        "    batch_size = A.shape[0]\n",
        "    metric = 0.0\n",
        "    for batch in range(batch_size):\n",
        "        t, p = A[batch], B[batch]\n",
        "        true = np.sum(t)\n",
        "        pred = np.sum(p)\n",
        "        \n",
        "        # deal with empty mask first\n",
        "        # 最初に空のマスクを処理します\n",
        "        if true == 0:\n",
        "            metric += (pred == 0)\n",
        "            continue\n",
        "        \n",
        "        # non empty mask case.  Union is never empty \n",
        "        # 空のマスクケースに。ユニオンは決して空ではありません\n",
        "        # hence it is safe to divide by its number of pixels\n",
        "        # したがって、ピクセル数で割っても安全です。\n",
        "        intersection = np.sum(t * p)\n",
        "        union = true + pred - intersection\n",
        "        iou = intersection / union\n",
        "        \n",
        "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
        "        # iou metrricは、0.5を超える実際のiouの段階的な近似です。\n",
        "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
        "        \n",
        "        metric += iou\n",
        "        \n",
        "    # teake the average over all images in batch\n",
        "    # バッチですべての画像の平均をティークします\n",
        "    metric /= batch_size\n",
        "    return metric\n",
        "\n",
        "\n",
        "def my_iou_metric(label, pred):\n",
        "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
        "\n",
        "\n",
        "# For Lovash loss\n",
        "# Lovashの損失について\n",
        "def my_iou_metric_2(label, pred):\n",
        "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--jKqObGU81r"
      },
      "source": [
        "### Encoder features - ResNet50:\n",
        "\n",
        "In ResNet50, each block finishes with a pooling layer, so we can extract features from intermediate layers just before the pooling. This way, when first layer is added as additional extractor, we will have features extracted from 5 layers.\n",
        "Default input size will be assumed, which is (224, 224, 3).\n",
        "Layers will be as follows:\n",
        "\n",
        "- 'activation_1', shape: (None, 112, 112, 64)\n",
        "- 'activation_10', shape: (None, 56, 56, 256)\n",
        "- 'activation_22', shape: (None, 28, 28, 512)\n",
        "- 'activation_40', shape: (None, 14, 14, 1024)\n",
        "- 'activation_49', shape: (None, 7, 7, 2048)\n",
        "\n",
        "One thing to keep in mind is that every time a model will be created in the same TF session in the notebook, layer names will change, so above layer names correspond to first creation of the model. In order to reset session, call `K.clear_session()`.  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**エンコーダー機能-ResNet50：**     \n",
        "ResNet50では、各ブロックはプーリングレイヤーで終了するため、プーリングの直前に中間レイヤーからフィーチャを抽出できます。このようにして、最初のレイヤーが追加の抽出機能として追加されると、5つのレイヤーからフィーチャが抽出されます。デフォルトの入力サイズ（（224、224、3））が想定されます。レイヤーは次のようになります。\n",
        "\n",
        "'activation_1'、形状：（なし、112、112、64） 'activation_10'、形状：（なし、56、56、256） 'activation_22'、形状：（なし、28、28、512） 'activation_40'、形状：（なし、14、14、1024） 'activation_49'、形状：（なし、7、7、2048） 注意すべきことは、ノートブック内の同じTFセッションでモデルが作成されるたびにレイヤー名が変更されるため、上記のレイヤー名はモデルの最初の作成に対応するということです。セッションをリセットするには、を呼び出しますK.clear_session()。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUqgCM4vU81w",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "647f9537-728c-4d6f-ed08-c66d473c2361"
      },
      "source": [
        "input_size = (224, 224, 3)\n",
        "\n",
        "base_model = VGG19(input_shape=input_size, include_top=False)\n",
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "=================================================================\n",
            "Total params: 20,024,384\n",
            "Trainable params: 20,024,384\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgHsswOBU81x"
      },
      "source": [
        "### Decoder blocks:\n",
        "\n",
        "Features from ResNet50 will serve as a basis for encoder part of the segmentation model, now a decoder part is needed.\n",
        "For this part, we will have to create our own blocks. Let's create a very basic block and a second one, which structure will have a more complicated structure.  \n",
        "\n",
        "**デコーダーブロック：**  \n",
        "\n",
        "ResNet50の機能は、セグメンテーションモデルのエンコーダー部分の基盤として機能しますが、現在はデコーダー部分が必要です。 この部分では、独自のブロックを作成する必要があります。 非常に基本的なブロックと2つ目のブロックを作成してみましょう。この構造はより複雑な構造になります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7QG9RMmU81x"
      },
      "source": [
        "# Basic decoder block with Conv, BN and PReLU activation.　　\n",
        "# Conv、BN、およびPReLUがアクティブ化された基本的なデコーダーブロック。\n",
        "def decoder_block_simple(\n",
        "        layer_name, block_name,\n",
        "        num_filters=32,\n",
        "        conv_dim=(3, 3)):\n",
        "\n",
        "    x_dec = Conv2D(\n",
        "        num_filters, conv_dim,\n",
        "        padding='same',\n",
        "        name='{}_conv'.format(block_name))(layer_name)\n",
        "    x_dec = BatchNormalization(\n",
        "        name='{}_bn'.format(block_name))(x_dec)\n",
        "    x_dec = PReLU(\n",
        "        name='{}_activation'.format(block_name))(x_dec)\n",
        "\n",
        "    return x_dec\n",
        "\n",
        "# Decoder block with bottleneck architecture, where middle conv layer\n",
        "# is half the size of first and last, in order to compress representation.\n",
        "# This type of architecture is supposed to retain most useful information.  \n",
        "# ボトルネックアーキテクチャを備えたデコーダブロック。中間コンバードレイヤー\n",
        "# は、表現を圧縮するために、最初と最後の半分のサイズです。\n",
        "# このタイプのアーキテクチャは、最も有用な情報を保持することになっています。\n",
        "\n",
        "def decoder_block_bottleneck(\n",
        "        layer_name, block_name,\n",
        "        num_filters=32,\n",
        "        conv_dim=(3, 3),\n",
        "        dropout_frac=0.2):\n",
        "\n",
        "    x_dec = Conv2D(\n",
        "        num_filters, conv_dim,\n",
        "        padding='same',\n",
        "        name='{}_conv1'.format(block_name))(layer_name)\n",
        "    x_dec = BatchNormalization(\n",
        "        name='{}_bn1'.format(block_name))(x_dec)\n",
        "    x_dec = PReLU(\n",
        "        name='{}_activation1'.format(block_name))(x_dec)\n",
        "    x_dec = Dropout(dropout_frac)(x_dec)\n",
        "\n",
        "    x_dec2 = Conv2D(\n",
        "        num_filters // 2, conv_dim,\n",
        "        padding='same',\n",
        "        name='{}_conv2'.format(block_name))(x_dec)\n",
        "    x_dec2 = BatchNormalization(\n",
        "        name='{}_bn2'.format(block_name))(x_dec2)\n",
        "    x_dec2 = PReLU(\n",
        "        name='{}_activation2'.format(block_name))(x_dec2)\n",
        "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
        "\n",
        "    x_dec2 = Conv2D(\n",
        "        num_filters, conv_dim,\n",
        "        padding='same',\n",
        "        name='{}_conv3'.format(block_name))(x_dec2)\n",
        "    x_dec2 = BatchNormalization(\n",
        "        name='{}_bn3'.format(block_name))(x_dec2)\n",
        "    x_dec2 = PReLU(\n",
        "        name='{}_activation3'.format(block_name))(x_dec2)\n",
        "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
        "\n",
        "    x_dec2 = Add()([x_dec, x_dec2])\n",
        "\n",
        "    return x_dec2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjE8MBy5U81y"
      },
      "source": [
        "### Model definition:\n",
        "\n",
        "Combine encoder and decoder blocks to create final segmentation model.  \n",
        "\n",
        "**モデル定義**  \n",
        "エンコーダーブロックとデコーダーブロックを組み合わせて、最終的なセグメンテーションモデルを作成します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OMZuhzAU81y"
      },
      "source": [
        "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
        "# as this is an argument that can be given a function, like decoder_block_simple.\n",
        "# モデルは、decoder_blockタイプを簡単に変更できるようにパラメーター化されています。\n",
        "# これは、decoder_block_simpleのような関数を指定できる引数であるためです。\n",
        "\n",
        "def unet_resnet(input_size, decoder_block,\n",
        "                weights='imagenet',\n",
        "                loss_func='binary_crossentropy',\n",
        "                metrics_list=[my_iou_metric],\n",
        "                use_lovash=False):\n",
        "\n",
        "    # Base model - encoder\n",
        "    base_model = VGG19(\n",
        "        input_shape=input_size, \n",
        "        include_top=False,\n",
        "        weights=weights)\n",
        "    \n",
        "    # Layers for feature extraction in the encoder part\n",
        "    encoder1 = base_model.get_layer('block2_conv2').output # activation_1\n",
        "    encoder2 = base_model.get_layer('block3_conv2').output # activation_10\n",
        "    encoder3 = base_model.get_layer('block4_conv3').output # activation_22\n",
        "    encoder4 = base_model.get_layer('block5_conv3').output # activation_40\n",
        "    encoder5 = base_model.get_layer('block5_pool').output # activation_40\n",
        "\n",
        "    # Center block\n",
        "    center = decoder_block(\n",
        "        encoder5, 'center', num_filters=512)\n",
        "    concat5 = concatenate([center, encoder5], axis=-1)\n",
        "\n",
        "    # Decoder part.\n",
        "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
        "    # This creates skip connections.\n",
        "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
        "    decoder4 = decoder_block(\n",
        "        concat5, 'decoder4', num_filters=256)\n",
        "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
        "\n",
        "    decoder3 = decoder_block(\n",
        "        concat4, 'decoder3', num_filters=128)\n",
        "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
        "\n",
        "    decoder2 = decoder_block(\n",
        "        concat3, 'decoder2', num_filters=64)\n",
        "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
        "\n",
        "    decoder1 = decoder_block(\n",
        "        concat2, 'decoder1', num_filters=64)\n",
        "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
        "\n",
        "    # Final upsampling and decoder block for segmentation.\n",
        "    output = UpSampling2D()(concat1)\n",
        "    output = decoder_block(\n",
        "        output, 'decoder_output', num_filters=32)\n",
        "    output = Conv2D(\n",
        "        1, (1, 1), activation=None, name='prediction')(output)\n",
        "    if not use_lovash:\n",
        "        output = Activation('sigmoid')(output)\n",
        "        \n",
        "    model = Model(base_model.input, output)\n",
        "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pUb3CnXU81y"
      },
      "source": [
        "### Inspect created model:  \n",
        "作成されたモデルを検査します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ed5gC-6U81z",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61820ccc-330a-41e2-a21d-98de3833d9b0"
      },
      "source": [
        "input_size = (224, 224, 3)\n",
        "\n",
        "K.clear_session()\n",
        "model = unet_resnet(\n",
        "    input_size, decoder_block_simple, weights='imagenet')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From <ipython-input-47-5341f7a615d0>:174: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv4 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv4 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv4 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_conv (Conv2D)            (None, 7, 7, 512)    2359808     block5_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "center_bn (BatchNormalization)  (None, 7, 7, 512)    2048        center_conv[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "center_activation (PReLU)       (None, 7, 7, 512)    25088       center_bn[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 7, 7, 1024)   0           center_activation[0][0]          \n",
            "                                                                 block5_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv (Conv2D)          (None, 7, 7, 256)    2359552     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn (BatchNormalization (None, 7, 7, 256)    1024        decoder4_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation (PReLU)     (None, 7, 7, 256)    12544       decoder4_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           decoder4_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 14, 14, 768)  0           up_sampling2d_1[0][0]            \n",
            "                                                                 block5_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv (Conv2D)          (None, 14, 14, 128)  884864      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn (BatchNormalization (None, 14, 14, 128)  512         decoder3_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation (PReLU)     (None, 14, 14, 128)  25088       decoder3_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           decoder3_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv (Conv2D)          (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn (BatchNormalization (None, 28, 28, 64)   256         decoder2_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation (PReLU)     (None, 28, 28, 64)   50176       decoder2_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           decoder2_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
            "                                                                 block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv (Conv2D)          (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn (BatchNormalization (None, 56, 56, 64)   256         decoder1_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation (PReLU)     (None, 56, 56, 64)   200704      decoder1_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           decoder1_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 112, 112, 192 0           up_sampling2d_4[0][0]            \n",
            "                                                                 block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 192 0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 55328       up_sampling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 28,160,513\n",
            "Trainable params: 28,158,401\n",
            "Non-trainable params: 2,112\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUP_nqaFU81z"
      },
      "source": [
        "### Train model:  \n",
        "学習モデル"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LASS_GUuU810",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b7abc56-9b74-4a08-b91d-12712eb42914"
      },
      "source": [
        "K.clear_session()\n",
        "\n",
        "# Build model:\n",
        "# Here, you can experiment with various losses.\n",
        "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
        "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
        "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
        "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
        "# This is controlled by use_lovash parameter.\n",
        "model_depth = unet_resnet(\n",
        "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
        "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
        "    use_lovash=False)\n",
        "print(model_depth.summary())\n",
        "\n",
        "\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n",
        "    save_best_only=True, save_weights_only=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_my_iou_metric',\n",
        "    mode='max',\n",
        "    factor=0.5, \n",
        "    patience=5, \n",
        "    min_lr=0.0001, \n",
        "    verbose=1)\n",
        "\n",
        "\n",
        "epochs = 10  # 25\n",
        "batch_size = 16\n",
        "\n",
        "history = model_depth.fit(X_tr, y_tr,\n",
        "                    validation_data=[X_val, y_val], \n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    callbacks=[model_checkpoint,reduce_lr], \n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv4 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv4 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv4 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_conv1 (Conv2D)           (None, 7, 7, 512)    2359808     block5_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
            "                                                                 dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 7, 7, 1024)   0           add_1[0][0]                      \n",
            "                                                                 block5_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    2359552     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 7, 7, 256)    0           dropout_4[0][0]                  \n",
            "                                                                 dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 14, 14, 768)  0           up_sampling2d_1[0][0]            \n",
            "                                                                 block5_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  884864      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 14, 14, 128)  0           dropout_7[0][0]                  \n",
            "                                                                 dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 64)   0           dropout_10[0][0]                 \n",
            "                                                                 dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
            "                                                                 block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 56, 56, 64)   0           dropout_13[0][0]                 \n",
            "                                                                 dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 112, 112, 192 0           up_sampling2d_4[0][0]            \n",
            "                                                                 block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 192 0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 55328       up_sampling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
            "                                                                 dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Conv2D)             (None, 224, 224, 1)  33          add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 34,226,801\n",
            "Trainable params: 34,221,521\n",
            "Non-trainable params: 5,280\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 4 samples, validate on 5 samples\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 31s 8s/step - loss: 1.5410 - my_iou_metric: 0.0000e+00 - val_loss: 3.8463 - val_my_iou_metric: 0.0000e+00\n",
            "\n",
            "Epoch 00001: val_my_iou_metric improved from -inf to 0.00000, saving model to unet_resnet.h5\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 20s 5s/step - loss: 1.3199 - my_iou_metric: 0.0500 - val_loss: 3.6313 - val_my_iou_metric: 0.0000e+00\n",
            "\n",
            "Epoch 00002: val_my_iou_metric did not improve from 0.00000\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 20s 5s/step - loss: 1.1916 - my_iou_metric: 0.0500 - val_loss: 2.5778 - val_my_iou_metric: 0.0000e+00\n",
            "\n",
            "Epoch 00003: val_my_iou_metric did not improve from 0.00000\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 20s 5s/step - loss: 1.0996 - my_iou_metric: 0.0500 - val_loss: 1.9333 - val_my_iou_metric: 0.0000e+00\n",
            "\n",
            "Epoch 00004: val_my_iou_metric did not improve from 0.00000\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 20s 5s/step - loss: 1.0190 - my_iou_metric: 0.0500 - val_loss: 1.7088 - val_my_iou_metric: 0.0000e+00\n",
            "\n",
            "Epoch 00005: val_my_iou_metric did not improve from 0.00000\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 20s 5s/step - loss: 0.9394 - my_iou_metric: 0.0750 - val_loss: 1.3616 - val_my_iou_metric: 0.0000e+00\n",
            "\n",
            "Epoch 00006: val_my_iou_metric did not improve from 0.00000\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 20s 5s/step - loss: 0.8759 - my_iou_metric: 0.0750 - val_loss: 1.3127 - val_my_iou_metric: 0.0000e+00\n",
            "\n",
            "Epoch 00007: val_my_iou_metric did not improve from 0.00000\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 20s 5s/step - loss: 0.8182 - my_iou_metric: 0.1000 - val_loss: 1.2753 - val_my_iou_metric: 0.0000e+00\n",
            "\n",
            "Epoch 00008: val_my_iou_metric did not improve from 0.00000\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 20s 5s/step - loss: 0.7840 - my_iou_metric: 0.1000 - val_loss: 1.2966 - val_my_iou_metric: 0.0000e+00\n",
            "\n",
            "Epoch 00009: val_my_iou_metric did not improve from 0.00000\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 20s 5s/step - loss: 0.7276 - my_iou_metric: 0.1250 - val_loss: 1.5803 - val_my_iou_metric: 0.0800\n",
            "\n",
            "Epoch 00010: val_my_iou_metric improved from 0.00000 to 0.08000, saving model to unet_resnet.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6iuzpHjU810"
      },
      "source": [
        "### Validation set prediction and resizing to original size:　　\n",
        "検証セットの予測と元のサイズへのサイズ変更："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_zt4C-jU810"
      },
      "source": [
        "val_preds = model_depth.predict(X_val, batch_size=16)\n",
        "\n",
        "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
        "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMAfQJAvU811"
      },
      "source": [
        "### Threshold optimization: 　　\n",
        "しきい値の最適化："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQ2GWQoFU811"
      },
      "source": [
        "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
        "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
        "    labels = y_true_in\n",
        "    y_pred = y_pred_in\n",
        "    \n",
        "    true_objects = 2\n",
        "    pred_objects = 2\n",
        "\n",
        "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
        "\n",
        "    # Compute areas (needed for finding the union between all objects)\n",
        "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
        "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
        "    area_true = np.expand_dims(area_true, -1)\n",
        "    area_pred = np.expand_dims(area_pred, 0)\n",
        "\n",
        "    # Compute union\n",
        "    union = area_true + area_pred - intersection\n",
        "\n",
        "    # Exclude background from the analysis\n",
        "    intersection = intersection[1:,1:]\n",
        "    union = union[1:,1:]\n",
        "    union[union == 0] = 1e-9\n",
        "\n",
        "    # Compute the intersection over union\n",
        "    iou = intersection / union\n",
        "\n",
        "    # Precision helper function\n",
        "    def precision_at(threshold, iou):\n",
        "        matches = iou > threshold\n",
        "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
        "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
        "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
        "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
        "        return tp, fp, fn\n",
        "\n",
        "    # Loop over IoU thresholds\n",
        "    prec = []\n",
        "    if print_table:\n",
        "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
        "    for t in np.arange(0.5, 1.0, 0.05):\n",
        "        tp, fp, fn = precision_at(t, iou)\n",
        "        if (tp + fp + fn) > 0:\n",
        "            p = tp / (tp + fp + fn)\n",
        "        else:\n",
        "            p = 0\n",
        "        if print_table:\n",
        "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
        "        prec.append(p)\n",
        "    \n",
        "    if print_table:\n",
        "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
        "    return np.mean(prec)\n",
        "\n",
        "def iou_metric_batch(y_true_in, y_pred_in):\n",
        "    batch_size = y_true_in.shape[0]\n",
        "    metric = []\n",
        "    for batch in range(batch_size):\n",
        "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
        "        metric.append(value)\n",
        "    return np.mean(metric)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND5PkuB3U811",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23578cb8-0a04-4d91-bfce-f8e67105c79d"
      },
      "source": [
        "# Threshold range, over which optimization is performed\n",
        "thresholds = np.arange(0.2, 0.9, 0.02)\n",
        "\n",
        "# For every threshold, set predictions to binary arrays, \n",
        "# where values above threshold are treated as 1 and the rest as 0.\n",
        "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
        "ious = np.array(\n",
        "    [iou_metric_batch(y_val_true,\n",
        "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:00<00:00, 106.76it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yn-sLWgOU812",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "c4f1c0f9-5212-4ef0-d8ab-c6b4d4ed06f0"
      },
      "source": [
        "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
        "df_iou['iou'] = ious\n",
        "\n",
        "# Get index of best IoU\n",
        "best_index = df_iou['iou'].idxmax()\n",
        "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
        "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
        "\n",
        "# Describe IoU DF\n",
        "df_iou.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best IoU: 0.5200 at threshold: 0.200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>threshold</th>\n",
              "      <th>iou</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.198857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.204939</td>\n",
              "      <td>0.196974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.370000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.160000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.380000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.520000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       threshold        iou\n",
              "count  35.000000  35.000000\n",
              "mean    0.540000   0.198857\n",
              "std     0.204939   0.196974\n",
              "min     0.200000   0.000000\n",
              "25%     0.370000   0.000000\n",
              "50%     0.540000   0.160000\n",
              "75%     0.710000   0.380000\n",
              "max     0.880000   0.520000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY6TS42dU812",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "outputId": "ea2b7a73-55aa-4392-c7ae-c624605146ba"
      },
      "source": [
        "# Plot IoU values over threshold range.\n",
        "df_iou.plot(x='threshold', y='iou')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9be77151d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "We3pLALfU812"
      },
      "source": [
        "## Conclusions:\n",
        "\n",
        "- Pretrained models can be used for segmentation problems:\n",
        "    - Some of architectures can be easily adapted to the problem (ie ResNet)\n",
        "    - Other architectures may require more experimentation with selection of proper layers for feature extraction and padding (example of using [Xception](https://www.kaggle.com/meaninglesslives/getting-0-87-on-private-lb-using-kaggle-kernel). )\n",
        "    - You can experiment with selection of layers for feature extraction\n",
        "    - For some models, you can also try to experiment with number of encoder/decoder blocks\n",
        "- Threshold optimization is important in problems, where direct metric optimization during training is difficult.\n",
        "    - It it possible to use more involved optimization methods (from [scipy optimize](https://docs.scipy.org/doc/scipy/reference/optimize.html)), although this may not be optimal unless distribution of train and test set are very similar. Overoptimization of threshold or any other parameter on validation set may result in worse test set results.\n",
        "- Experiment with various losses - BCE, Dice, combined BCE with Dice, Lovash loss.\n",
        "    - Models trained with various losses may give different results, which may be advantageous when ensembling.\n",
        "\n",
        "\n",
        "### Possible experiments:\n",
        "\n",
        "- Change type of decoder block in created segmentation model\n",
        "- Create your own decoder blocks\n",
        "- Train with other losses\n",
        "- Train longer\n",
        "- Train with BCE/Dice, save the model, then load weights and finetune with Lovash loss\n",
        "- Try different ranges and intervals for threshold optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCh5HC_nkvQp"
      },
      "source": [
        "# 結論：\n",
        "\n",
        "- 事前学習済みのモデルは、セグメンテーションの問題に使用できます。\n",
        "  - 一部のアーキテクチャは、問題に簡単に適合させることができます（ResNetなど）     \n",
        "  - 他のアーキテクチャでは、機能の抽出とパディングに適切なレイヤーを選択するためのより多くの実験が必要になる場合があります（[Xception]（https://www.kaggle.com/meaninglesslives/getting-0-87-on-private-lb-usingの使用例） -kaggle-kernel）。）     \n",
        "  - 特徴抽出用のレイヤーの選択を試すことができます  \n",
        "  - 一部のモデルでは、エンコーダー/デコーダーブロックの数を試してみることができます \n",
        "- トレーニング中の直接的なメトリック最適化が難しい問題では、しきい値の最適化が重要です。     \n",
        " - より複雑な最適化方法を使用することが可能です（[scipy optimize]（https://docs.scipy.org/doc/scipy/reference/optimize.html）から）。ただし、これは列車とテストセットは非常に似ています。検証セットのしきい値またはその他のパラメーターを過剰に最適化すると、テストセットの結果が悪化する可能性があります。 \n",
        "- さまざまな損失の実験-BCE、Dice、BCEとDice、Lovashの損失の組み合わせ。     \n",
        " - さまざまな損失で訓練されたモデルは異なる結果をもたらす可能性があり、これは組み立てるときに有利になる場合があります。\n",
        "\n",
        "# 可能な実験：\n",
        "- 作成されたセグメンテーションモデルのデコーダブロックのタイプを変更 \n",
        "- 独自のデコーダーブロックを作成 -他の損失を伴う訓練 \n",
        "- より長くトレーニング -BCE / Diceでトレーニングし、モデルを保存してから、Lovashの損失で重量をロードして微調整します \n",
        "- しきい値の最適化のために異なる範囲と間隔を試してください"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS2jbbG8U813",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4771d12-a6b3-44e7-ce02-45d10d71aac2"
      },
      "source": [
        "np.int32(0.7 > 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQJcGU95U813"
      },
      "source": [
        "def get_iou_vector(A, B):\n",
        "    # Numpy version\n",
        "    \n",
        "    batch_size = A.shape[0]\n",
        "    metric = 0.0\n",
        "    for batch in range(batch_size):\n",
        "        t, p = A[batch], B[batch]\n",
        "        true = np.sum(t)\n",
        "        pred = np.sum(p)\n",
        "        \n",
        "        # deal with empty mask first\n",
        "        if true == 0:\n",
        "            metric += (pred == 0)\n",
        "            continue\n",
        "        \n",
        "        # non empty mask case.  Union is never empty \n",
        "        # hence it is safe to divide by its number of pixels\n",
        "        intersection = np.sum(t * p)\n",
        "        union = true + pred - intersection\n",
        "        iou = intersection / union\n",
        "        \n",
        "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
        "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
        "        \n",
        "        metric += iou\n",
        "        \n",
        "    # teake the average over all images in batch\n",
        "    metric /= batch_size\n",
        "    return metric"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rteqfOvLGjrs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}