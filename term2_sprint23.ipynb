{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "term2_sprint23.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1W8-9TpAyLO3FbvdPuYyPePcWDqX4r74N",
      "authorship_tag": "ABX9TyMSg7e4PGGfQoFT0wenLW6E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/T-Sawao/diveintocode-ml3/blob/main/term2_sprint23.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTZxWm6erz_M"
      },
      "source": [
        "# term2_sprint23 ゲート付きリカレントニューラルネットワーク"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE5ToodZrtRp"
      },
      "source": [
        "## 1.このSprintについて\n",
        "\n",
        "### Sprintの目的\n",
        "発展的なRNNの手法を理解する\n",
        "ドキュメントを網羅的に読む\n",
        "\n",
        "### どのように学ぶか\n",
        "Kerasに用意されているRNN関係のレイヤーを動作させながら学んでいきます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eixa3fS73FXS"
      },
      "source": [
        "## 2.KerasのRecurrentレイヤー\n",
        "\n",
        "Kerasには複数のRecurrentレイヤーや、それに関連したクラスが用意されています。今回のSprintではこれら全てを動かした上で、それぞれの役割を説明できる状態を目指します。\n",
        "\n",
        "\n",
        "以下のドキュメントにまとめられています。\n",
        "\n",
        "\n",
        "Recurrentレイヤー - Keras Documentation  \n",
        "https://keras.io/ja/layers/recurrent/\n",
        "\n",
        "\n",
        "## 【問題1】各種手法の実行\n",
        "Kerasには4種類のReccurentレイヤーが用意されています。SimpleRNN以外はゲート付きリカレントニューラルネットワークです。\n",
        "\n",
        "\n",
        "SimpleRNN\n",
        "GRU\n",
        "LSTM\n",
        "ConvLSTM2D\n",
        "\n",
        "これらを実行してください。この中でSimpleRNN、GRU、LSTMは同様のタスクに用いることができるため、精度の比較も行なってください。\n",
        "\n",
        "\n",
        "Keras公式のサンプルコードを利用してください。\n",
        "\n",
        "\n",
        "**LSTMのサンプルコード**\n",
        "\n",
        "\n",
        "keras-apache-mxnet/imdb_lstm.py at master · awslabs/keras-apache-mxnet  \n",
        "https://github.com/awslabs/keras-apache-mxnet/blob/master/examples/imdb_lstm.py\n",
        "\n",
        "**ConvLSTM2Dのサンプルコード**\n",
        "\n",
        "\n",
        "keras-apache-mxnet/conv_lstm.py at master · awslabs/keras-apache-mxnet  \n",
        "https://github.com/awslabs/keras-apache-mxnet/blob/master/examples/conv_lstm.py\n",
        "\n",
        "このサンプルコードをそのまま使う必要はなく、ノード数やエポックなどは変更して構いません。全て実行する上での実行時間を考慮した数に設定してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAoV4xSJseOb"
      },
      "source": [
        "### 0.0.0 （準備）データセット_IMDB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dtEXApCsZku"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKnbT8UYk_UG"
      },
      "source": [
        "### 1.1.1（解答）SimpleRNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxiqCCv9lE6Y"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import SimpleRNN\n",
        "from keras import backend as K\n",
        "\n",
        "# laywer作成\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(SimpleRNN(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# try using different optimizers and different optimizer configs\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Train...')\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=3,\n",
        "          validation_data=(x_test, y_test))\n",
        "score, acc = model.evaluate(x_test, y_test,\n",
        "                            batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVCuWhxRqa6T"
      },
      "source": [
        "### 1.2.1（解答） GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnTrMl37qmeh"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import GRU\n",
        "from keras import backend as K\n",
        "\n",
        "# laywer作成\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(GRU(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# try using different optimizers and different optimizer configs\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Train...')\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=3,\n",
        "          validation_data=(x_test, y_test))\n",
        "score, acc = model.evaluate(x_test, y_test,\n",
        "                            batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBXsY9W6jYTw"
      },
      "source": [
        "### 1.3.1 （解答）LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pY-odw7Te_O5"
      },
      "source": [
        " '''Trains an LSTM model on the IMDB sentiment classification task.\n",
        "The dataset is actually too small for LSTM to be of any advantage\n",
        "compared to simpler, much faster methods such as TF-IDF + LogReg.\n",
        "# Notes\n",
        "- RNNs are tricky. Choice of batch size is important,\n",
        "choice of loss and optimizer is critical, etc.\n",
        "Some configurations won't converge.\n",
        "- LSTM loss decrease patterns during training can be quite different\n",
        "from what you see with CNNs/MLPs/etc.\n",
        "'''\n",
        "from __future__ import print_function\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras import backend as K\n",
        "\n",
        "max_features = 20000\n",
        "# cut texts after this number of words (among top max_features most common words)\n",
        "maxlen = 80\n",
        "batch_size = 32\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# try using different optimizers and different optimizer configs\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Train...')\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=3,\n",
        "          validation_data=(x_test, y_test))\n",
        "score, acc = model.evaluate(x_test, y_test,\n",
        "                            batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfGPz1qOk09K"
      },
      "source": [
        "### 1.4.1（解答）ConvLSTM2D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBmDOLDmjFta"
      },
      "source": [
        "\"\"\"\n",
        "#This script demonstrates the use of a convolutional LSTM network.\n",
        "This network is used to predict the next frame of an artificially\n",
        "generated movie which contains moving squares.\n",
        "このスクリプトは、畳み込みLSTMネットワークの使用を示しています。\n",
        "このネットワークは、移動する正方形を含む人工的に生成された映画の次のフレームを予測するために使用されます。\n",
        "\"\"\"\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv3D\n",
        "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "import pylab as plt\n",
        "from keras import backend as K\n",
        "\n",
        "if K.backend() == 'mxnet':\n",
        "    raise NotImplementedError(\"MXNet Backend: ConvLSTM2D Layer is not supported yet.\")\n",
        "\n",
        "# We create a layer which take as input movies of shape\n",
        "# (n_frames, width, height, channels) and returns a movie\n",
        "# of identical shape.\n",
        "\n",
        "#形状のムービー（n_frames、幅、高さ、チャンネル）を入力として受け取り、\n",
        "#同じ形状のムービーを返すレイヤーを作成します。\n",
        "\n",
        "seq = Sequential()\n",
        "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
        "                   input_shape=(None, 40, 40, 1),\n",
        "                   padding='same', return_sequences=True))\n",
        "seq.add(BatchNormalization())\n",
        "\n",
        "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
        "                   padding='same', return_sequences=True))\n",
        "seq.add(BatchNormalization())\n",
        "\n",
        "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
        "                   padding='same', return_sequences=True))\n",
        "seq.add(BatchNormalization())\n",
        "\n",
        "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
        "                   padding='same', return_sequences=True))\n",
        "seq.add(BatchNormalization())\n",
        "\n",
        "seq.add(Conv3D(filters=1, kernel_size=(3, 3, 3),\n",
        "               activation='sigmoid',\n",
        "               padding='same', data_format='channels_last'))\n",
        "seq.compile(loss='binary_crossentropy', optimizer='adadelta')\n",
        "\n",
        "# Artificial data generation:\n",
        "# Generate movies with 3 to 7 moving squares inside.\n",
        "# The squares are of shape 1x1 or 2x2 pixels,\n",
        "# which move linearly over time.\n",
        "# For convenience we first create movies with bigger width and height (80x80)\n",
        "# and at the end we select a 40x40 window.\n",
        "\n",
        "#人工データの生成：\n",
        "#内部に3〜7個の移動する正方形を含むムービーを生成します。\n",
        "#正方形の形状は1x1または2x2ピクセルで、\n",
        "#時間とともに直線的に移動します。\n",
        "#便宜上、最初に幅と高さの大きい（80x80）ムービーを作成します\n",
        "#最後に、40x40ウィンドウを選択します。\n",
        "\n",
        "def generate_movies(n_samples=1200, n_frames=15):\n",
        "    row = 80\n",
        "    col = 80\n",
        "    noisy_movies = np.zeros((n_samples, n_frames, row, col, 1), dtype=np.float)\n",
        "    shifted_movies = np.zeros((n_samples, n_frames, row, col, 1),\n",
        "                              dtype=np.float)\n",
        "\n",
        "    for i in range(n_samples):\n",
        "        # Add 3 to 7 moving squares\n",
        "        n = np.random.randint(3, 8)\n",
        "\n",
        "        for j in range(n):\n",
        "            # Initial position\n",
        "            xstart = np.random.randint(20, 60)\n",
        "            ystart = np.random.randint(20, 60)\n",
        "            # Direction of motion\n",
        "            directionx = np.random.randint(0, 3) - 1\n",
        "            directiony = np.random.randint(0, 3) - 1\n",
        "\n",
        "            # Size of the square\n",
        "            w = np.random.randint(2, 4)\n",
        "\n",
        "            for t in range(n_frames):\n",
        "                x_shift = xstart + directionx * t\n",
        "                y_shift = ystart + directiony * t\n",
        "                noisy_movies[i, t, x_shift - w: x_shift + w,\n",
        "                             y_shift - w: y_shift + w, 0] += 1\n",
        "\n",
        "                # Make it more robust by adding noise.\n",
        "                # The idea is that if during inference,\n",
        "                # the value of the pixel is not exactly one,\n",
        "                # we need to train the network to be robust and still\n",
        "                # consider it as a pixel belonging to a square.\n",
        "                \n",
        "                #ノイズを追加して、より堅牢にします。\n",
        "                #アイデアは、推論中に、ピクセルの値は正確に1ではありません。\n",
        "                #ネットワークを堅牢にトレーニングし、それでも正方形に属するピクセルと見なす必要があります。\n",
        "\n",
        "                if np.random.randint(0, 2):\n",
        "                    noise_f = (-1)**np.random.randint(0, 2)\n",
        "                    noisy_movies[i, t,\n",
        "                                 x_shift - w - 1: x_shift + w + 1,\n",
        "                                 y_shift - w - 1: y_shift + w + 1,\n",
        "                                 0] += noise_f * 0.1\n",
        "\n",
        "                # Shift the ground truth by 1\n",
        "                x_shift = xstart + directionx * (t + 1)\n",
        "                y_shift = ystart + directiony * (t + 1)\n",
        "                shifted_movies[i, t, x_shift - w: x_shift + w,\n",
        "                               y_shift - w: y_shift + w, 0] += 1\n",
        "\n",
        "    # Cut to a 40x40 window\n",
        "    noisy_movies = noisy_movies[::, ::, 20:60, 20:60, ::]\n",
        "    shifted_movies = shifted_movies[::, ::, 20:60, 20:60, ::]\n",
        "    noisy_movies[noisy_movies >= 1] = 1\n",
        "    shifted_movies[shifted_movies >= 1] = 1\n",
        "    return noisy_movies, shifted_movies\n",
        "\n",
        "# Train the network\n",
        "noisy_movies, shifted_movies = generate_movies(n_samples=1200)\n",
        "seq.fit(noisy_movies[:1000], shifted_movies[:1000], batch_size=10,\n",
        "        epochs=3, validation_split=0.05)\n",
        "\n",
        "# Testing the network on one movie\n",
        "# feed it with the first 7 positions and then\n",
        "# predict the new positions\n",
        "\n",
        "#1つの映画でネットワークをテストし、最初の7つの位置をフィードしてから、新しい位置を予測します\n",
        "\n",
        "which = 1004\n",
        "track = noisy_movies[which][:7, ::, ::, ::]\n",
        "\n",
        "for j in range(16):\n",
        "    new_pos = seq.predict(track[np.newaxis, ::, ::, ::, ::])\n",
        "    new = new_pos[::, -1, ::, ::, ::]\n",
        "    track = np.concatenate((track, new), axis=0)\n",
        "\n",
        "\n",
        "# And then compare the predictions to the ground truth\n",
        "#そして、予測をグラウンドトゥルースと比較します\n",
        "\n",
        "track2 = noisy_movies[which][::, ::, ::, ::]\n",
        "for i in range(15):\n",
        "    fig = plt.figure(figsize=(10, 5))\n",
        "\n",
        "    ax = fig.add_subplot(121)\n",
        "\n",
        "    if i >= 7:\n",
        "        ax.text(1, 3, 'Predictions !', fontsize=20, color='w')\n",
        "    else:\n",
        "        ax.text(1, 3, 'Initial trajectory', fontsize=20)\n",
        "\n",
        "    toplot = track[i, ::, ::, 0]\n",
        "\n",
        "    plt.imshow(toplot)\n",
        "    ax = fig.add_subplot(122)\n",
        "    plt.text(1, 3, 'Ground truth', fontsize=20)\n",
        "\n",
        "    toplot = track2[i, ::, ::, 0]\n",
        "    if i >= 2:\n",
        "        toplot = shifted_movies[which][i - 1, ::, ::, 0]\n",
        "\n",
        "    plt.imshow(toplot)\n",
        "    plt.savefig('%i_animate.png' % (i + 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hm9PXMSy5To1"
      },
      "source": [
        "### 1.5.1（解答）比較"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqBc74d55YPj"
      },
      "source": [
        "import pandas as pd\n",
        "result_summary = pd.DataFrame({\"Test Score\":[0.752, 0.481, 0.449], \"Test accuracy\":[0.630, 0.833, 0.830]},\n",
        "                              index = [\"SimpleRNN\",\"GRU\", \"LSTM\"])\n",
        "result_summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxapxwUh3fx4"
      },
      "source": [
        "## 【問題2】（アドバンス課題）複数のデータセット間での比較\n",
        "他のデータセットでも実験を行なってください。\n",
        "\n",
        "\n",
        "データセット - Keras Documentation  \n",
        "https://keras.io/ja/datasets/#_5\n",
        "\n",
        "\n",
        "Kerasで簡単に利用できる自然言語データセットとしてロイターのニュースワイヤー トピックス分類があります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRJuBghC3mwO"
      },
      "source": [
        "## 【問題3】他のクラスの説明\n",
        "ドキュメントには他にも関連するクラスが記載されています。それらがどういうものなのかを説明してください。この中には実際に扱うことは少ないクラスも含まれています。\n",
        "\n",
        "\n",
        "- RNN\n",
        "- SimpleRNNCell\n",
        "- GRUCell\n",
        "- LSTMCell\n",
        "- StackedRNNCells\n",
        "- CuDNNGRU\n",
        "- CuDNNLSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiXYeYJN7Te-"
      },
      "source": [
        "### RNN\n",
        "リカレントニューラルネットワークの基底クラス  \n",
        "callメソッドを持つ このクラスの引数に任意のレイヤをー任意の数入力することで、スタックされたRNNを構築することができる\n",
        "\n",
        "### SimpleRNNCell\n",
        "出力が入力にフィードバックされる全結合RNNのcellクラス 入力した値から予測値を返すが、その次の入力値に前回の入力値を加えて予測を返す。 RNNの引数として複数入力することによりstackできる\n",
        "\n",
        "### GRUCell\n",
        "ゲートつきRNN 勾配消失問題を解決したネットワークのcellクラス 更新ゲートを持ち、前回の値をどれだけ保持して前に渡すかを決めてから渡すRNN LSTMに比べゲートの数が異なる\n",
        "\n",
        "### LSTMCell\n",
        "ゲートつきRNN GRUと同じく勾配消失問題を解決したネットワークのcell 入力、出力、忘却ゲートを持つ 入力ゲートで入力値をどれだけ処理するか 出力ゲートで出力の値をどれだけにするか 忘却ゲートで、保持している値をどれだけ保持するかを決める\n",
        "\n",
        "### StackedRNNCells\n",
        "RNN cellのスタックの振る舞いを単一のcellのようにするためのラッパー 例 cells = [ keras.layers.LSTMCell(output_dim), keras.layers.LSTMCell(output_dim), keras.layers.LSTMCell(output_dim), ] cellを繋げて一つの単位として構成できる\n",
        "\n",
        "### CuDNNGRU\n",
        "NDIVAのGPUを使用するGRU 通常より高速に処理を行える\n",
        "\n",
        "### CuDNNLSTM\n",
        "NDIVAのGPUを使用するLSTM 通常より高速に処理を行える"
      ]
    }
  ]
}