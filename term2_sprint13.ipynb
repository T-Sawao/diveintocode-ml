{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "term2_sprint13.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1_PvUm_oFdrzVgxG-iOyMkdQslrLdcOVn",
      "authorship_tag": "ABX9TyNjMyAVBvdXlRO6QXpo04NL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/T-Sawao/diveintocode-ml3/blob/main/term2_sprint13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23ZnsBwMjqH0"
      },
      "source": [
        "# 1.このSprintについて\n",
        "\n",
        "**Sprintの目的**  \n",
        "- フレームワークのコードを読めるようにする\n",
        "- フレームワークを習得し続けられるようになる\n",
        "- 理論を知っている範囲をフレームワークで動かす\n",
        "\n",
        "**どのように学ぶか**  \n",
        "TensorFLowのサンプルコードを元に、これまで扱ってきたデータセットを学習していきます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU05fHOSbhWZ"
      },
      "source": [
        "# 2.コードリーディング\n",
        "\n",
        "TensorFLowによって2値分類を行うサンプルコードを載せました。今回はこれをベースにして進めます。\n",
        "\n",
        "\n",
        "tf.kerasやtf.estimatorなどの高レベルAPIは使用していません。低レベルなところから見ていくことにします。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzhRLqRijZxW"
      },
      "source": [
        "## 【問題1】スクラッチを振り返る\n",
        "ここまでのスクラッチを振り返り、ディープラーニングを実装するためにはどのようなものが必要だったかを列挙してください。\n",
        "\n",
        "\n",
        "（例）\n",
        "\n",
        "\n",
        "- 重みを初期化する必要があった\n",
        "- エポックのループが必要だった\n",
        "\n",
        "それらがフレームワークにおいてはどのように実装されるかを今回覚えていきましょう。\n",
        "\n",
        "\n",
        "**データセットの用意**  \n",
        "以前から使用しているIrisデータセットを使用します。以下のサンプルコードではIris.csvが同じ階層にある想定です。\n",
        "\n",
        "\n",
        "Iris Species  \n",
        "https://www.kaggle.com/uciml/iris/data\n",
        "\n",
        "目的変数はSpeciesですが、3種類ある中から以下の2種類のみを取り出して使用します。  \n",
        "- Iris-versicolor\n",
        "- ris-virginica\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmDURlinpISS"
      },
      "source": [
        "### 1.1.1（解答）\n",
        "- 重み、バイアスの初期化、更新\n",
        "- エポックのループ\n",
        "- 活性化関数を通して出力する。\n",
        "- forward,back propagationを繰り返す。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNKoPRiSqJog"
      },
      "source": [
        "## 【問題2】スクラッチとTensorFlowの対応を考える\n",
        "以下のサンプルコードを見て、先ほど列挙した「ディープラーニングを実装するために必要なもの」がTensorFlowではどう実装されているかを確認してください。\n",
        "\n",
        "\n",
        "それを簡単に言葉でまとめてください。単純な一対一の対応であるとは限りません。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzH0BaqoiWbz"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygUcz5fzCwxu"
      },
      "source": [
        "class GetMiniBatch:\n",
        "    \"\"\"\n",
        "    ミニバッチを取得するイテレータ\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : 次の形のndarray, shape (n_samples, n_features)\n",
        "      訓練データ\n",
        "    y : 次の形のndarray, shape (n_samples, 1)\n",
        "      正解値\n",
        "    batch_size : int\n",
        "      バッチサイズ\n",
        "    seed : int\n",
        "      NumPyの乱数のシード\n",
        "    \"\"\"\n",
        "    def __init__(self, X, y, batch_size = 10, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self.X = X[shuffle_index]\n",
        "        self.y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self.X[p0:p1], self.y[p0:p1]        \n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self.X[p0:p1], self.y[p0:p1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gt0-yIzsC7gX"
      },
      "source": [
        "# モデルの作成\n",
        "def example_net(x):\n",
        "    \"\"\"\n",
        "    単純な3層ニューラルネットワーク\n",
        "    \"\"\"\n",
        "    # 重みの宣言\n",
        "    weights = {\n",
        "        'w1': tf.Variable(tf.random_normal([n_input, n_hidden1])),\n",
        "        'w2': tf.Variable(tf.random_normal([n_hidden1, n_hidden2])),\n",
        "        'w3': tf.Variable(tf.random_normal([n_hidden2, n_classes]))\n",
        "    }\n",
        "    # バイアスの宣言\n",
        "    biases = {\n",
        "        'b1': tf.Variable(tf.random_normal([n_hidden1])),\n",
        "        'b2': tf.Variable(tf.random_normal([n_hidden2])),\n",
        "        'b3': tf.Variable(tf.random_normal([n_classes]))\n",
        "    }\n",
        "    # レイヤーの構成\n",
        "    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
        "    layer_2 = tf.nn.relu(layer_2)\n",
        "    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3'] # tf.addと+は等価である\n",
        "    return layer_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t78pi-VdqOIa"
      },
      "source": [
        "\"\"\"\n",
        "TensorFlowで実装したニューラルネットワークを使いIrisデータセットを2値分類する\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# データセットの読み込み\n",
        "dataset_path =\"Iris.csv\"\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/diveintocode-ml/Iris.csv\")\n",
        "# データフレームから条件抽出\n",
        "df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
        "y = df[\"Species\"]\n",
        "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
        "y = np.array(y)\n",
        "X = np.array(X)\n",
        "# ラベルを数値に変換\n",
        "y[y=='Iris-versicolor'] = 0\n",
        "y[y=='Iris-virginica'] = 1\n",
        "y = y.astype(np.int)[:, np.newaxis]\n",
        "# trainとtestに分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "# さらにtrainとvalに分割\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
        "\n",
        "# ハイパーパラメータの設定\n",
        "learning_rate = 0.01\n",
        "batch_size = 10\n",
        "num_epochs = 10\n",
        "n_hidden1 = 50\n",
        "n_hidden2 = 100\n",
        "n_input = X_train.shape[1]\n",
        "n_samples = X_train.shape[0]\n",
        "n_classes = 1\n",
        "# 計算グラフに渡す引数の形を決める\n",
        "X = tf.placeholder(\"float\", [None, n_input])\n",
        "Y = tf.placeholder(\"float\", [None, n_classes])\n",
        "# trainのミニバッチイテレータ\n",
        "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
        "\n",
        "# ネットワーク構造の読み込み                               \n",
        "logits = example_net(X)\n",
        "# 目的関数\n",
        "loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=logits))\n",
        "# 最適化手法\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "# 推定結果\n",
        "correct_pred = tf.equal(tf.sign(Y - 0.5), tf.sign(tf.sigmoid(logits) - 0.5))\n",
        "# 指標値計算\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "# variableの初期化\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# 計算グラフの実行\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for epoch in range(num_epochs):\n",
        "        # エポックごとにループ\n",
        "        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
        "            # ミニバッチごとにループ\n",
        "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "            total_loss += loss\n",
        "            total_acc += acc\n",
        "        total_loss /= n_samples\n",
        "        total_acc /= n_samples\n",
        "        val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n",
        "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}, val_acc : {:.3f}\".format(epoch, loss, val_loss, acc, val_acc))\n",
        "    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n",
        "    print(\"test_acc : {:.3f}\".format(test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEzeYDssoIuT"
      },
      "source": [
        "### 2.1.1(解答)　　\n",
        "- forward,backward propagationの記述が無く簡素化された。\n",
        "- 初期化、更新、活性化関数は定義と実行が１文でまとまられた。\n",
        "- エポックのループ処理は変更なし。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YeeFzvsr--q"
      },
      "source": [
        "# 3.他のデータセットへの適用\n",
        "\n",
        "これまで扱ってきた小さなデータセットがいくつかあります。上記サンプルコードを書き換え、これらに対して学習・推定を行うニューラルネットワークを作成してください。\n",
        "\n",
        "- Iris（3種類全ての目的変数を使用）\n",
        "- House Prices\n",
        "\n",
        "どのデータセットもtrain, val, testの3種類に分けて使用してください。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SswbVpYPlbbn"
      },
      "source": [
        "## 【問題3】3種類全ての目的変数を使用したIrisのモデルを作成  \n",
        "Irisデータセットのtrain.csvの中で、目的変数Speciesに含まれる3種類全てを分類できるモデルを作成してください。\n",
        "\n",
        "\n",
        "Iris Species  \n",
        "https://www.kaggle.com/uciml/iris/data\n",
        "\n",
        "2クラスの分類と3クラス以上の分類の違いを考慮してください。それがTensorFlowでどのように書き換えられるかを公式ドキュメントなどを参考に調べてください。\n",
        "\n",
        "\n",
        "**《ヒント》**  \n",
        "以下の2箇所は2クラス分類特有の処理です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c09YnrKw824-"
      },
      "source": [
        "# loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=logits))\n",
        "\n",
        "# correct_pred = tf.equal(tf.sign(Y - 0.5), tf.sign(tf.sigmoid(logits) - 0.5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXnUoSeb85wx"
      },
      "source": [
        "メソッドは以下のように公式ドキュメントを確認してください。\n",
        "\n",
        "\n",
        "tf.nn.sigmoid_cross_entropy_with_logits  |  TensorFlow  \n",
        "https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits\n",
        "\n",
        "tf.math.sign  |  TensorFlow  \n",
        "https://www.tensorflow.org/api_docs/python/tf/math/sign\n",
        "\n",
        "\n",
        "＊tf.signとtf.math.signは同じ働きをします。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhFiLtetiRLs"
      },
      "source": [
        "### 3.1.1（前処理）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCVZYGvrXVSE"
      },
      "source": [
        "# データセットの読み込み\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/diveintocode-ml/Iris.csv\")\n",
        "# データフレームから条件抽出\n",
        "y = df[\"Species\"]\n",
        "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
        "y = pd.get_dummies(y)\n",
        "y = np.array(y)\n",
        "X = np.array(X)\n",
        "\n",
        "# trainとtestに分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "# さらにtrainとvalに分割\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QKwH42lieay"
      },
      "source": [
        "### 3.2.1（解答）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnJufKXhFivD"
      },
      "source": [
        "# ハイパーパラメータの設定\n",
        "learning_rate = 0.01\n",
        "batch_size = 10\n",
        "num_epochs = 10\n",
        "n_hidden1 = 50\n",
        "n_hidden2 = 100\n",
        "n_input = X_train.shape[1]\n",
        "n_samples = X_train.shape[0]\n",
        "n_classes = 3\n",
        "# ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "# 1.プレースホルダーの作成 (tensorflow2ではプレースホルダーは使用できない)\n",
        "# 2.float型のNone×784の行列を作成\n",
        "\n",
        "# 計算グラフに渡す引数の形を決める\n",
        "X = tf.placeholder(\"float\", [None, n_input])\n",
        "Y = tf.placeholder(\"float\", [None, n_classes])\n",
        "# ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "# 3.重みとバイアスを定義\n",
        "\n",
        "# ネットワーク構造の読み込み                               \n",
        "logits = example_net(X)\n",
        "# ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "# 4.モデルの実装\n",
        "\n",
        "# 目的関数\n",
        "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=logits))\n",
        "\n",
        "# 最適化手法\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "# ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "# 5.モデルの評価\n",
        "\n",
        "# 推定結果\n",
        "correct_pred = tf.equal(tf.argmax(Y,1),tf.argmax(tf.nn.softmax(logits),1))\n",
        "\n",
        "# 指標値計算\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
        "# ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "# 6.変数（variables）の初期化\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "# ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "# 7.モデルのトレーニング\n",
        "\n",
        "# trainのミニバッチイテレータ\n",
        "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for epoch in range(num_epochs):\n",
        "        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
        "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "            total_loss += loss\n",
        "            total_acc += acc\n",
        "        total_loss /= n_samples\n",
        "        total_acc /= n_samples\n",
        "        val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n",
        "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}, val_acc : {:.3f}\".format(epoch, loss, val_loss, acc, val_acc))\n",
        "    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n",
        "    print(\"test_acc : {:.3f}\".format(test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWQWY5bSrJ1l"
      },
      "source": [
        "## 【問題4】House Pricesのモデルを作成\n",
        "回帰問題のデータセットであるHouse Pricesを使用したモデルを作成してください。\n",
        "\n",
        "\n",
        "House Prices: Advanced Regression Techniques  \n",
        "https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data\n",
        "\n",
        "\n",
        "この中のtrain.csvをダウンロードし、目的変数としてSalePrice、説明変数として、GrLivAreaとYearBuiltを使ってください。説明変数はさらに増やしても構いません。\n",
        "\n",
        "\n",
        "分類問題と回帰問題の違いを考慮してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-PEOZNTrJmb"
      },
      "source": [
        "# データセットの読み込み\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/diveintocode-ml/house-prices-advanced-regression-techniques/train.csv\")\n",
        "# データフレームから条件抽出\n",
        "X = df[[\"GrLivArea\", \"YearBuilt\"]]\n",
        "y = df[[\"SalePrice\"]]\n",
        "y = np.array(np.log(y))\n",
        "X = np.array(np.log(X))\n",
        "\n",
        "# trainとtestに分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_mms, y, test_size=0.2, random_state=0)\n",
        "# さらにtrainとvalに分割\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3L8CktwiAZ8u"
      },
      "source": [
        "# 1.プレースホルダーの作成 (tensorflow2ではプレースホルダーは使用できない)\n",
        "# 2.float型のNone×784の行列を作成\n",
        "\n",
        "# 計算グラフに渡す引数の形を決める\n",
        "X = tf.placeholder(\"float\", [None, n_input])\n",
        "Y = tf.placeholder(\"float\", [None, n_classes])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWov4l04rJUJ"
      },
      "source": [
        "# ハイパーパラメータの設定\n",
        "learning_rate = 0.01\n",
        "batch_size = 10\n",
        "num_epochs = 10\n",
        "n_hidden1 = 50\n",
        "n_hidden2 = 100\n",
        "n_input = X_train.shape[1]\n",
        "n_samples = X_train.shape[0]\n",
        "n_classes = 1\n",
        "# ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "# 1.プレースホルダーの作成 (tensorflow2ではプレースホルダーは使用できない)\n",
        "# 2.float型のNone×784の行列を作成\n",
        "\n",
        "# 計算グラフに渡す引数の形を決める\n",
        "X = tf.placeholder(\"float\", [None, n_input])\n",
        "Y = tf.placeholder(\"float\", [None, n_classes])\n",
        "# ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "# 3.モデルの作成 (⇒def example_net(x):)                             \n",
        "logits = example_net(X)\n",
        "\n",
        "# 目的関数\n",
        "loss_op = tf.reduce_mean(tf.square(logits - Y))\n",
        "\n",
        "# 最適化手法\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "# ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "# 4.モデルの評価\n",
        "\n",
        "# 推定結果\n",
        "correct_pred = logits\n",
        "\n",
        "# 指標値計算\n",
        "MSE = tf.reduce_mean(tf.square(correct_pred - Y))\n",
        "# ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "# 5.変数（variables）の初期化\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "# ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "# 6.モデルのトレーニング\n",
        "\n",
        "# trainのミニバッチイテレータ\n",
        "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for epoch in range(num_epochs):\n",
        "      # エポックのループ\n",
        "      total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n",
        "      total_loss = 0\n",
        "      total_mse = 0\n",
        "      for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
        "        # ミニバッチのループ\n",
        "        sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "        loss, mse = sess.run([loss_op, MSE], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "        total_loss += loss\n",
        "        total_mse += mse\n",
        "      total_loss /= n_samples\n",
        "      total_mse /= n_samples\n",
        "      val_loss, val_mse = sess.run([loss_op, MSE], feed_dict={X: X_val, Y: y_val})\n",
        "      # if epoch %10==0:\n",
        "      print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, mse : {:.3f}, val_mse : {:.3f}\".format(epoch, loss, val_loss, mse, val_mse))\n",
        "    test_mse = sess.run(MSE, feed_dict={X: X_test, Y: y_test})\n",
        "    print(\"test_mse : {:.3f}\".format(test_mse))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8O5ZD9EITRa"
      },
      "source": [
        "### 【問題5】MNISTのモデルを作成\n",
        "ニューラルネットワークのスクラッチで使用したMNISTを分類するモデルを作成してください。\n",
        "\n",
        "\n",
        "3クラス以上の分類という点ではひとつ前のIrisと同様です。入力が画像であるという点で異なります。\n",
        "\n",
        "\n",
        "スクラッチで実装したモデルの再現を目指してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI7hFh2lMa7t"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.reshape(-1, 784)\n",
        "X_test = X_test.reshape(-1, 784)\n",
        "\n",
        "# float化と0or1処理\n",
        "X_train_flt = X_train.astype(np.float)\n",
        "X_test_flt = X_test.astype(np.float)\n",
        "X_train_flt /= 255\n",
        "X_test_flt /= 255\n",
        "\n",
        "# X_train = X_train_flt[:, np.newaxis,:,:]\n",
        "# X_test = X_test_flt[:, np.newaxis,:,:]\n",
        "\n",
        "# one hot処理\n",
        "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "y_train_onehot = enc.fit_transform(y_train[:, np.newaxis])\n",
        "y_test_onehot = enc.fit_transform(y_test[:, np.newaxis])\n",
        "print(X_train.shape)\n",
        "print(y_train_onehot.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OHX994tJLWt"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "# ハイパーパラメータの設定\n",
        "learning_rate = 0.01\n",
        "batch_size = 200\n",
        "num_epochs = 10\n",
        "n_hidden1 = 50\n",
        "n_hidden2 = 100\n",
        "n_input = X_train.shape[1]\n",
        "n_samples = X_train.shape[0]\n",
        "n_classes = 10\n",
        "# trainのミニバッチイテレータ\n",
        "get_mini_batch_train = GetMiniBatch(X_train, y_train_onehot, batch_size=batch_size)\n",
        "\n",
        "# ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "# 1.プレースホルダーの作成 (tensorflow2ではプレースホルダーは使用できない)\n",
        "# 2.float型のNone×784の行列を作成\n",
        "\n",
        "# 計算グラフに渡す引数の形を決める\n",
        "X = tf.placeholder(\"float\", [None, n_input])\n",
        "Y = tf.placeholder(\"float\", [None, n_classes])\n",
        "# ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "# 3.重みとバイアスを定義\n",
        "\n",
        "# ネットワーク構造の読み込み                               \n",
        "logits = example_net(X)\n",
        "# ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "# 4.モデルの実装\n",
        "\n",
        "# 目的関数\n",
        "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=logits))\n",
        "\n",
        "# 最適化手法\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "# ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "# 5.モデルの評価\n",
        "\n",
        "# 推定結果\n",
        "correct_pred = tf.equal(tf.argmax(Y,1),tf.argmax(tf.nn.softmax(logits),1))\n",
        "\n",
        "# 指標値計算\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
        "# ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "# 6.変数（variables）の初期化\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "# ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "# 7.モデルのトレーニング\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    # エポックのループ\n",
        "    for epoch in range(num_epochs):\n",
        "        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n",
        "                    # -------\n",
        "                    # 少数の切り上げ \n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "        # バッチのループ\n",
        "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
        "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "            total_loss += loss\n",
        "            total_acc += acc\n",
        "        total_loss /= n_samples\n",
        "        total_acc /= n_samples\n",
        "        val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n",
        "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}, val_acc : {:.3f}\".format(epoch, loss, val_loss, acc, val_acc))\n",
        "    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test_onehot})\n",
        "    print(\"test_acc : {:.3f}\".format(test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}