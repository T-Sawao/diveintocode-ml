{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "term2_sprint13.ipynb",
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1_PvUm_oFdrzVgxG-iOyMkdQslrLdcOVn",
      "authorship_tag": "ABX9TyO4vmiPnmKxR4botFyoOCkH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/T-Sawao/diveintocode-ml3/blob/main/term2_sprint13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgiLhXWPuQiX"
      },
      "source": [
        "## TensorFlowとは  \n",
        "TensorFlowは2015年11月にGoogle社が開発したオープンソースの深層学習ライブラリです。\n",
        "\n",
        "TensorFlowの特徴に関して簡単に説明いたします。\n",
        "主に以下のような特徴があります。\n",
        " \n",
        "- 1.CPUやGPUで動作し、複数のGPUマシンで分散・並列処理ができる。\n",
        " \n",
        "- 2.多層NN（ディープラーニング）に特化したライブラリ。\n",
        " \n",
        "- 3.TensorBoardというログ取得を行うことでモデルや値の推移を可視化できる。\n",
        " \n",
        "公式ドキュメンテーション  \n",
        "https://www.tensorflow.org/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqdbBnGyazgu"
      },
      "source": [
        "バージョンを確認する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PSSXrphbZ6d"
      },
      "source": [
        "pip list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF1BcIxabsUL"
      },
      "source": [
        "# # Tensorflow2の状況下で1を使えるコード\n",
        "# import tensorflow.compat.v1 as tf\n",
        "# tf.disable_v2_behavior()\n",
        "\n",
        "# Tensorflowのバージョンダウン\n",
        "# !pip install tensorflow==1.12.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYVlXk7-vQkw"
      },
      "source": [
        "簡単な記述例"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRYSpInKaSZq"
      },
      "source": [
        "import tensorflow as tf\n",
        "a = tf.constant(5)\n",
        "b = tf.constant(7)\n",
        "add = tf.add(a, b)\n",
        "\n",
        "#　セッションを変数に入れる （セッションとは、次に使う事を宣言するようなこと）\n",
        "sess = tf.Session()\n",
        "# addを実行すると宣言する。\n",
        "output = sess.run(add)\n",
        "print(output) # 12\n",
        "\n",
        "sess.close()\n",
        "\n",
        "const1 = tf.constant(10)\n",
        "const2 = tf.constant(15)\n",
        "add_op = tf.add(const1, const2)\n",
        "\n",
        "#　セッション→実行 （セッションとは、次に使う事を宣言するようなこと）\n",
        "with tf.Session() as sess:\n",
        "    result = sess.run(add_op)\n",
        "    print(result)\n",
        "\n",
        "# 上記は下記の記載と同じ\n",
        "# sess = tf.Session()\n",
        "# # addを実行すると宣言する。\n",
        "# output = sess.run(add)\n",
        "# print(output) # 12\n",
        "# sess.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HveGbEiOvfxi"
      },
      "source": [
        "**TensorFlowの用語**  \n",
        "定数(tf.constant)に加え変数(Variable)とプレースホルダー(placeholder)を宣言できます。\n",
        "\n",
        "**変数**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtmApzRwyPdg"
      },
      "source": [
        "var = tf.Variable(0)\n",
        "const = tf.constant(5)\n",
        "\n",
        "add_op = tf.add(var, const)\n",
        "# 変数に値を代入する。\n",
        "update_var = tf.assign(var, add_op)\n",
        "\n",
        "# mul_op = tf.mul(add_op, update_var) # 以前のバージョン\n",
        "mul_op = tf.multiply(add_op, update_var)\n",
        "\n",
        "v1 = tf.Variable(0)\n",
        "c1 = tf.constant(5)\n",
        "add_op = tf.add(v1,c1)\n",
        "update = tf.assign(v1, add_op) # updateというオペレーションノード\n",
        "\n",
        "# 変数を使う時は、セッション内でtf.global_variables_initializer()を実行し、変数を初期化する必要があります。\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "print(sess.run(v1))\n",
        "\n",
        "sess.run(update)\n",
        "print(sess.run(v1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHou0pdjzz-O"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    print(sess.run([mul_op]))\n",
        "    print(sess.run([mul_op]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCfGY8fL1Rse"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    print(sess.run([mul_op]))\n",
        "    print(sess.run([mul_op, mul_op]))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    print(sess.run([mul_op]))\n",
        "    print(sess.run([mul_op, mul_op]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIluLRRX2M95"
      },
      "source": [
        "**プレースホルダー**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwJClnLIkr0d"
      },
      "source": [
        "# プレースホルダーの作成 変数の時のように初期値を与えていない\n",
        "# 型としてtf.int32を指定しています。\n",
        "h1 = tf.placeholder(tf.int32)\n",
        "h2 = tf.placeholder(tf.int32)\n",
        "\n",
        "# output = tf.mul(h1,h2) # 以前のバージョン\n",
        "output = tf.multiply(h1,h2)\n",
        "\n",
        "sess = tf.Session()\n",
        "result = sess.run(output, feed_dict = {h1:100, h2:200})\n",
        "print(result)\n",
        "sess.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxcsCWIQ2erS"
      },
      "source": [
        "var = tf.Variable(0)\n",
        "holder2 = tf.placeholder(tf.int32)\n",
        "\n",
        "add_op = tf.add(var, holder2)\n",
        "update_var = tf.assign(var, add_op)\n",
        "\n",
        "# mul_op = tf.mul(add_op, update_var) # 以前のバージョン\n",
        "mul_op = tf.multiply(add_op, update_var)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    result = sess.run(mul_op, feed_dict={holder2: 5})\n",
        "    print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lvn4GE_TmViq"
      },
      "source": [
        "import numpy as np\n",
        "x_train = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y_train = np.array([[0],[0],[0],[1]])\n",
        "\n",
        "x = tf.placeholder(tf.float32, [None, 2])\n",
        "t = tf.placeholder(tf.float32, [None, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h028tHx6Q__C"
      },
      "source": [
        "W = tf.Variable(tf.zeros([2,1]))\n",
        "b = tf.Variable(tf.zeros([1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VKl9gkiRZKn"
      },
      "source": [
        "# 仮定関数　+ 目的関数の定義\n",
        "y = tf.sigmoid(tf.matmul(x, W) + b)\n",
        "cross_entropy = tf.reduce_sum(-t * tf.log(y) - (1 - t) * tf.log(1 - y))\n",
        "\n",
        "# 学習（勾配降下法） + 目的関数の実行）\n",
        "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)\n",
        "\n",
        "# 評価\n",
        "correct_prediction = tf.equal(tf.sign(y - 0.5), tf.sign(t - 0.5))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vaai7C5JWmPx"
      },
      "source": [
        "# セッションを宣言\n",
        "sess = tf.Session()\n",
        "\n",
        "# variavlesの値（重みとバイアス）を初期化\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBolEXbIYK7P"
      },
      "source": [
        "for epoch in range(1000):\n",
        "  # feel_dictで空箱を設置\n",
        "  sess.run(train_step, feed_dict = {\n",
        "      x:x_train,\n",
        "      t:y_train\n",
        "  })\n",
        "\n",
        "  # 100階毎に正解率を表示\n",
        "  if epoch % 100 == 0:\n",
        "    # 空箱だったxにx_trainの値が入る。\n",
        "    acc_val = sess.run(accuracy, feed_dict={\n",
        "        x:x_train,\n",
        "        t:y_train})\n",
        "    print(epoch, acc_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AY3w84SWsVT"
      },
      "source": [
        "#学習結果が正しいか確認\n",
        "classified = sess.run(correct_prediction, feed_dict={\n",
        "    x:x_train,\n",
        "    t:y_train\n",
        "})\n",
        "\n",
        "#出力yの確認\n",
        "prob = sess.run(y, feed_dict={\n",
        "    x:x_train,\n",
        "    t:y_train\n",
        "})\n",
        "print(classified)\n",
        "print(prob)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJEq-LOPa_Mj"
      },
      "source": [
        "print('W:', sess.run(W))\n",
        "print('b:', sess.run(b))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve0JYCfjbTmZ"
      },
      "source": [
        "mat = tf.matmul(x, W)\n",
        "y = tf.sigmoid(mat + b)\n",
        "print(sess.run(mat, feed_dict={\n",
        "    x:x_train,\n",
        "    t:y_train\n",
        "}))\n",
        "\n",
        "sess.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU05fHOSbhWZ"
      },
      "source": [
        "# 2.コードリーディング\n",
        "\n",
        "TensorFLowによって2値分類を行うサンプルコードを載せました。今回はこれをベースにして進めます。\n",
        "\n",
        "\n",
        "tf.kerasやtf.estimatorなどの高レベルAPIは使用していません。低レベルなところから見ていくことにします。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzhRLqRijZxW"
      },
      "source": [
        "## 【問題1】スクラッチを振り返る\n",
        "ここまでのスクラッチを振り返り、ディープラーニングを実装するためにはどのようなものが必要だったかを列挙してください。\n",
        "\n",
        "\n",
        "（例）\n",
        "\n",
        "\n",
        "- 重みを初期化する必要があった\n",
        "- エポックのループが必要だった\n",
        "\n",
        "それらがフレームワークにおいてはどのように実装されるかを今回覚えていきましょう。\n",
        "\n",
        "\n",
        "**データセットの用意**  \n",
        "以前から使用しているIrisデータセットを使用します。以下のサンプルコードではIris.csvが同じ階層にある想定です。\n",
        "\n",
        "\n",
        "Iris Species  \n",
        "https://www.kaggle.com/uciml/iris/data\n",
        "\n",
        "目的変数はSpeciesですが、3種類ある中から以下の2種類のみを取り出して使用します。  \n",
        "- Iris-versicolor\n",
        "- ris-virginica\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmDURlinpISS"
      },
      "source": [
        "【回答】\n",
        "- 重み、バイアスの初期化、更新\n",
        "- エポックのループ\n",
        "- 活性化関数を通して出力する。\n",
        "- forward,back propagationを繰り返す。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNKoPRiSqJog"
      },
      "source": [
        "## 【問題2】スクラッチとTensorFlowの対応を考える\n",
        "以下のサンプルコードを見て、先ほど列挙した「ディープラーニングを実装するために必要なもの」がTensorFlowではどう実装されているかを確認してください。\n",
        "\n",
        "\n",
        "それを簡単に言葉でまとめてください。単純な一対一の対応であるとは限りません。\n",
        "\n",
        "\n",
        "**《サンプルコード》**\n",
        "\n",
        "\n",
        "＊バージョン1.5から1.14の間で動作を確認済みです。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygUcz5fzCwxu"
      },
      "source": [
        "class GetMiniBatch:\n",
        "    \"\"\"\n",
        "    ミニバッチを取得するイテレータ\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : 次の形のndarray, shape (n_samples, n_features)\n",
        "      訓練データ\n",
        "    y : 次の形のndarray, shape (n_samples, 1)\n",
        "      正解値\n",
        "    batch_size : int\n",
        "      バッチサイズ\n",
        "    seed : int\n",
        "      NumPyの乱数のシード\n",
        "    \"\"\"\n",
        "    def __init__(self, X, y, batch_size = 10, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self.X = X[shuffle_index]\n",
        "        self.y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self.X[p0:p1], self.y[p0:p1]        \n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self.X[p0:p1], self.y[p0:p1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gt0-yIzsC7gX"
      },
      "source": [
        "def example_net(x):\n",
        "    \"\"\"\n",
        "    単純な3層ニューラルネットワーク\n",
        "    \"\"\"\n",
        "    # 重みとバイアスの宣言\n",
        "    weights = {\n",
        "        'w1': tf.Variable(tf.random_normal([n_input, n_hidden1])),\n",
        "        'w2': tf.Variable(tf.random_normal([n_hidden1, n_hidden2])),\n",
        "        'w3': tf.Variable(tf.random_normal([n_hidden2, n_classes]))\n",
        "    }\n",
        "    biases = {\n",
        "        'b1': tf.Variable(tf.random_normal([n_hidden1])),\n",
        "        'b2': tf.Variable(tf.random_normal([n_hidden2])),\n",
        "        'b3': tf.Variable(tf.random_normal([n_classes]))\n",
        "    }\n",
        "    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
        "    layer_2 = tf.nn.relu(layer_2)\n",
        "    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3'] # tf.addと+は等価である\n",
        "    return layer_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t78pi-VdqOIa"
      },
      "source": [
        "\"\"\"\n",
        "TensorFlowで実装したニューラルネットワークを使いIrisデータセットを2値分類する\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "# データセットの読み込み\n",
        "dataset_path =\"Iris.csv\"\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/diveintocode-ml/Iris.csv\")\n",
        "# データフレームから条件抽出\n",
        "df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
        "y = df[\"Species\"]\n",
        "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
        "y = np.array(y)\n",
        "X = np.array(X)\n",
        "# ラベルを数値に変換\n",
        "y[y=='Iris-versicolor'] = 0\n",
        "y[y=='Iris-virginica'] = 1\n",
        "y = y.astype(np.int)[:, np.newaxis]\n",
        "# trainとtestに分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "# さらにtrainとvalに分割\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
        "\n",
        "# ハイパーパラメータの設定\n",
        "learning_rate = 0.01\n",
        "batch_size = 10\n",
        "num_epochs = 10\n",
        "n_hidden1 = 50\n",
        "n_hidden2 = 100\n",
        "n_input = X_train.shape[1]\n",
        "n_samples = X_train.shape[0]\n",
        "n_classes = 1\n",
        "# 計算グラフに渡す引数の形を決める\n",
        "X = tf.placeholder(\"float\", [None, n_input])\n",
        "Y = tf.placeholder(\"float\", [None, n_classes])\n",
        "# trainのミニバッチイテレータ\n",
        "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
        "\n",
        "# ネットワーク構造の読み込み                               \n",
        "logits = example_net(X)\n",
        "# 目的関数\n",
        "loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=logits))\n",
        "# 最適化手法\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "# 推定結果\n",
        "correct_pred = tf.equal(tf.sign(Y - 0.5), tf.sign(tf.sigmoid(logits) - 0.5))\n",
        "# 指標値計算\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "# variableの初期化\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# 計算グラフの実行\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for epoch in range(num_epochs):\n",
        "        # エポックごとにループ\n",
        "        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
        "            # ミニバッチごとにループ\n",
        "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "            total_loss += loss\n",
        "            total_acc += acc\n",
        "        total_loss /= n_samples\n",
        "        total_acc /= n_samples\n",
        "        val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n",
        "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}, val_acc : {:.3f}\".format(epoch, loss, val_loss, acc, val_acc))\n",
        "    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n",
        "    print(\"test_acc : {:.3f}\".format(test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEzeYDssoIuT"
      },
      "source": [
        "### 2.1.1(解答)　　\n",
        "- forward,backward propagationの記述が無く簡素化された。\n",
        "- 初期化、更新、活性化関数は定義と実行が１文でまとまられた。\n",
        "- エポックのループ処理は変更なし。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YeeFzvsr--q"
      },
      "source": [
        "# 3.他のデータセットへの適用\n",
        "\n",
        "これまで扱ってきた小さなデータセットがいくつかあります。上記サンプルコードを書き換え、これらに対して学習・推定を行うニューラルネットワークを作成してください。\n",
        "\n",
        "- Iris（3種類全ての目的変数を使用）\n",
        "- House Prices\n",
        "\n",
        "どのデータセットもtrain, val, testの3種類に分けて使用してください。\n",
        "\n",
        "## 【問題3】3種類全ての目的変数を使用したIrisのモデルを作成  \n",
        "Irisデータセットのtrain.csvの中で、目的変数Speciesに含まれる3種類全てを分類できるモデルを作成してください。\n",
        "\n",
        "\n",
        "Iris Species  \n",
        "https://www.kaggle.com/uciml/iris/data\n",
        "\n",
        "2クラスの分類と3クラス以上の分類の違いを考慮してください。それがTensorFlowでどのように書き換えられるかを公式ドキュメントなどを参考に調べてください。\n",
        "\n",
        "\n",
        "**《ヒント》**  \n",
        "以下の2箇所は2クラス分類特有の処理です。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c09YnrKw824-"
      },
      "source": [
        "# loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=logits))\n",
        "\n",
        "# correct_pred = tf.equal(tf.sign(Y - 0.5), tf.sign(tf.sigmoid(logits) - 0.5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXnUoSeb85wx"
      },
      "source": [
        "メソッドは以下のように公式ドキュメントを確認してください。\n",
        "\n",
        "\n",
        "tf.nn.sigmoid_cross_entropy_with_logits  |  TensorFlow  \n",
        "https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits\n",
        "\n",
        "tf.math.sign  |  TensorFlow  \n",
        "https://www.tensorflow.org/api_docs/python/tf/math/sign\n",
        "\n",
        "\n",
        "＊tf.signとtf.math.signは同じ働きをします。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhFiLtetiRLs"
      },
      "source": [
        "### 3.1.1（前処理）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCVZYGvrXVSE"
      },
      "source": [
        "# データセットの読み込み\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/diveintocode-ml/Iris.csv\")\n",
        "# データフレームから条件抽出\n",
        "y = df[\"Species\"]\n",
        "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
        "y = pd.get_dummies(y)\n",
        "y = np.array(y)\n",
        "X = np.array(X)\n",
        "\n",
        "# trainとtestに分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "# さらにtrainとvalに分割\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QKwH42lieay"
      },
      "source": [
        "### 3.2.1（解答）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnJufKXhFivD"
      },
      "source": [
        "# ハイパーパラメータの設定\n",
        "learning_rate = 0.01\n",
        "batch_size = 10\n",
        "num_epochs = 10\n",
        "n_hidden1 = 50\n",
        "n_hidden2 = 100\n",
        "n_input = X_train.shape[1]\n",
        "n_samples = X_train.shape[0]\n",
        "n_classes = 3\n",
        "# ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "# 1.プレースホルダーの作成 (tensorflow2ではプレースホルダーは使用できない)\n",
        "# 2.float型のNone×784の行列を作成\n",
        "\n",
        "# 計算グラフに渡す引数の形を決める\n",
        "X = tf.placeholder(\"float\", [None, n_input])\n",
        "Y = tf.placeholder(\"float\", [None, n_classes])\n",
        "# ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "# 3.重みとバイアスを定義\n",
        "\n",
        "# ネットワーク構造の読み込み                               \n",
        "logits = example_net(X)\n",
        "# ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "# 4.モデルの実装\n",
        "\n",
        "# 目的関数\n",
        "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=logits))\n",
        "\n",
        "# 最適化手法\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "# ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "# 5.モデルの評価\n",
        "\n",
        "# 推定結果\n",
        "correct_pred = tf.equal(tf.argmax(Y,1),tf.argmax(tf.nn.softmax(logits),1))\n",
        "\n",
        "# 指標値計算\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
        "# ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "# 6.変数（variables）の初期化\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "# ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー\n",
        "# 7.モデルのトレーニング\n",
        "\n",
        "# trainのミニバッチイテレータ\n",
        "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for epoch in range(num_epochs):\n",
        "        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
        "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "            total_loss += loss\n",
        "            total_acc += acc\n",
        "        total_loss /= n_samples\n",
        "        total_acc /= n_samples\n",
        "        val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n",
        "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}, val_acc : {:.3f}\".format(epoch, loss, val_loss, acc, val_acc))\n",
        "    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n",
        "    print(\"test_acc : {:.3f}\".format(test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWQWY5bSrJ1l"
      },
      "source": [
        "## 【問題4】House Pricesのモデルを作成\n",
        "回帰問題のデータセットであるHouse Pricesを使用したモデルを作成してください。\n",
        "\n",
        "\n",
        "House Prices: Advanced Regression Techniques  \n",
        "https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data\n",
        "\n",
        "\n",
        "この中のtrain.csvをダウンロードし、目的変数としてSalePrice、説明変数として、GrLivAreaとYearBuiltを使ってください。説明変数はさらに増やしても構いません。\n",
        "\n",
        "\n",
        "分類問題と回帰問題の違いを考慮してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-PEOZNTrJmb"
      },
      "source": [
        "# データセットの読み込み\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/diveintocode-ml/Iris.csv\")\n",
        "# データフレームから条件抽出\n",
        "df = df[(df[\"Species\"] == \"Iris-setosa\")|(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
        "y = df[\"Species\"]\n",
        "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
        "y = np.array(y)\n",
        "X = np.array(X)\n",
        "\n",
        "# ラベルを数値に変換\n",
        "y[y=='Iris-setosa'] = 0\n",
        "y[y=='Iris-versicolor'] = 1\n",
        "y[y=='Iris-virginica'] = 2\n",
        "\n",
        "# one hot処理\n",
        "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "y_train_one_hot = enc.fit_transform(y[:, np.newaxis])\n",
        "  \n",
        "# trainとtestに分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "# さらにtrainとvalに分割\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWov4l04rJUJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJ5AgRn-27oN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}